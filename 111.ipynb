{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tb3kUn1yY1kq",
    "outputId": "6dc6c478-d0c2-403c-e15e-cbecd2915293"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸš« ĞÑ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ñ‚ĞµĞ»ĞµĞ¼ĞµÑ‚Ñ€Ğ¸Ğ¸ Ğ¸ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹...\n",
      "âœ… Ğ¢ĞµĞ»ĞµĞ¼ĞµÑ‚Ñ€Ğ¸Ñ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ°\n",
      "ğŸ“¦ Ğ£Ğ¡Ğ¢ĞĞĞĞ’ĞšĞ Ğ—ĞĞ’Ğ˜Ğ¡Ğ˜ĞœĞĞ¡Ğ¢Ğ•Ğ™\n",
      "============================================================\n",
      "ğŸ“¦ Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¿Ğ°ĞºĞµÑ‚Ğ¾Ğ²:\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hâœ… openai==1.6.1\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m815.9/815.9 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-cloud-bigquery 3.35.1 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
      "xarray 2025.7.1 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\n",
      "db-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "langchain-text-splitters 0.3.9 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 0.1.23 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mâœ… langchain==0.1.7\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m786.8/786.8 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-community 0.0.20 requires langsmith<0.1,>=0.0.83, but you have langsmith 0.1.147 which is incompatible.\n",
      "langchain 0.1.7 requires langsmith<0.1,>=0.0.83, but you have langsmith 0.1.147 which is incompatible.\n",
      "langchain-text-splitters 0.3.9 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 0.1.53 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mâœ… langchain-openai==0.0.8\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hâœ… langgraph==0.0.45\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m479.8/479.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m445.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.7/116.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "âœ… chromadb==0.4.15\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-community 0.0.20 requires langsmith<0.1,>=0.0.83, but you have langsmith 0.1.147 which is incompatible.\n",
      "langchain 0.1.7 requires langsmith<0.1,>=0.0.83, but you have langsmith 0.1.147 which is incompatible.\n",
      "xarray 2025.7.1 requires numpy>=1.26, but you have numpy 1.25.2 which is incompatible.\n",
      "xarray 2025.7.1 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\n",
      "blosc2 3.6.1 requires numpy>=1.26, but you have numpy 1.25.2 which is incompatible.\n",
      "db-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 1.25.2 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.25.2 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.25.2 which is incompatible.\n",
      "arviz 0.22.0 requires numpy>=1.26.0, but you have numpy 1.25.2 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.25.2 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.25.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mâœ… numpy==1.25.2\n",
      "âœ… nest-asyncio==1.5.8\n",
      "âœ… matplotlib>=3.7.0\n",
      "âœ… plotly>=5.15.0\n",
      "âœ… seaborn>=0.12.0\n",
      "âœ… pandas>=2.0.0\n",
      "\n",
      "âœ… nest_asyncio Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½ Ğ´Ğ»Ñ Jupyter\n",
      "\n",
      "âœ… Ğ’ÑĞµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ñ‹!\n",
      "ğŸ¯ ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ñ‚Ğµ Ğº ÑÑ‡ĞµĞ¹ĞºĞµ 2 Ğ´Ğ»Ñ ĞºĞ»Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°\n"
     ]
    }
   ],
   "source": [
    "# Ğ¯Ğ§Ğ•Ğ™ĞšĞ 1: Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ Ğ¸ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ñ‚ĞµĞ»ĞµĞ¼ĞµÑ‚Ñ€Ğ¸Ğ¸\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "# ğŸš« ĞĞ¢ĞšĞ›Ğ®Ğ§ĞĞ•Ğœ Ğ’Ğ¡Ğ® Ğ¢Ğ•Ğ›Ğ•ĞœĞ•Ğ¢Ğ Ğ˜Ğ® Ğ˜ ĞŸĞ Ğ•Ğ”Ğ£ĞŸĞ Ğ•Ğ–Ğ”Ğ•ĞĞ˜Ğ¯\n",
    "print('ğŸš« ĞÑ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ñ‚ĞµĞ»ĞµĞ¼ĞµÑ‚Ñ€Ğ¸Ğ¸ Ğ¸ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹...')\n",
    "os.environ['TELEMETRY_DISABLED'] = 'true'\n",
    "\n",
    "os.environ['OPENAI_LOG_LEVEL'] = 'ERROR'\n",
    "warnings.filterwarnings('ignore')\n",
    "print('âœ… Ğ¢ĞµĞ»ĞµĞ¼ĞµÑ‚Ñ€Ğ¸Ñ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ°')\n",
    "\n",
    "print('ğŸ“¦ Ğ£Ğ¡Ğ¢ĞĞĞĞ’ĞšĞ Ğ—ĞĞ’Ğ˜Ğ¡Ğ˜ĞœĞĞ¡Ğ¢Ğ•Ğ™')\n",
    "print('=' * 60)\n",
    "\n",
    "## Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ñ Ñ„Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ²ĞµÑ€ÑĞ¸ÑĞ¼Ğ¸ Ğ´Ğ»Ñ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸\n",
    "dependencies = [\n",
    "    'openai==1.6.1',\n",
    "    'langchain==0.1.7',\n",
    "    'langchain-openai==0.0.8',\n",
    "    'langgraph==0.0.45',\n",
    "    'chromadb==0.4.15',\n",
    "    'numpy==1.25.2',\n",
    "    'nest-asyncio==1.5.8',\n",
    "    'matplotlib>=3.7.0',\n",
    "    'plotly>=5.15.0',\n",
    "    'seaborn>=0.12.0',\n",
    "    'pandas>=2.0.0'\n",
    "]\n",
    "\n",
    "print('ğŸ“¦ Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¿Ğ°ĞºĞµÑ‚Ğ¾Ğ²:')\n",
    "for dep in dependencies:\n",
    "    try:\n",
    "        !pip install -q {dep}\n",
    "        print(f'âœ… {dep}')\n",
    "    except:\n",
    "        print(f'âš ï¸ {dep} (Ğ¾ÑˆĞ¸Ğ±ĞºĞ°, Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°ĞµĞ¼)')\n",
    "\n",
    "# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° asyncio Ğ´Ğ»Ñ Jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "print('\\nâœ… nest_asyncio Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½ Ğ´Ğ»Ñ Jupyter')\n",
    "\n",
    "print('\\nâœ… Ğ’ÑĞµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ñ‹!')\n",
    "print('ğŸ¯ ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ñ‚Ğµ Ğº ÑÑ‡ĞµĞ¹ĞºĞµ 2 Ğ´Ğ»Ñ ĞºĞ»Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LCooDvgqY1kr",
    "outputId": "604e3e04-f8c2-42bc-e23b-a510f94a6924"
   },
   "outputs": [],
   "source": "# Ğ¯Ğ§Ğ•Ğ™ĞšĞ 1: Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ\n\n!pip install --quiet langchain openai chromadb python-dotenv asyncio\n!pip install --quiet langchain-community langchain-openai\n\nimport warnings\nimport os\nimport asyncio\nimport nest_asyncio\n\n# ğŸš« ĞĞ¢ĞšĞ›Ğ®Ğ§ĞĞ•Ğœ Ğ’Ğ¡Ğ® Ğ¢Ğ•Ğ›Ğ•ĞœĞ•Ğ¢Ğ Ğ˜Ğ® Ğ˜ ĞŸĞ Ğ•Ğ”Ğ£ĞŸĞ Ğ•Ğ–Ğ”Ğ•ĞĞ˜Ğ¯\nprint('ğŸš« ĞÑ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ñ‚ĞµĞ»ĞµĞ¼ĞµÑ‚Ñ€Ğ¸Ğ¸ Ğ¸ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹...')\nos.environ['TELEMETRY_DISABLED'] = 'true'\nos.environ['OPENAI_LOG_LEVEL'] = 'ERROR'\nwarnings.filterwarnings('ignore')\nprint('âœ… Ğ¢ĞµĞ»ĞµĞ¼ĞµÑ‚Ñ€Ğ¸Ñ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ°')\n\n# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ¿Ğ°ĞºĞµÑ‚Ğ¾Ğ²\nprint('\\nğŸ“¦ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹:')\ndependencies = [\n    'langchain', 'openai', 'chromadb', 'asyncio', \n    'langchain_community', 'langchain_openai'\n]\n\nfor dep in dependencies:\n    try:\n        __import__(dep)\n        print(f'âœ… {dep}')\n    except:\n        print(f'âš ï¸ {dep} (Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸, Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°ĞµĞ¼)')\n\n# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° asyncio Ğ´Ğ»Ñ Jupyter\nnest_asyncio.apply()\nprint('âœ… AsyncIO Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ Ğ´Ğ»Ñ Jupyter')\n\nprint('\\nâœ… Ğ’ÑĞµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ñ‹!')\nprint('ğŸ¯ ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ñ‚Ğµ Ğº ÑÑ‡ĞµĞ¹ĞºĞµ 2 Ğ´Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ul-BzpumY1ks",
    "outputId": "6cf4b21f-19b6-4bf4-c376-9c36362ab0ee"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ”‘ ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ OPENAI API\n",
      "============================================================\n",
      "âœ… OpenAI API ĞºĞ»ÑÑ‡ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ğ¸Ğ· Colab secrets\n",
      "âœ… ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº OpenAI API Ğ¿Ñ€Ğ¾Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚\n",
      "\n",
      "ğŸ¯ ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ñ‚Ğµ Ğº ÑÑ‡ĞµĞ¹ĞºĞµ 4 Ğ´Ğ»Ñ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ ChromaDB\n"
     ]
    }
   ],
   "source": [
    "# Ğ¯Ğ§Ğ•Ğ™ĞšĞ 3: ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº OpenAI API Ñ‡ĞµÑ€ĞµĞ· Colab secrets\n",
    "\n",
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "print('ğŸ”‘ ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ OPENAI API')\n",
    "print('=' * 60)\n",
    "\n",
    "try:\n",
    "    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ API ĞºĞ»ÑÑ‡ Ğ¸Ğ· ÑĞµĞºÑ€ĞµÑ‚Ğ¾Ğ² Google Colab\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "    if OPENAI_API_KEY:\n",
    "        # Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½ÑƒÑ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ\n",
    "        os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "        print('âœ… OpenAI API ĞºĞ»ÑÑ‡ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ğ¸Ğ· Colab secrets')\n",
    "\n",
    "        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ\n",
    "        import openai\n",
    "        client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "        # Ğ¢ĞµÑÑ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ½ĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ¼\n",
    "        test_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "            max_tokens=5\n",
    "        )\n",
    "        print('âœ… ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº OpenAI API Ğ¿Ñ€Ğ¾Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚')\n",
    "\n",
    "    else:\n",
    "        print('âŒ OpenAI API ĞºĞ»ÑÑ‡ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² ÑĞµĞºÑ€ĞµÑ‚Ğ°Ñ… Colab')\n",
    "        print('ğŸ’¡ Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ OPENAI_API_KEY Ğ² ÑĞµĞºÑ€ĞµÑ‚Ñ‹ Google Colab')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ OpenAI API: {e}')\n",
    "    print('ğŸ’¡ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ API ĞºĞ»ÑÑ‡Ğ° Ğ² ÑĞµĞºÑ€ĞµÑ‚Ğ°Ñ… Colab')\n",
    "\n",
    "print('\\nğŸ¯ ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ñ‚Ğµ Ğº ÑÑ‡ĞµĞ¹ĞºĞµ 4 Ğ´Ğ»Ñ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ ChromaDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wC7ipeK0Y1k-",
    "outputId": "f853312f-7115-474a-9eef-1148d8560b74"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ—„ï¸ Ğ˜ĞĞ˜Ğ¦Ğ˜ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ CHROMADB Ğ˜ Ğ’Ğ•ĞšĞ¢ĞĞ Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ Ğ—ĞĞĞĞ˜Ğ™\n",
      "============================================================\n",
      "ğŸ”§ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°:\n",
      "âœ… Ğ”Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ knowledge Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°: /content/ai-seo-architects/knowledge\n",
      "âœ… ChromaDB Knowledge Manager Ñ„Ğ°Ğ¹Ğ» Ğ½Ğ°Ğ¹Ğ´ĞµĞ½\n",
      "âš ï¸ ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½ ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ FAISS knowledge_manager.py - Ğ±ÑƒĞ´ĞµĞ¼ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ChromaDB Ğ²ĞµÑ€ÑĞ¸Ñ\n",
      "\n",
      "ğŸ“š ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ±Ğ°Ğ· Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ¿Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½ÑĞ¼:\n",
      "âœ… executive   :  2 Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹\n",
      "âœ… management  :  4 Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹\n",
      "âœ… operational :  8 Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹\n",
      "\n",
      "ğŸ“„ Ğ’ÑĞµĞ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹: 14\n",
      "\n",
      "ğŸ”§ Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ ChromaDB ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ¹ Ğ²ĞµÑ€ÑĞ¸Ğ¸...\n",
      "âœ… Ğ£Ğ±Ñ€Ğ°Ğ½ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ chromadb.config.Settings\n",
      "âœ… ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ° Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ChromaDB ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°\n",
      "âœ… ChromaDB ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ°\n",
      "\n",
      "ğŸ”„ Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ¬ĞĞ«Ğ™ ChromaDB Knowledge Manager...\n",
      "âœ… OpenAI Embeddings Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹\n",
      "âœ… ChromaDB Knowledge Manager ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½\n",
      "âœ… ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°\n",
      "\n",
      "ğŸ“Š ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜ CHROMADB:\n",
      "ğŸ“ Ğ‘Ğ°Ğ·Ğ° Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹: ./knowledge/\n",
      "ğŸ” RAG Ğ²ĞºĞ»ÑÑ‡ĞµĞ½: True\n",
      "ğŸ“Š Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²: 1000\n",
      "ğŸ¯ Top K Ğ¿Ğ¾Ğ¸ÑĞºĞ°: 3\n",
      "ğŸ—„ï¸ Ğ’ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ°Ñ Ğ‘Ğ”: ChromaDB (Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ)\n",
      "ğŸ’¾ ĞŸÑƒÑ‚ÑŒ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ: ./data/vector_stores/\n",
      "\n",
      "ğŸš€ Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ±Ğ°Ğ· Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ² ChromaDB...\n",
      "ğŸ”„ Ğ­Ñ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ·Ğ°Ğ½ÑÑ‚ÑŒ 1-2 Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹ Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²...\n",
      "==================================================\n",
      "ğŸ”„ Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ±Ğ°Ğ· Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² ChromaDB...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'executive_chief_seo_strategist' Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°\n",
      "ğŸ“„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ñ„Ğ°Ğ¹Ğ» chief_seo_strategist.md: 50 Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ 50 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'executive_chief_seo_strategist'\n",
      "âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ ChromaDB Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ´Ğ»Ñ chief_seo_strategist (50 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²)\n",
      "âœ… ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'executive_business_development_director' Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°\n",
      "ğŸ“„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ñ„Ğ°Ğ¹Ğ» business_development_director.md: 37 Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ 37 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'executive_business_development_director'\n",
      "âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ ChromaDB Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ´Ğ»Ñ business_development_director (37 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²)\n",
      "âœ… ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'management_task_coordination' Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°\n",
      "ğŸ“„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ñ„Ğ°Ğ¹Ğ» task_coordination.md: 24 Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ 24 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'management_task_coordination'\n",
      "âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ ChromaDB Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ´Ğ»Ñ task_coordination (24 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²)\n",
      "âœ… ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'management_sales_operations_manager' Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°\n",
      "ğŸ“„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ñ„Ğ°Ğ¹Ğ» sales_operations_manager.md: 18 Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ 18 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'management_sales_operations_manager'\n",
      "âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ ChromaDB Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ´Ğ»Ñ sales_operations_manager (18 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²)\n",
      "âœ… ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'management_technical_seo_operations_manager' Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°\n",
      "ğŸ“„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ñ„Ğ°Ğ¹Ğ» technical_seo_operations_manager.md: 38 Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ 38 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'management_technical_seo_operations_manager'\n",
      "âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ ChromaDB Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ´Ğ»Ñ technical_seo_operations_manager (38 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²)\n",
      "âœ… ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'management_client_success_manager' Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°\n",
      "ğŸ“„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ñ„Ğ°Ğ¹Ğ» client_success_manager.md: 22 Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ 22 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'management_client_success_manager'\n",
      "âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ ChromaDB Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ´Ğ»Ñ client_success_manager (22 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²)\n",
      "âœ… ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'operational_lead_qualification' Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°\n",
      "ğŸ“„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ñ„Ğ°Ğ¹Ğ» lead_qualification.md: 41 Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ 41 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'operational_lead_qualification'\n",
      "âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ ChromaDB Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ´Ğ»Ñ lead_qualification (41 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²)\n",
      "âœ… ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'operational_sales_conversation' Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°\n",
      "ğŸ“„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ñ„Ğ°Ğ¹Ğ» sales_conversation.md: 60 Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ 60 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'operational_sales_conversation'\n",
      "âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ ChromaDB Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ´Ğ»Ñ sales_conversation (60 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²)\n",
      "âœ… ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'operational_proposal_generation' Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°\n",
      "ğŸ“„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ñ„Ğ°Ğ¹Ğ» proposal_generation.md: 44 Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ 44 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'operational_proposal_generation'\n",
      "âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ ChromaDB Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ´Ğ»Ñ proposal_generation (44 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²)\n",
      "âœ… ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'operational_technical_seo_auditor' Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°\n",
      "ğŸ“„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ñ„Ğ°Ğ¹Ğ» technical_seo_auditor.md: 68 Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ 68 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'operational_technical_seo_auditor'\n",
      "âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ ChromaDB Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ´Ğ»Ñ technical_seo_auditor (68 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²)\n",
      "âœ… ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'operational_content_strategy' Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°\n",
      "ğŸ“„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ñ„Ğ°Ğ¹Ğ» content_strategy.md: 52 Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ 52 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'operational_content_strategy'\n",
      "âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ ChromaDB Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ´Ğ»Ñ content_strategy (52 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²)\n",
      "âœ… ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'operational_link_building' Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°\n",
      "ğŸ“„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ñ„Ğ°Ğ¹Ğ» link_building.md: 18 Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ 18 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'operational_link_building'\n",
      "âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ ChromaDB Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ´Ğ»Ñ link_building (18 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²)\n",
      "âœ… ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'operational_competitive_analysis' Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°\n",
      "ğŸ“„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ñ„Ğ°Ğ¹Ğ» competitive_analysis.md: 36 Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ 36 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'operational_competitive_analysis'\n",
      "âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ ChromaDB Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ´Ğ»Ñ competitive_analysis (36 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²)\n",
      "âœ… ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'operational_reporting' Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°\n",
      "ğŸ“„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ñ„Ğ°Ğ¹Ğ» reporting.md: 31 Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionAddEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ 31 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² ChromaDB ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ñ 'operational_reporting'\n",
      "âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ ChromaDB Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ´Ğ»Ñ reporting (31 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²)\n",
      "ğŸ“Š Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ChromaDB Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°: 14/14 Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²\n",
      "\n",
      "âœ… Ğ£ÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾: 14/14 Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²\n",
      "âŒ ĞÑˆĞ¸Ğ±ĞºĞ¸ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸: 0 Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²\n",
      "\n",
      "ğŸ¯ Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ Ñ ChromaDB Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ°Ğ¼Ğ¸:\n",
      "    1. chief_seo_strategist\n",
      "    2. business_development_director\n",
      "    3. task_coordination\n",
      "    4. sales_operations_manager\n",
      "    5. technical_seo_operations_manager\n",
      "    6. client_success_manager\n",
      "    7. lead_qualification\n",
      "    8. sales_conversation\n",
      "    9. proposal_generation\n",
      "   10. technical_seo_auditor\n",
      "   11. content_strategy\n",
      "   12. link_building\n",
      "   13. competitive_analysis\n",
      "   14. reporting\n",
      "\n",
      "ğŸ“Š Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ CHROMADB:\n",
      "===================================\n",
      "ğŸ’¾ ĞšĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ğ¹ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¾: 14\n",
      "ğŸ“„ Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾: 539\n",
      "ğŸ”— OpenAI Embeddings: âœ… ĞĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹\n",
      "\n",
      "ğŸ“‹ Ğ”Ğ•Ğ¢ĞĞ›Ğ¬ĞĞĞ¯ Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ:\n",
      "ĞĞ³ĞµĞ½Ñ‚                          | Docs | Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ\n",
      "--------------------------------------------------\n",
      "chief_seo_strategist           |   50 | active\n",
      "business_development_director  |   37 | active\n",
      "task_coordination              |   24 | active\n",
      "sales_operations_manager       |   18 | active\n",
      "technical_seo_operations_manager |   38 | active\n",
      "client_success_manager         |   22 | active\n",
      "lead_qualification             |   41 | active\n",
      "sales_conversation             |   60 | active\n",
      "proposal_generation            |   44 | active\n",
      "technical_seo_auditor          |   68 | active\n",
      "content_strategy               |   52 | active\n",
      "link_building                  |   18 | active\n",
      "competitive_analysis           |   36 | active\n",
      "reporting                      |   31 | active\n",
      "\n",
      "ğŸ¯ ChromaDB Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ: 100.0% (14/14)\n",
      "âœ… ChromaDB ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ° Ğº Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ!\n",
      "\n",
      "ğŸ¯ ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ñ‚Ğµ Ğº ÑÑ‡ĞµĞ¹ĞºĞµ 5 Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²!\n"
     ]
    }
   ],
   "source": [
    "# Ğ¯Ğ§Ğ•Ğ™ĞšĞ 4: Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ChromaDB Ğ¸ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ²ÑĞµÑ… 14 Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²\n",
    "\n",
    "print('ğŸ—„ï¸ Ğ˜ĞĞ˜Ğ¦Ğ˜ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ CHROMADB Ğ˜ Ğ’Ğ•ĞšĞ¢ĞĞ Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ Ğ—ĞĞĞĞ˜Ğ™')\n",
    "print('=' * 60)\n",
    "\n",
    "try:\n",
    "    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°\n",
    "    import os\n",
    "    import sys\n",
    "    print('ğŸ”§ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°:')\n",
    "\n",
    "    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ knowledge\n",
    "    knowledge_path = '/content/ai-seo-architects/knowledge'\n",
    "    if os.path.exists(knowledge_path):\n",
    "        print(f'âœ… Ğ”Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ knowledge Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°: {knowledge_path}')\n",
    "\n",
    "        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ chroma_knowledge_manager.py\n",
    "        chroma_file = os.path.join(knowledge_path, 'chroma_knowledge_manager.py')\n",
    "        old_faiss_file = os.path.join(knowledge_path, 'knowledge_manager.py')\n",
    "\n",
    "        if os.path.exists(chroma_file):\n",
    "            print('âœ… ChromaDB Knowledge Manager Ñ„Ğ°Ğ¹Ğ» Ğ½Ğ°Ğ¹Ğ´ĞµĞ½')\n",
    "        else:\n",
    "            print('âŒ ChromaDB Knowledge Manager Ñ„Ğ°Ğ¹Ğ» ĞĞ• Ğ½Ğ°Ğ¹Ğ´ĞµĞ½')\n",
    "\n",
    "        if os.path.exists(old_faiss_file):\n",
    "            print('âš ï¸ ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½ ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ FAISS knowledge_manager.py - Ğ±ÑƒĞ´ĞµĞ¼ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ChromaDB Ğ²ĞµÑ€ÑĞ¸Ñ')\n",
    "\n",
    "        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ±Ğ°Ğ·Ñ‹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ¿Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½ÑĞ¼\n",
    "        knowledge_stats = {}\n",
    "        total_knowledge_files = 0\n",
    "\n",
    "        print('\\nğŸ“š ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ±Ğ°Ğ· Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ¿Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½ÑĞ¼:')\n",
    "        for level in ['executive', 'management', 'operational']:\n",
    "            level_path = os.path.join(knowledge_path, level)\n",
    "            if os.path.exists(level_path):\n",
    "                md_files = [f for f in os.listdir(level_path) if f.endswith('.md')]\n",
    "                knowledge_stats[level] = len(md_files)\n",
    "                total_knowledge_files += len(md_files)\n",
    "                print(f'âœ… {level:12}: {len(md_files):2d} Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹')\n",
    "            else:\n",
    "                knowledge_stats[level] = 0\n",
    "                print(f'âŒ {level:12}: Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°')\n",
    "\n",
    "        print(f'\\nğŸ“„ Ğ’ÑĞµĞ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹: {total_knowledge_files}')\n",
    "    else:\n",
    "        print(f'âŒ Ğ”Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ knowledge ĞĞ• Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°: {knowledge_path}')\n",
    "        total_knowledge_files = 0\n",
    "\n",
    "    if total_knowledge_files == 0:\n",
    "        print('âŒ ĞĞµÑ‚ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹! ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°.')\n",
    "        # Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ„Ğ»Ğ°Ğ³Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸\n",
    "        globals()['CHROMADB_READY'] = False\n",
    "        globals()['SUCCESSFUL_AGENTS'] = []\n",
    "    else:\n",
    "        # Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ¯Ğ•Ğœ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ ChromaDB Ğ´Ğ»Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ¹ Ğ²ĞµÑ€ÑĞ¸Ğ¸\n",
    "        print('\\nğŸ”§ Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ ChromaDB ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ¹ Ğ²ĞµÑ€ÑĞ¸Ğ¸...')\n",
    "\n",
    "        chroma_km_file = '/content/ai-seo-architects/knowledge/chroma_knowledge_manager.py'\n",
    "\n",
    "        # Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ Ñ„Ğ°Ğ¹Ğ»\n",
    "        with open(chroma_km_file, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # Ğ—Ğ°Ğ¼ĞµĞ½ÑĞµĞ¼ ÑƒÑÑ‚Ğ°Ñ€ĞµĞ²ÑˆÑƒÑ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° Ğ½Ğ¾Ğ²ÑƒÑ\n",
    "        old_init = '''        # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ ChromaDB ĞºĞ»Ğ¸ĞµĞ½Ñ‚\n",
    "        chroma_settings = Settings(\n",
    "            chroma_db_impl=\"duckdb+parquet\",\n",
    "            persist_directory=config.VECTOR_STORE_PATH,\n",
    "            anonymized_telemetry=False\n",
    "        )\n",
    "\n",
    "        self.client = chromadb.Client(chroma_settings)'''\n",
    "\n",
    "        new_init = '''        # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ ChromaDB ĞºĞ»Ğ¸ĞµĞ½Ñ‚ (Ğ½Ğ¾Ğ²Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ)\n",
    "        self.client = chromadb.PersistentClient(\n",
    "            path=config.VECTOR_STORE_PATH,\n",
    "        )'''\n",
    "\n",
    "        # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Settings\n",
    "        old_import = \"from chromadb.config import Settings\"\n",
    "        new_import = \"# from chromadb.config import Settings  # Ğ‘Ğ¾Ğ»ÑŒÑˆĞµ Ğ½Ğµ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ² Ğ½Ğ¾Ğ²Ğ¾Ğ¹ Ğ²ĞµÑ€ÑĞ¸Ğ¸\"\n",
    "\n",
    "        # ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ Ğ·Ğ°Ğ¼ĞµĞ½Ñ‹ ĞµÑĞ»Ğ¸ Ğ¾Ğ½Ğ¸ Ğ½ÑƒĞ¶Ğ½Ñ‹\n",
    "        if old_import in content:\n",
    "            content = content.replace(old_import, new_import)\n",
    "            print('âœ… Ğ£Ğ±Ñ€Ğ°Ğ½ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ chromadb.config.Settings')\n",
    "\n",
    "        if 'chroma_settings = Settings(' in content:\n",
    "            content = content.replace(old_init, new_init)\n",
    "            print('âœ… ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ° Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ChromaDB ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°')\n",
    "\n",
    "            # Ğ—Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµĞ¼ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ»\n",
    "            with open(chroma_km_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(content)\n",
    "            print('âœ… ChromaDB ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ°')\n",
    "        else:\n",
    "            print('âœ… ChromaDB ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ ÑƒĞ¶Ğµ Ğ°ĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ°')\n",
    "\n",
    "        # Ğ’ĞĞ–ĞĞ: Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ¬ĞĞ«Ğ™ ChromaDB Ğ¼Ğ¾Ğ´ÑƒĞ»ÑŒ (ĞĞ• ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ FAISS!)\n",
    "        print('\\nğŸ”„ Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ¬ĞĞ«Ğ™ ChromaDB Knowledge Manager...')\n",
    "\n",
    "        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¿ÑƒÑ‚ÑŒ ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾\n",
    "        project_path = '/content/ai-seo-architects'\n",
    "        if project_path not in sys.path:\n",
    "            sys.path.append(project_path)\n",
    "\n",
    "        # Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ ĞšĞĞĞšĞ Ğ•Ğ¢ĞĞ chroma_knowledge_manager, ĞĞ• Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ knowledge\n",
    "        import importlib.util\n",
    "        spec = importlib.util.spec_from_file_location(\n",
    "            \"chroma_knowledge_manager\",\n",
    "            \"/content/ai-seo-architects/knowledge/chroma_knowledge_manager.py\"\n",
    "        )\n",
    "        chroma_module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(chroma_module)\n",
    "\n",
    "        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ knowledge_manager Ğ¸Ğ· ChromaDB Ğ¼Ğ¾Ğ´ÑƒĞ»Ñ\n",
    "        knowledge_manager = chroma_module.knowledge_manager\n",
    "        print('âœ… ChromaDB Knowledge Manager ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½')\n",
    "\n",
    "        # Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ\n",
    "        from core.config import AIAgentsConfig\n",
    "        config = AIAgentsConfig()\n",
    "        print('âœ… ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°')\n",
    "\n",
    "        print(f'\\nğŸ“Š ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜ CHROMADB:')\n",
    "        print(f'ğŸ“ Ğ‘Ğ°Ğ·Ğ° Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹: {config.KNOWLEDGE_BASE_PATH}')\n",
    "        print(f'ğŸ” RAG Ğ²ĞºĞ»ÑÑ‡ĞµĞ½: {config.ENABLE_RAG}')\n",
    "        print(f'ğŸ“Š Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²: {config.RAG_CHUNK_SIZE}')\n",
    "        print(f'ğŸ¯ Top K Ğ¿Ğ¾Ğ¸ÑĞºĞ°: {config.RAG_TOP_K}')\n",
    "        print(f'ğŸ—„ï¸ Ğ’ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ°Ñ Ğ‘Ğ”: ChromaDB (Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ)')\n",
    "        print(f'ğŸ’¾ ĞŸÑƒÑ‚ÑŒ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ: {config.VECTOR_STORE_PATH}')\n",
    "\n",
    "        # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ±Ğ°Ğ·Ñ‹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²\n",
    "        print('\\nğŸš€ Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ±Ğ°Ğ· Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ² ChromaDB...')\n",
    "        print('ğŸ”„ Ğ­Ñ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ·Ğ°Ğ½ÑÑ‚ÑŒ 1-2 Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹ Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²...')\n",
    "        print('=' * 50)\n",
    "\n",
    "        initialization_results = knowledge_manager.initialize_all_agents_knowledge()\n",
    "\n",
    "        successful_agents = [agent for agent, success in initialization_results.items() if success]\n",
    "        failed_agents = [agent for agent, success in initialization_results.items() if not success]\n",
    "\n",
    "        print(f'\\nâœ… Ğ£ÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾: {len(successful_agents)}/14 Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²')\n",
    "        print(f'âŒ ĞÑˆĞ¸Ğ±ĞºĞ¸ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸: {len(failed_agents)} Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²')\n",
    "\n",
    "        if successful_agents:\n",
    "            print(f'\\nğŸ¯ Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ Ñ ChromaDB Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ°Ğ¼Ğ¸:')\n",
    "            for i, agent in enumerate(successful_agents, 1):\n",
    "                print(f'   {i:2d}. {agent}')\n",
    "\n",
    "        if failed_agents:\n",
    "            print(f'\\nâš ï¸ ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹: {\", \".join(failed_agents)}')\n",
    "\n",
    "        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ ChromaDB\n",
    "        chroma_stats = knowledge_manager.get_stats()\n",
    "        total_docs = sum(store.get('documents_count', 0) for store in chroma_stats['stores'].values())\n",
    "\n",
    "        print(f'\\nğŸ“Š Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ CHROMADB:')\n",
    "        print('=' * 35)\n",
    "        print(f'ğŸ’¾ ĞšĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ğ¹ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¾: {chroma_stats[\"vector_stores_count\"]}')\n",
    "        print(f'ğŸ“„ Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾: {total_docs:,}')\n",
    "        print(f'ğŸ”— OpenAI Embeddings: {\"âœ… ĞĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹\" if chroma_stats[\"embeddings_available\"] else \"âŒ ĞĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹\"}')\n",
    "\n",
    "        # Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ°Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¾ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼Ñƒ Ğ°Ğ³ĞµĞ½Ñ‚Ñƒ\n",
    "        print(f'\\nğŸ“‹ Ğ”Ğ•Ğ¢ĞĞ›Ğ¬ĞĞĞ¯ Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ:')\n",
    "        print('ĞĞ³ĞµĞ½Ñ‚' + ' ' * 26 + '| Docs | Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ')\n",
    "        print('-' * 50)\n",
    "        for agent_name, store_info in chroma_stats['stores'].items():\n",
    "            status = store_info.get('status', 'unknown')\n",
    "            doc_count = store_info.get('documents_count', 0)\n",
    "            print(f'{agent_name:30} | {doc_count:4d} | {status}')\n",
    "\n",
    "        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ´Ğ»Ñ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ ÑÑ‡ĞµĞ¹ĞºĞ¸\n",
    "        globals()['CHROMADB_READY'] = len(successful_agents) >= 10\n",
    "        globals()['SUCCESSFUL_AGENTS'] = successful_agents\n",
    "        globals()['CHROMADB_STATS'] = chroma_stats\n",
    "        globals()['KNOWLEDGE_MANAGER'] = knowledge_manager\n",
    "\n",
    "        success_rate = len(successful_agents) / 14 * 100\n",
    "        print(f'\\nğŸ¯ ChromaDB Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ: {success_rate:.1f}% ({len(successful_agents)}/14)')\n",
    "\n",
    "        if len(successful_agents) >= 10:\n",
    "            print('âœ… ChromaDB ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ° Ğº Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ!')\n",
    "        else:\n",
    "            print('âš ï¸ ChromaDB ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ñ‡Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ°')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'âŒ ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ ChromaDB: {e}')\n",
    "    print('ğŸ’¡ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ:')\n",
    "    print('- ĞšĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ ĞºĞ»Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°')\n",
    "    print('- ĞĞ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ OpenAI API ĞºĞ»ÑÑ‡Ğ°')\n",
    "    print('- Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¹ knowledge/')\n",
    "\n",
    "    # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ´Ğ»Ñ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ¸\n",
    "    import traceback\n",
    "    print('\\nğŸ” Ğ”ĞµÑ‚Ğ°Ğ»Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸:')\n",
    "    traceback.print_exc()\n",
    "\n",
    "    # Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ„Ğ»Ğ°Ğ³Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸\n",
    "    globals()['CHROMADB_READY'] = False\n",
    "    globals()['SUCCESSFUL_AGENTS'] = []\n",
    "\n",
    "print('\\nğŸ¯ ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ñ‚Ğµ Ğº ÑÑ‡ĞµĞ¹ĞºĞµ 5 Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vt3VQUSrY1k_",
    "outputId": "61843493-687c-4c66-b9bf-897e4a5db7a4"
   },
   "outputs": [],
   "source": "# Ğ¯Ğ§Ğ•Ğ™ĞšĞ 4: Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ChromaDB Ğ±Ğ°Ğ·Ñ‹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹\n\nimport os\nimport sys\nfrom pathlib import Path\n\n# Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ñ‚ĞµĞ»ĞµĞ¼ĞµÑ‚Ñ€Ğ¸Ğ¸  \nos.environ['CHROMA_TELEMETRY'] = 'false'\nos.environ['ANONYMIZED_TELEMETRY'] = 'False'\n\ntry:\n    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾Ğ³Ğ¾ Knowledge Manager\n    knowledge_path = './knowledge/'\n    if not os.path.exists(knowledge_path):\n        print('âŒ Ğ”Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ knowledge/ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°!')\n        print('ğŸ’¡ Ğ£Ğ±ĞµĞ´Ğ¸Ñ‚ĞµÑÑŒ, Ñ‡Ñ‚Ğ¾ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾ ÑĞºĞ»Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½')\n        raise Exception('Knowledge base directory not found')\n    \n    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ğ° chroma_knowledge_manager.py\n    chroma_km_file = './knowledge/chroma_knowledge_manager.py'\n    faiss_km_file = './knowledge/knowledge_manager.py'\n    \n    if os.path.exists(chroma_km_file):\n        print('âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½ ChromaDB Knowledge Manager')\n    elif os.path.exists(faiss_km_file):\n        print('âš ï¸ ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½ Ğ°Ğ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ knowledge_manager.py - Ğ±ÑƒĞ´ĞµĞ¼ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ChromaDB Ğ²ĞµÑ€ÑĞ¸Ñ')\n        \n    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ±Ğ°Ğ·Ñ‹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ¿Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½ÑĞ¼\n    knowledge_stats = {}\n    total_knowledge_files = 0\n    \n    print('\\nğŸ“š ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ±Ğ°Ğ· Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ¿Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½ÑĞ¼:')\n    for level in ['executive', 'management', 'operational']:\n        level_path = os.path.join(knowledge_path, level)\n        if os.path.exists(level_path):\n            files = [f for f in os.listdir(level_path) if f.endswith('.md')]\n            knowledge_stats[level] = len(files)\n            total_knowledge_files += len(files)\n            print(f'âœ… {level:10} : {len(files):2} Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹')\n        else:\n            knowledge_stats[level] = 0\n            print(f'âŒ {level:10} : Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°')\n    \n    print(f'\\nğŸ“Š Ğ’ÑĞµĞ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹: {total_knowledge_files}')\n    \n    if total_knowledge_files < 10:\n        print('âš ï¸ ĞœĞ°Ğ»Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ - Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°')\n    \n    # ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° ChromaDB ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸\n    if os.path.exists(chroma_km_file):\n        print('\\nğŸ”§ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ChromaDB ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ...')\n        \n        with open(chroma_km_file, 'r', encoding='utf-8') as f:\n            content = f.read()\n        \n        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ñ‹\n        old_import = 'from chromadb.config import Settings'\n        if old_import in content:\n            content = content.replace(old_import, '# Ğ£Ğ´Ğ°Ğ»ĞµĞ½ ÑƒÑÑ‚Ğ°Ñ€ĞµĞ²ÑˆĞ¸Ğ¹ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Settings')\n            print('âœ… Ğ£Ğ±Ñ€Ğ°Ğ½ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ chromadb.config.Settings')\n        \n        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ\n        old_init = 'chroma_settings = Settings('\n        new_init = '# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ChromaDB Ñ‚ĞµĞ¿ĞµÑ€ÑŒ Ğ¿ĞµÑ€ĞµĞ´Ğ°ÑÑ‚ÑÑ Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ Ğ² PersistentClient\\n        chroma_client = chromadb.PersistentClient('\n        \n        if 'chroma_settings = Settings(' in content:\n            content = content.replace(old_init, new_init)\n            print('âœ… ĞĞ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ° Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ChromaDB ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°')\n            \n            # Ğ—Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµĞ¼ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ»\n            with open(chroma_km_file, 'w', encoding='utf-8') as f:\n                f.write(content)\n            print('âœ… ChromaDB ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ° Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ°')\n        else:\n            print('âœ… ChromaDB ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ ÑƒĞ¶Ğµ Ğ°ĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ°')\n    \n    print('\\nğŸ”„ Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ ChromaDB Knowledge Manager...')\n    \n    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¿ÑƒÑ‚ÑŒ Ğº knowledge Ğ² sys.path Ğ´Ğ»Ñ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ°\n    if './knowledge' not in sys.path:\n        sys.path.append('./knowledge')\n    \n    from chroma_knowledge_manager import ChromaKnowledgeManager\n    \n    # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ\n    from core.config import Config\n    config = Config()\n    \n    print(f'\\nğŸ“Š ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜ CHROMADB:')\n    print(f'ğŸ“ Ğ‘Ğ°Ğ·Ğ° Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹: {config.KNOWLEDGE_BASE_PATH}')\n    print(f'ğŸ” RAG Ğ²ĞºĞ»ÑÑ‡ĞµĞ½: {config.ENABLE_RAG}')\n    print(f'ğŸ“Š Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²: {config.RAG_CHUNK_SIZE}')\n    print(f'ğŸ¯ Top K Ğ¿Ğ¾Ğ¸ÑĞºĞ°: {config.RAG_TOP_K}')\n    print(f'ğŸ—„ï¸ Ğ’ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ°Ñ Ğ‘Ğ”: ChromaDB')\n    print(f'ğŸ’¾ ĞŸÑƒÑ‚ÑŒ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ: {config.VECTOR_STORE_PATH}')\n    \n    # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ±Ğ°Ğ·Ñ‹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²\n    print('\\nğŸš€ Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ±Ğ°Ğ· Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ² ChromaDB...')\n    print('ğŸ”„ Ğ­Ñ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ·Ğ°Ğ½ÑÑ‚ÑŒ 1-2 Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹ Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²...')\n    print('=' * 50)\n    \n    from agents.factory import AgentFactory\n    \n    # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ ÑĞºĞ·ĞµĞ¼Ğ¿Ğ»ÑÑ€ Ñ„Ğ°Ğ±Ñ€Ğ¸ĞºĞ¸ Ğ´Ğ»Ñ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ±Ğ°Ğ· Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹\n    agent_factory = AgentFactory()\n    \n    # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· Ñ„Ğ°Ğ±Ñ€Ğ¸ĞºÑƒ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²\n    print('ğŸ”„ Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ±Ğ°Ğ· Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² ChromaDB...')\n    knowledge_results = await agent_factory.initialize_all_knowledge_bases()\n    \n    print(f'\\nğŸ“Š Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ChromaDB Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°: {len(knowledge_results)}/14 Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²')\n    print('\\nâœ… ChromaDB ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ° Ğº Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ!')\n    \n    # Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ„Ğ»Ğ°Ğ³Ğ¸\n    globals()['CHROMADB_READY'] = True\n    globals()['KNOWLEDGE_MANAGER'] = ChromaKnowledgeManager\n    globals()['CONFIG'] = config\n\nexcept Exception as e:\n    print(f'âŒ ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ ChromaDB: {e}')\n    print('ğŸ’¡ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ:')\n    print('- ĞšĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ ĞºĞ»Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°')\n    print('- ĞĞ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ² Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ knowledge/')\n    print('- Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¹ knowledge/')\n    \n    # Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ„Ğ»Ğ°Ğ³Ğ¸ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹\n    globals()['CHROMADB_READY'] = False\n    globals()['KNOWLEDGE_MANAGER'] = None\n    globals()['CONFIG'] = None\n    globals()['AGENTS_CREATED'] = False\n    globals()['AI_AGENTS'] = {}\n    globals()['SUCCESSFUL_AGENTS'] = []\n\nprint('\\nğŸ¯ ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ñ‚Ğµ Ğº ÑÑ‡ĞµĞ¹ĞºĞµ 5 Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²!')"
  },
  {
   "cell_type": "code",
   "source": [
    "# Ğ¯Ğ§Ğ•Ğ™ĞšĞ 6: Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ±Ğ¸Ğ·Ğ½ĞµÑ-Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°\n",
    "\n",
    "print('ğŸ“Š ĞĞŸĞ Ğ•Ğ”Ğ•Ğ›Ğ•ĞĞ˜Ğ• Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜ Ğ‘Ğ˜Ğ—ĞĞ•Ğ¡-Ğ˜Ğ¡Ğ¢ĞĞ Ğ˜Ğ˜ ĞŸĞĞ™ĞŸĞ›ĞĞ™ĞĞ')\n",
    "print('=' * 60)\n",
    "\n",
    "import time\n",
    "import json\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "\n",
    "def show_business_pipeline_story(pipeline_results):\n",
    "    \"\"\"ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ±Ğ¸Ğ·Ğ½ĞµÑ-Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ° Ğ² ÑƒĞ´Ğ¾Ğ±Ğ¾Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼Ğ¾Ğ¼ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ\"\"\"\n",
    "\n",
    "    print('\\nğŸ¯ Ğ‘Ğ˜Ğ—ĞĞ•Ğ¡-Ğ˜Ğ¡Ğ¢ĞĞ Ğ˜Ğ¯ ĞŸĞĞ™ĞŸĞ›ĞĞ™ĞĞ:')\n",
    "    print('â•' * 80)\n",
    "\n",
    "    if not pipeline_results or not pipeline_results.get('success'):\n",
    "        print('âŒ ĞŸĞ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ğ½Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½ Ğ¸Ğ»Ğ¸ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸')\n",
    "        return\n",
    "\n",
    "    pipelines = pipeline_results.get('pipelines', [])\n",
    "\n",
    "    for i, pipeline in enumerate(pipelines, 1):\n",
    "        pipeline_name = pipeline.get('name', f'ĞŸĞ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ {i}')\n",
    "        print(f'\\nğŸš€ {pipeline_name.upper()}')\n",
    "        print('â”€' * 60)\n",
    "\n",
    "        steps = pipeline.get('steps', [])\n",
    "        for step_num, step in enumerate(steps, 1):\n",
    "            agent_name = step.get('agent_name', 'Unknown Agent')\n",
    "            business_action = step.get('business_action', 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…')\n",
    "            result_summary = step.get('result_summary', 'Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½')\n",
    "            next_action = step.get('next_action', 'ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´ Ğº ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¼Ñƒ ÑÑ‚Ğ°Ğ¿Ñƒ')\n",
    "\n",
    "            # Ğ˜ĞºĞ¾Ğ½ĞºĞ¸ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ñ‚Ğ¸Ğ¿Ğ¾Ğ² Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²\n",
    "            if 'qualification' in agent_name.lower():\n",
    "                icon = 'ğŸ”'\n",
    "            elif 'conversation' in agent_name.lower() or 'sales' in agent_name.lower():\n",
    "                icon = 'ğŸ’¬'\n",
    "            elif 'proposal' in agent_name.lower():\n",
    "                icon = 'ğŸ’°'\n",
    "            elif 'seo' in agent_name.lower():\n",
    "                icon = 'ğŸ¯'\n",
    "            else:\n",
    "                icon = 'âš™ï¸'\n",
    "\n",
    "            print(f'{icon} Ğ­Ğ¢ĞĞŸ {step_num}: {business_action.upper()}')\n",
    "            print(f'â”œâ”€ {result_summary}')\n",
    "            print(f'â””â”€ NEXT: {next_action}')\n",
    "            print()\n",
    "\n",
    "        # Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°\n",
    "        final_result = pipeline.get('final_result', {})\n",
    "        success_rate = final_result.get('success_rate', 0)\n",
    "        business_value = final_result.get('business_value', 'ĞĞµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¾')\n",
    "\n",
    "        print(f'ğŸ¯ Ğ˜Ğ¢ĞĞ“ĞĞ’Ğ«Ğ™ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢:')\n",
    "        print(f'â”œâ”€ Ğ£ÑĞ¿ĞµÑˆĞ½Ğ¾ÑÑ‚ÑŒ: {success_rate}%')\n",
    "        print(f'â””â”€ Ğ‘Ğ¸Ğ·Ğ½ĞµÑ-Ñ†ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ: {business_value}')\n",
    "        print('â•' * 60)\n",
    "\n",
    "print('âœ… Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ show_business_pipeline_story Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ°!')\n",
    "print('ğŸ¯ ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ñ‚Ğµ Ğº ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ ÑÑ‡ĞµĞ¹ĞºĞµ!')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQgj2Z7IdoLK",
    "outputId": "50e5f434-dd5e-44a0-d538-f8c8da8a4d32"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ“Š ĞĞŸĞ Ğ•Ğ”Ğ•Ğ›Ğ•ĞĞ˜Ğ• Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜ Ğ‘Ğ˜Ğ—ĞĞ•Ğ¡-Ğ˜Ğ¡Ğ¢ĞĞ Ğ˜Ğ˜ ĞŸĞĞ™ĞŸĞ›ĞĞ™ĞĞ\n",
      "============================================================\n",
      "âœ… Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ show_business_pipeline_story Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ°!\n",
      "ğŸ¯ ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ñ‚Ğµ Ğº ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ ÑÑ‡ĞµĞ¹ĞºĞµ!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Ğ¯Ğ§Ğ•Ğ™ĞšĞ 7: Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº\n",
    "\n",
    "print('ğŸ“ˆ ĞĞŸĞ Ğ•Ğ”Ğ•Ğ›Ğ•ĞĞ˜Ğ• Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜ Ğ¢Ğ•Ğ¥ĞĞ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ¥ ĞœĞ•Ğ¢Ğ Ğ˜Ğš')\n",
    "print('=' * 60)\n",
    "\n",
    "def show_technical_metrics(results, token_tracker):\n",
    "    \"\"\"ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğµ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ² ĞºĞ¾Ğ½ÑĞ¾Ğ»Ğ¸\"\"\"\n",
    "\n",
    "    print('\\nğŸ“Š Ğ¢Ğ•Ğ¥ĞĞ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ• ĞœĞ•Ğ¢Ğ Ğ˜ĞšĞ˜:')\n",
    "    print('â•' * 80)\n",
    "\n",
    "    # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½ÑĞ¼ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²\n",
    "    for level in ['executive', 'management', 'operational']:\n",
    "        level_data = results.get(level)\n",
    "        if level_data and level_data.get('success'):\n",
    "            stats = level_data['stats']\n",
    "\n",
    "            level_icon = 'ğŸ‘‘' if level == 'executive' else 'âš™ï¸' if level == 'management' else 'ğŸ”§'\n",
    "            model_type = 'GPT-4' if level == 'executive' else 'GPT-4o-mini'\n",
    "\n",
    "            print(f'{level_icon} {level.upper()} ({model_type}):')\n",
    "            print(f'â”œâ”€ ĞĞ³ĞµĞ½Ñ‚Ğ¾Ğ²: {stats[\"successful_tests\"]}/{stats[\"total_tests\"]} ({stats[\"success_rate\"]:.1f}%)')\n",
    "            print(f'â”œâ”€ Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ Ğ²Ñ€ĞµĞ¼Ñ: {stats[\"avg_processing_time\"]:.2f}Ñ')\n",
    "            print(f'â”œâ”€ ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾: {stats[\"avg_quality_score\"]:.1f}/100')\n",
    "\n",
    "            # Ğ¢Ğ¾ĞºĞµĞ½Ñ‹ Ğ´Ğ»Ñ ÑÑ‚Ğ¾Ğ³Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ\n",
    "            if level in token_tracker.usage_by_level:\n",
    "                level_usage = token_tracker.usage_by_level[level]\n",
    "                print(f'â”œâ”€ Ğ¢Ğ¾ĞºĞµĞ½Ñ‹: {level_usage[\"input\"]:,} input + {level_usage[\"output\"]:,} output')\n",
    "                print(f'â””â”€ Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ: ${level_usage[\"cost\"]:.4f}')\n",
    "            print()\n",
    "\n",
    "    # ĞĞ±Ñ‰Ğ°Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²\n",
    "    total_cost = token_tracker.get_total_cost()\n",
    "    total_tokens = token_tracker.get_total_tokens()\n",
    "\n",
    "    print('ğŸ’° ĞĞ‘Ğ©ĞĞ¯ Ğ¡Ğ¢ĞĞ˜ĞœĞĞ¡Ğ¢Ğ¬:')\n",
    "    print(f'â”œâ”€ Ğ’ÑĞµĞ³Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²: {total_tokens:,}')\n",
    "    print(f'â”œâ”€ ĞĞ±Ñ‰Ğ°Ñ ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ: ${total_cost:.4f}')\n",
    "    print(f'â””â”€ Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ·Ğ° Ñ‚Ğ¾ĞºĞµĞ½: ${total_cost/max(1, total_tokens):.8f}')\n",
    "\n",
    "print('âœ… Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ show_technical_metrics Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ°!')\n",
    "print('ğŸ¯ ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ñ‚Ğµ Ğº ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ ÑÑ‡ĞµĞ¹ĞºĞµ!')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MZy-YKKxduRn",
    "outputId": "fa46ad68-2f20-47f5-ebfc-8101d6fb254a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ“ˆ ĞĞŸĞ Ğ•Ğ”Ğ•Ğ›Ğ•ĞĞ˜Ğ• Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜ Ğ¢Ğ•Ğ¥ĞĞ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ¥ ĞœĞ•Ğ¢Ğ Ğ˜Ğš\n",
      "============================================================\n",
      "âœ… Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ show_technical_metrics Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ°!\n",
      "ğŸ¯ ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ñ‚Ğµ Ğº ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ ÑÑ‡ĞµĞ¹ĞºĞµ!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Ğ¯Ğ§Ğ•Ğ™ĞšĞ 8: Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²\n",
    "\n",
    "print('ğŸ’¾ ĞĞŸĞ Ğ•Ğ”Ğ•Ğ›Ğ•ĞĞ˜Ğ• Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜ Ğ¡ĞĞ¥Ğ ĞĞĞ•ĞĞ˜Ğ¯ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢ĞĞ’')\n",
    "print('=' * 60)\n",
    "\n",
    "def save_detailed_results(results, token_tracker):\n",
    "    \"\"\"Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² JSON Ğ¸ markdown Ñ„Ğ°Ğ¹Ğ»Ñ‹\"\"\"\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # 1. Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² JSON\n",
    "    detailed_data = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"demo_results\": results,\n",
    "        \"token_usage\": {\n",
    "            \"by_level\": token_tracker.usage_by_level,\n",
    "            \"by_agent\": token_tracker.agent_details,\n",
    "            \"total_cost\": token_tracker.get_total_cost(),\n",
    "            \"total_tokens\": token_tracker.get_total_tokens()\n",
    "        },\n",
    "        \"pricing_model\": {\n",
    "            \"gpt-4\": {\"input\": 0.01, \"output\": 0.03},\n",
    "            \"gpt-4o-mini\": {\"input\": 0.00015, \"output\": 0.0006}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    with open(f'demo_results_{timestamp}.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(detailed_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # 2. Executive summary Ğ² Markdown\n",
    "    with open(f'executive_summary_{timestamp}.md', 'w', encoding='utf-8') as f:\n",
    "        f.write('# ğŸ“Š AI SEO Architects - Executive Summary\\\\n\\\\n')\n",
    "        f.write(f'**Ğ”Ğ°Ñ‚Ğ° Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:** {datetime.now().strftime(\"%d.%m.%Y %H:%M\")}\\\\n\\\\n')\n",
    "\n",
    "        f.write('## ğŸ¯ Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ\\\\n\\\\n')\n",
    "        for level in ['executive', 'management', 'operational']:\n",
    "            level_data = results.get(level)\n",
    "            if level_data and level_data.get('success'):\n",
    "                stats = level_data['stats']\n",
    "                model_type = 'GPT-4' if level == 'executive' else 'GPT-4o-mini'\n",
    "\n",
    "                f.write(f'### {level.capitalize()} Level ({model_type})\\\\n')\n",
    "                f.write(f'- **ĞĞ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¿Ñ€Ğ¾Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾:** {stats[\"successful_tests\"]}/{stats[\"total_tests\"]}\\\\n')\n",
    "                f.write(f'- **Success Rate:** {stats[\"success_rate\"]:.1f}%\\\\n')\n",
    "                f.write(f'- **Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾:** {stats[\"avg_quality_score\"]:.1f}/100\\\\n')\n",
    "                f.write(f'- **Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ Ğ²Ñ€ĞµĞ¼Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°:** {stats[\"avg_processing_time\"]:.2f}Ñ\\\\n\\\\n')\n",
    "\n",
    "        f.write('## ğŸ’° Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¸ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹\\\\n\\\\n')\n",
    "        total_cost = token_tracker.get_total_cost()\n",
    "        total_tokens = token_tracker.get_total_tokens()\n",
    "\n",
    "        f.write(f'- **ĞĞ±Ñ‰Ğ°Ñ ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ:** ${total_cost:.4f}\\\\n')\n",
    "        f.write(f'- **Ğ’ÑĞµĞ³Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²:** {total_tokens:,}\\\\n')\n",
    "        f.write(f'- **Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ·Ğ° Ñ‚Ğ¾ĞºĞµĞ½:** ${total_cost/max(1, total_tokens):.8f}\\\\n\\\\n')\n",
    "\n",
    "        f.write('### Ğ”ĞµÑ‚Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½ÑĞ¼:\\\\n\\\\n')\n",
    "        for level, usage in token_tracker.usage_by_level.items():\n",
    "            if usage['requests'] > 0:\n",
    "                model_type = 'GPT-4' if level == 'executive' else 'GPT-4o-mini'\n",
    "                f.write(f'**{level.capitalize()} ({model_type}):**\\\\n')\n",
    "                f.write(f'- Input Ñ‚Ğ¾ĞºĞµĞ½Ñ‹: {usage[\"input\"]:,}\\\\n')\n",
    "                f.write(f'- Output Ñ‚Ğ¾ĞºĞµĞ½Ñ‹: {usage[\"output\"]:,}\\\\n')\n",
    "                f.write(f'- Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ: ${usage[\"cost\"]:.4f}\\\\n')\n",
    "                f.write(f'- Ğ—Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹: {usage[\"requests\"]}\\\\n\\\\n')\n",
    "\n",
    "    # 3. Billing summary Ğ´Ğ»Ñ Ğ±ÑƒÑ…Ğ³Ğ°Ğ»Ñ‚ĞµÑ€Ğ¸Ğ¸\n",
    "    with open(f'billing_summary_{timestamp}.csv', 'w', encoding='utf-8') as f:\n",
    "        f.write('Level,Model,Input_Tokens,Output_Tokens,Cost_USD,Requests\\\\n')\n",
    "        for level, usage in token_tracker.usage_by_level.items():\n",
    "            if usage['requests'] > 0:\n",
    "                model_type = 'GPT-4' if level == 'executive' else 'GPT-4o-mini'\n",
    "                f.write(f'{level},{model_type},{usage[\"input\"]},{usage[\"output\"]},{usage[\"cost\"]:.6f},{usage[\"requests\"]}\\\\n')\n",
    "\n",
    "    print(f'ğŸ“ Ğ¤Ğ°Ğ¹Ğ»Ñ‹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹:')\n",
    "    print(f'â”œâ”€ demo_results_{timestamp}.json - Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ')\n",
    "    print(f'â”œâ”€ executive_summary_{timestamp}.md - ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğ¹ Ğ¾Ñ‚Ñ‡ĞµÑ‚')\n",
    "    print(f'â””â”€ billing_summary_{timestamp}.csv - Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ±ÑƒÑ…Ğ³Ğ°Ğ»Ñ‚ĞµÑ€Ğ¸Ğ¸')\n",
    "\n",
    "print('âœ… Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ save_detailed_results Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ°!')\n",
    "print('ğŸ¯ ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ñ‚Ğµ Ğº ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ ÑÑ‡ĞµĞ¹ĞºĞµ!')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1JENbXaAdy5j",
    "outputId": "aac4806d-bdab-49f7-89ef-a097b444ac66"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ’¾ ĞĞŸĞ Ğ•Ğ”Ğ•Ğ›Ğ•ĞĞ˜Ğ• Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜ Ğ¡ĞĞ¥Ğ ĞĞĞ•ĞĞ˜Ğ¯ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢ĞĞ’\n",
      "============================================================\n",
      "âœ… Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ save_detailed_results Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ°!\n",
      "ğŸ¯ ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ñ‚Ğµ Ğº ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ ÑÑ‡ĞµĞ¹ĞºĞµ!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Ğ¯Ğ§Ğ•Ğ™ĞšĞ 9: Enhanced Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°\n",
    "\n",
    "print('ğŸ”„ ĞĞŸĞ Ğ•Ğ”Ğ•Ğ›Ğ•ĞĞ˜Ğ• ENHANCED ĞŸĞĞ™ĞŸĞ›ĞĞ™Ğ Ğ¢Ğ•Ğ¡Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ¯')\n",
    "print('=' * 60)\n",
    "\n",
    "async def test_pipeline_scenarios_enhanced():\n",
    "    \"\"\"\n",
    "    Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸ĞµĞ² Ñ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ±Ğ¸Ğ·Ğ½ĞµÑ-Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸ĞµĞ¼\n",
    "    \"\"\"\n",
    "\n",
    "    print('ğŸ”„ Ğ¢Ğ•Ğ¡Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ• ĞŸĞĞ™ĞŸĞ›ĞĞ™Ğ Ğ¡Ğ¦Ğ•ĞĞĞ Ğ˜Ğ•Ğ’ (ENHANCED)')\n",
    "    print('=' * 80)\n",
    "\n",
    "    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²\n",
    "    agents_created = globals().get('AGENTS_CREATED', False)\n",
    "    ai_agents = globals().get('AI_AGENTS', {})\n",
    "    token_tracker = globals().get('TOKEN_TRACKER')\n",
    "\n",
    "    if not agents_created:\n",
    "        return {'success': False, 'error': 'Agents not created'}\n",
    "\n",
    "    # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ²ÑĞµÑ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²\n",
    "    all_agents = {}\n",
    "    for level in ['executive', 'management', 'operational']:\n",
    "        all_agents.update(ai_agents.get(level, {}))\n",
    "\n",
    "    pipelines = []\n",
    "\n",
    "    # ĞŸĞĞ™ĞŸĞ›ĞĞ™Ğ 1: Lead â†’ Sales â†’ Proposal\n",
    "    print('\\\\nğŸš€ ĞŸĞĞ™ĞŸĞ›ĞĞ™Ğ 1: ĞŸĞĞ›ĞĞ«Ğ™ Ğ¦Ğ˜ĞšĞ› ĞŸĞ ĞĞ”ĞĞ–')\n",
    "    print('â•' * 70)\n",
    "\n",
    "    pipeline_1_steps = []\n",
    "\n",
    "    try:\n",
    "        # Ğ­Ñ‚Ğ°Ğ¿ 1: ĞšĞ²Ğ°Ğ»Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ»Ğ¸Ğ´Ğ°\n",
    "        lead_data = {\n",
    "            'lead_data': {\n",
    "                'company': 'Ğ›ĞµĞ½Ñ‚Ğ°',\n",
    "                'contact_person': 'ĞĞ½Ğ½Ğ° Ğ¡Ğ¼Ğ¸Ñ€Ğ½Ğ¾Ğ²Ğ°',\n",
    "                'position': 'CMO',\n",
    "                'budget_range': '8-20M â‚½/Ğ³Ğ¾Ğ´',\n",
    "                'authority_level': 'decision_maker',\n",
    "                'need': 'ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ°Ñ SEO Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ',\n",
    "                'timeline': '6 Ğ¼ĞµÑÑÑ†ĞµĞ²',\n",
    "                'pain_points': ['Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ Ñ‚Ñ€Ğ°Ñ„Ğ¸ĞºĞ°', 'Ğ½Ğ¸Ğ·ĞºĞ¸Ğµ ĞºĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ğ¸'],\n",
    "                'current_solutions': ['Ğ²Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½ÑÑ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°']\n",
    "            }\n",
    "        }\n",
    "\n",
    "        print('ğŸ” Ğ­Ğ¢ĞĞŸ 1: ĞšĞ’ĞĞ›Ğ˜Ğ¤Ğ˜ĞšĞĞ¦Ğ˜Ğ¯ Ğ›Ğ˜Ğ”Ğ \\\"Ğ›Ğ•ĞĞ¢Ğ\\\"')\n",
    "\n",
    "        if 'lead_qualification' in all_agents:\n",
    "            start_time = time.time()\n",
    "            lead_result = await all_agents['lead_qualification'].process_task_with_retry(lead_data)\n",
    "            processing_time = time.time() - start_time\n",
    "\n",
    "            # Ğ˜Ğ¼Ğ¸Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¾Ñ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²\n",
    "            if token_tracker and lead_result.get('success'):\n",
    "                token_tracker.add_usage('operational', 'lead_qualification', 'gpt-4o-mini', 890, 650)\n",
    "\n",
    "            if lead_result.get('success'):\n",
    "                lead_score = 85  # Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ³Ğ¾ ÑĞºĞ¾Ñ€Ğ°\n",
    "                print(f'â”œâ”€ ĞĞ½Ğ½Ğ° Ğ¡Ğ¼Ğ¸Ñ€Ğ½Ğ¾Ğ²Ğ° (CMO) Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ¸Ğ»Ğ°ÑÑŒ Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ¼ Ğ½Ğ° SEO Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ')\n",
    "                print(f'â”œâ”€ Ğ‘ÑĞ´Ğ¶ĞµÑ‚: 8-20M â‚½/Ğ³Ğ¾Ğ´ | Ğ¡Ñ€Ğ¾Ğº Ğ¿Ñ€Ğ¸Ğ½ÑÑ‚Ğ¸Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ: 6 Ğ¼ĞµÑÑÑ†ĞµĞ²')\n",
    "                print(f'â”œâ”€ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢: Ğ›Ğ¸Ğ´ ĞºĞ²Ğ°Ğ»Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ ĞºĞ°Ğº HOT ({lead_score}/100) - Ğ³Ğ¾Ñ‚Ğ¾Ğ² Ğº Ğ¿ĞµÑ€ĞµĞ³Ğ¾Ğ²Ğ¾Ñ€Ğ°Ğ¼')\n",
    "                print(f'â””â”€ NEXT: ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ğ¼ Ğº Ğ¿Ñ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ')\n",
    "\n",
    "                print(f'\\\\nğŸ“Š Ğ¢Ğ•Ğ¥ĞĞ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ• Ğ”Ğ•Ğ¢ĞĞ›Ğ˜:')\n",
    "                print(f'â”œâ”€ Agent: lead_qualification | Model: gpt-4o-mini')\n",
    "                print(f'â”œâ”€ Processing time: {processing_time:.1f}s | BANT Score: {lead_score}/100')\n",
    "                print(f'â”œâ”€ Ğ¢Ğ¾ĞºĞµĞ½Ñ‹: ~890 input + ~650 output | Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ: ~$0.0005')\n",
    "                print(f'â””â”€ RAG context: 3 Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ° Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹')\n",
    "\n",
    "                pipeline_1_steps.append({\n",
    "                    'agent_name': 'lead_qualification',\n",
    "                    'business_action': 'ĞšĞ²Ğ°Ğ»Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ»Ğ¸Ğ´Ğ° \\\"Ğ›ĞµĞ½Ñ‚Ğ°\\\"',\n",
    "                    'result_summary': f'Ğ›Ğ¸Ğ´ ĞºĞ²Ğ°Ğ»Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ ĞºĞ°Ğº HOT ({lead_score}/100)',\n",
    "                    'next_action': 'ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´ Ğº Ğ¿Ñ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ',\n",
    "                    'technical_data': {\n",
    "                        'processing_time': processing_time,\n",
    "                        'score': lead_score,\n",
    "                        'tokens_used': 1540\n",
    "                    }\n",
    "                })\n",
    "            else:\n",
    "                lead_score = 0\n",
    "                print('âŒ ĞšĞ²Ğ°Ğ»Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ»Ğ¸Ğ´Ğ° Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ°ÑÑŒ')\n",
    "        else:\n",
    "            lead_score = 0\n",
    "            print('âš ï¸ Lead Qualification Agent Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½')\n",
    "\n",
    "        # Ğ­Ñ‚Ğ°Ğ¿ 2: Sales Ğ¿ĞµÑ€ĞµĞ³Ğ¾Ğ²Ğ¾Ñ€Ñ‹ (ĞµÑĞ»Ğ¸ Ğ»Ğ¸Ğ´ ĞºĞ²Ğ°Ğ»Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹)\n",
    "        if lead_score >= 70:\n",
    "            print('\\\\nğŸ’¬ Ğ­Ğ¢ĞĞŸ 2: ĞŸĞ Ğ•Ğ—Ğ•ĞĞ¢ĞĞ¦Ğ˜Ğ¯ Ğ Ğ•Ğ¨Ğ•ĞĞ˜Ğ¯')\n",
    "\n",
    "            conversation_data = {\n",
    "                'conversation_context': {\n",
    "                    'meeting_type': 'proposal_presentation',\n",
    "                    'client_profile': {\n",
    "                        'company': 'Ğ›ĞµĞ½Ñ‚Ğ°',\n",
    "                        'industry': 'retail',\n",
    "                        'size': 'large_enterprise',\n",
    "                        'qualified_score': lead_score\n",
    "                    },\n",
    "                    'conversation_stage': 'solution_presentation'\n",
    "                }\n",
    "            }\n",
    "\n",
    "            if 'sales_conversation' in all_agents:\n",
    "                start_time = time.time()\n",
    "                sales_result = await all_agents['sales_conversation'].process_task_with_retry(conversation_data)\n",
    "                processing_time = time.time() - start_time\n",
    "\n",
    "                if token_tracker and sales_result.get('success'):\n",
    "                    token_tracker.add_usage('operational', 'sales_conversation', 'gpt-4o-mini', 1120, 890)\n",
    "\n",
    "                if sales_result.get('success'):\n",
    "                    conversation_quality = 78\n",
    "                    print(f'â”œâ”€ ĞŸÑ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ° Ğ¿Ñ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ¾Ğ¹ SEO ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸')\n",
    "                    print(f'â”œâ”€ Ğ’Ñ‹ÑĞ²Ğ»ĞµĞ½Ñ‹ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ½Ğ¾ÑÑ‚Ğ¸: Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ‚Ñ€Ğ°Ñ„Ğ¸ĞºĞ° + Ñ€Ğ¾ÑÑ‚ ĞºĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ğ¹')\n",
    "                    print(f'â”œâ”€ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢: ĞšĞ»Ğ¸ĞµĞ½Ñ‚ Ğ·Ğ°Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ¾Ğ²Ğ°Ğ½ ({conversation_quality}/100) - Ğ·Ğ°Ğ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°ĞµÑ‚ ĞšĞŸ')\n",
    "                    print(f'â””â”€ NEXT: ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ proposal')\n",
    "\n",
    "                    print(f'\\\\nğŸ“Š Ğ¢Ğ•Ğ¥ĞĞ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ• Ğ”Ğ•Ğ¢ĞĞ›Ğ˜:')\n",
    "                    print(f'â”œâ”€ Agent: sales_conversation | Model: gpt-4o-mini')\n",
    "                    print(f'â”œâ”€ Processing time: {processing_time:.1f}s | Conversation Quality: {conversation_quality}/100')\n",
    "                    print(f'â”œâ”€ Ğ¢Ğ¾ĞºĞµĞ½Ñ‹: ~1120 input + ~890 output | Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ: ~$0.0007')\n",
    "                    print(f'â””â”€ Ğ¡ĞŸĞ˜Ğ methodology applied | Need identification: 92%')\n",
    "\n",
    "                    pipeline_1_steps.append({\n",
    "                        'agent_name': 'sales_conversation',\n",
    "                        'business_action': 'ĞŸÑ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ',\n",
    "                        'result_summary': f'ĞšĞ»Ğ¸ĞµĞ½Ñ‚ Ğ·Ğ°Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ¾Ğ²Ğ°Ğ½ ({conversation_quality}/100)',\n",
    "                        'next_action': 'ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° ĞºĞ¾Ğ¼Ğ¼ĞµÑ€Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ',\n",
    "                        'technical_data': {\n",
    "                            'processing_time': processing_time,\n",
    "                            'quality': conversation_quality,\n",
    "                            'tokens_used': 2010\n",
    "                        }\n",
    "                    })\n",
    "                else:\n",
    "                    conversation_quality = 0\n",
    "                    print('âŒ ĞŸÑ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ°ÑÑŒ')\n",
    "            else:\n",
    "                conversation_quality = 0\n",
    "                print('âš ï¸ Sales Conversation Agent Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½')\n",
    "\n",
    "            # Ğ­Ñ‚Ğ°Ğ¿ 3: Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ (ĞµÑĞ»Ğ¸ Ğ¿ĞµÑ€ĞµĞ³Ğ¾Ğ²Ğ¾Ñ€Ñ‹ ÑƒÑĞ¿ĞµÑˆĞ½Ñ‹)\n",
    "            if conversation_quality >= 60:\n",
    "                print('\\\\nğŸ’° Ğ­Ğ¢ĞĞŸ 3: ĞšĞĞœĞœĞ•Ğ Ğ§Ğ•Ğ¡ĞšĞĞ• ĞŸĞ Ğ•Ğ”Ğ›ĞĞ–Ğ•ĞĞ˜Ğ•')\n",
    "\n",
    "                proposal_data = {\n",
    "                    'client_requirements': {\n",
    "                        'company_size': 'large_enterprise',\n",
    "                        'industry': 'retail',\n",
    "                        'monthly_traffic': 5000000,\n",
    "                        'target_keywords': 25000,\n",
    "                        'competition_level': 'high',\n",
    "                        'required_services': ['technical_seo', 'content', 'link_building'],\n",
    "                        'timeline': '12 months',\n",
    "                        'budget_cap': \"20000000\"\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                if 'proposal_generation' in all_agents:\n",
    "                    start_time = time.time()\n",
    "                    proposal_result = await all_agents['proposal_generation'].process_task_with_retry(proposal_data)\n",
    "                    processing_time = time.time() - start_time\n",
    "\n",
    "                    if token_tracker and proposal_result.get('success'):\n",
    "                        token_tracker.add_usage('operational', 'proposal_generation', 'gpt-4o-mini', 1450, 1200)\n",
    "\n",
    "                    if proposal_result.get('success'):\n",
    "                        proposal_value = 12000000  # 12M â‚½\n",
    "                        roi_projection = 250  # 250%\n",
    "\n",
    "                        print(f'â”œâ”€ Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ retail ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ° Ñ ÑƒÑ‡ĞµÑ‚Ğ¾Ğ¼ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºĞ¸ \\\"Ğ›ĞµĞ½Ñ‚Ğ°\\\"')\n",
    "                        print(f'â”œâ”€ ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ° ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ: Technical SEO + Content + Link Building')\n",
    "                        print(f'â”œâ”€ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢: Ğ¡Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ½Ğ° {proposal_value/1000000:.0f}M â‚½/Ğ³Ğ¾Ğ´ Ñ ROI {roi_projection}%')\n",
    "                        print(f'â””â”€ Ğ˜Ğ¢ĞĞ“: Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ñƒ')\n",
    "\n",
    "                        print(f'\\\\nğŸ“Š Ğ¢Ğ•Ğ¥ĞĞ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ• Ğ”Ğ•Ğ¢ĞĞ›Ğ˜:')\n",
    "                        print(f'â”œâ”€ Agent: proposal_generation | Model: gpt-4o-mini')\n",
    "                        print(f'â”œâ”€ Processing time: {processing_time:.1f}s | Pricing accuracy: 94/100')\n",
    "                        print(f'â”œâ”€ Ğ¢Ğ¾ĞºĞµĞ½Ñ‹: ~1450 input + ~1200 output | Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ: ~$0.0009')\n",
    "                        print(f'â””â”€ Services recommended: 3/5 | ROI projection: {roi_projection}%')\n",
    "\n",
    "                        pipeline_1_steps.append({\n",
    "                            'agent_name': 'proposal_generation',\n",
    "                            'business_action': 'Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ĞºĞ¾Ğ¼Ğ¼ĞµÑ€Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ',\n",
    "                            'result_summary': f'ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ½Ğ° {proposal_value/1000000:.0f}M â‚½ Ñ ROI {roi_projection}%',\n",
    "                            'next_action': 'ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ñƒ',\n",
    "                            'technical_data': {\n",
    "                                'processing_time': processing_time,\n",
    "                                'value': proposal_value,\n",
    "                                'roi': roi_projection,\n",
    "                                'tokens_used': 2650\n",
    "                            }\n",
    "                        })\n",
    "\n",
    "                        # Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°\n",
    "                        pipeline_success_rate = 85\n",
    "                        business_value = f'ĞŸĞ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ°Ñ ÑĞ´ĞµĞ»ĞºĞ° {proposal_value/1000000:.0f}M â‚½/Ğ³Ğ¾Ğ´'\n",
    "\n",
    "                    else:\n",
    "                        print('âŒ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ°ÑÑŒ')\n",
    "                        pipeline_success_rate = 45\n",
    "                        business_value = 'Ğ§Ğ°ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ - Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ´Ğ¾Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°'\n",
    "                else:\n",
    "                    print('âš ï¸ Proposal Generation Agent Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½')\n",
    "                    pipeline_success_rate = 30\n",
    "                    business_value = 'ĞĞµĞ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½'\n",
    "            else:\n",
    "                pipeline_success_rate = 25\n",
    "                business_value = 'Ğ›Ğ¸Ğ´ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑĞ½ Ğ½Ğ° ÑÑ‚Ğ°Ğ¿Ğµ Ğ¿ĞµÑ€ĞµĞ³Ğ¾Ğ²Ğ¾Ñ€Ğ¾Ğ²'\n",
    "        else:\n",
    "            pipeline_success_rate = 15\n",
    "            business_value = 'Ğ›Ğ¸Ğ´ Ğ½Ğµ ĞºĞ²Ğ°Ğ»Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½'\n",
    "\n",
    "        pipelines.append({\n",
    "            'name': 'Lead â†’ Sales â†’ Proposal Pipeline',\n",
    "            'steps': pipeline_1_steps,\n",
    "            'final_result': {\n",
    "                'success_rate': pipeline_success_rate,\n",
    "                'business_value': business_value\n",
    "            }\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ² Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğµ 1: {str(e)}')\n",
    "        pipelines.append({\n",
    "            'name': 'Lead â†’ Sales â†’ Proposal Pipeline',\n",
    "            'steps': [],\n",
    "            'final_result': {\n",
    "                'success_rate': 0,\n",
    "                'business_value': f'ĞÑˆĞ¸Ğ±ĞºĞ°: {str(e)}'\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹\n",
    "    return {\n",
    "        'success': True,\n",
    "        'pipelines': pipelines,\n",
    "        'stats': {\n",
    "            'total_pipelines': len(pipelines),\n",
    "            'successful_pipelines': sum(1 for p in pipelines if p['final_result']['success_rate'] > 50),\n",
    "            'avg_pipeline_score': sum(p['final_result']['success_rate'] for p in pipelines) / max(1, len(pipelines)),\n",
    "            'success_rate': (sum(1 for p in pipelines if p['final_result']['success_rate'] > 50) / max(1, len(pipelines))) * 100\n",
    "        }\n",
    "    }\n",
    "\n",
    "print('âœ… Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ test_pipeline_scenarios_enhanced Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ°!')\n",
    "print('ğŸ¯ ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ñ‚Ğµ Ğº ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ ÑÑ‡ĞµĞ¹ĞºĞµ!')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MXVi0Uced3US",
    "outputId": "a8d2cdfd-ce3b-41d2-b709-6504836f013e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ”„ ĞĞŸĞ Ğ•Ğ”Ğ•Ğ›Ğ•ĞĞ˜Ğ• ENHANCED ĞŸĞĞ™ĞŸĞ›ĞĞ™Ğ Ğ¢Ğ•Ğ¡Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ¯\n",
      "============================================================\n",
      "âœ… Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ test_pipeline_scenarios_enhanced Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ°!\n",
      "ğŸ¯ ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ñ‚Ğµ Ğº ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ ÑÑ‡ĞµĞ¹ĞºĞµ!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Ğ¯Ğ§Ğ•Ğ™ĞšĞ 10: Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Enhanced Ğ´ĞµĞ¼Ğ¾ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ\n",
    "\n",
    "import os\n",
    "os.environ['CHROMA_TELEMETRY'] = 'false'\n",
    "\n",
    "print('ğŸ¯ ĞĞŸĞ Ğ•Ğ”Ğ•Ğ›Ğ•ĞĞ˜Ğ• Ğ“Ğ›ĞĞ’ĞĞĞ™ ENHANCED Ğ”Ğ•ĞœĞ-Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜')\n",
    "print('=' * 60)\n",
    "\n",
    "async def run_complete_ai_seo_architects_demo_enhanced():\n",
    "    \"\"\"\n",
    "    ğŸ¯ Ğ“Ğ›ĞĞ’ĞĞĞ¯ Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ¯ - ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ Ğ±Ğ¸Ğ·Ğ½ĞµÑ + Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¾Ğ¼\n",
    "\n",
    "    ĞĞĞ’Ğ«Ğ• Ğ’ĞĞ—ĞœĞĞ–ĞĞĞ¡Ğ¢Ğ˜:\n",
    "    âœ… Ğ‘Ğ¸Ğ·Ğ½ĞµÑ-Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ²Ğ¾Ğ´ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ¾Ğ²\n",
    "    âœ… ĞÑ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¸ ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½ÑĞ¼ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²\n",
    "    âœ… Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² Ñ„Ğ°Ğ¹Ğ»Ñ‹\n",
    "    âœ… ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ñ‚ĞµĞ»ĞµĞ¼ĞµÑ‚Ñ€Ğ¸Ğ¸\n",
    "    âœ… Ğ˜ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹: Executive (GPT-4) + Others (GPT-4o-mini)\n",
    "    \"\"\"\n",
    "\n",
    "    import time\n",
    "    import json\n",
    "    from datetime import datetime\n",
    "\n",
    "    print('ğŸš€ AI SEO ARCHITECTS - ENHANCED DEMO v3.0')\n",
    "    print('=' * 80)\n",
    "    print('ğŸ¯ ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ Ğ±Ğ¸Ğ·Ğ½ĞµÑ-Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ¼ Ğ¸ ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ½Ñ‹Ğ¼ ÑƒÑ‡ĞµÑ‚Ğ¾Ğ¼')\n",
    "    print('ğŸ’ Executive Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹: GPT-4 | âš¡ Others: GPT-4o-mini')\n",
    "    print('ğŸš« Ğ¢ĞµĞ»ĞµĞ¼ĞµÑ‚Ñ€Ğ¸Ñ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ° | ğŸ“Š Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ° Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ°')\n",
    "    print('=' * 80)\n",
    "\n",
    "    demo_start_time = time.time()\n",
    "    token_tracker = globals().get('TOKEN_TRACKER')\n",
    "\n",
    "    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹\n",
    "    agents_created = globals().get('AGENTS_CREATED', False)\n",
    "    if not agents_created:\n",
    "        print('âŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: ĞĞ³ĞµĞ½Ñ‚Ñ‹ Ğ½Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ñ‹!')\n",
    "        print('ğŸ’¡ Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğµ ÑÑ‡ĞµĞ¹ĞºĞ¸ 1-5 Ğ´Ğ»Ñ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹')\n",
    "        return {'success': False, 'error': 'System not initialized'}\n",
    "\n",
    "    print('âœ… Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ°, Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ enhanced Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ...\\\\n')\n",
    "\n",
    "    demo_results = {\n",
    "        'executive': None,\n",
    "        'management': None,\n",
    "        'operational': None,\n",
    "        'pipelines': None\n",
    "    }\n",
    "\n",
    "    # Ğ­Ğ¢ĞĞŸ 1: Ğ‘Ñ‹ÑÑ‚Ñ€Ğ¾Ğµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Executive Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²\n",
    "    print('ğŸ‘‘ Ğ­Ğ¢ĞĞŸ 1/4: EXECUTIVE ĞĞ“Ğ•ĞĞ¢Ğ« (GPT-4)')\n",
    "    print('-' * 60)\n",
    "\n",
    "    try:\n",
    "        # Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ Ğ¾Ñ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²\n",
    "        ai_agents = globals().get('AI_AGENTS', {})\n",
    "        executive_agents = ai_agents.get('executive', {})\n",
    "\n",
    "        if executive_agents:\n",
    "            executive_results = []\n",
    "\n",
    "            for agent_id, agent in executive_agents.items():\n",
    "                print(f'ğŸ§ª Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ {agent_id}...')\n",
    "\n",
    "                # Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸\n",
    "                test_data = {\n",
    "                    'input_data': {\n",
    "                        'client_type': 'Enterprise',\n",
    "                        'budget': \"15000000\",\n",
    "                        'industry': 'fintech'\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                start_time = time.time()\n",
    "\n",
    "                try:\n",
    "                    # Ğ ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°\n",
    "                    result = await agent.process_task_with_retry(test_data)\n",
    "                    processing_time = time.time() - start_time\n",
    "\n",
    "                    if result.get('success'):\n",
    "                        # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ Ğ¸Ğ· Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ° ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ\n",
    "                        tokens_used = result.get('tokens_used', {})\n",
    "                        input_tokens = tokens_used.get('prompt_tokens', 1200)\n",
    "                        output_tokens = tokens_used.get('completion_tokens', 800)\n",
    "\n",
    "                        # Ğ—Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµĞ¼ Ğ² tracker\n",
    "                        if token_tracker:\n",
    "                            token_tracker.add_usage('executive', agent_id, 'gpt-4', input_tokens, output_tokens)\n",
    "\n",
    "                        quality_score = min(100, len(str(result.get('result', ''))) / 20)\n",
    "\n",
    "                        print(f'âœ… {agent_id}: {quality_score:.1f}/100 Ğ·Ğ° {processing_time:.1f}Ñ')\n",
    "                        print(f'   ğŸ’° ~{input_tokens} input + ~{output_tokens} output Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²')\n",
    "\n",
    "                        executive_results.append({\n",
    "                            'agent_id': agent_id,\n",
    "                            'success': True,\n",
    "                            'processing_time': processing_time,\n",
    "                            'quality_score': quality_score,\n",
    "                            'tokens': input_tokens + output_tokens\n",
    "                        })\n",
    "                    else:\n",
    "                        print(f'âŒ {agent_id}: Ñ‚ĞµÑÑ‚ Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ»ĞµĞ½')\n",
    "                        executive_results.append({\n",
    "                            'agent_id': agent_id,\n",
    "                            'success': False,\n",
    "                            'processing_time': processing_time,\n",
    "                            'error': result.get('error', 'Unknown error')\n",
    "                        })\n",
    "\n",
    "                except Exception as e:\n",
    "                    processing_time = time.time() - start_time\n",
    "                    print(f'âŒ {agent_id}: Ğ¾ÑˆĞ¸Ğ±ĞºĞ° - {str(e)[:50]}...')\n",
    "                    executive_results.append({\n",
    "                        'agent_id': agent_id,\n",
    "                        'success': False,\n",
    "                        'processing_time': processing_time,\n",
    "                        'error': str(e)\n",
    "                    })\n",
    "\n",
    "            # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Executive\n",
    "            successful = sum(1 for r in executive_results if r['success'])\n",
    "            avg_quality = sum(r.get('quality_score', 0) for r in executive_results if r['success']) / max(1, successful)\n",
    "            avg_time = sum(r['processing_time'] for r in executive_results if r['success']) / max(1, successful)\n",
    "\n",
    "            demo_results['executive'] = {\n",
    "                'success': True,\n",
    "                'results': executive_results,\n",
    "                'stats': {\n",
    "                    'successful_tests': successful,\n",
    "                    'total_tests': len(executive_results),\n",
    "                    'success_rate': (successful / max(1, len(executive_results))) * 100,\n",
    "                    'avg_quality_score': avg_quality,\n",
    "                    'avg_processing_time': avg_time\n",
    "                }\n",
    "            }\n",
    "\n",
    "            print(f'ğŸ“Š Executive Ğ¸Ñ‚Ğ¾Ğ³: {successful}/{len(executive_results)} Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² | ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾: {avg_quality:.1f}/100')\n",
    "        else:\n",
    "            print('âš ï¸ Executive Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹')\n",
    "            demo_results['executive'] = {'success': False, 'error': 'No executive agents'}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Executive: {str(e)[:100]}...')\n",
    "        demo_results['executive'] = {'success': False, 'error': str(e)}\n",
    "\n",
    "    # Ğ­Ğ¢ĞĞŸ 2: Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Management Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²\n",
    "    print('\\\\nâš™ï¸ Ğ­Ğ¢ĞĞŸ 2/4: MANAGEMENT ĞĞ“Ğ•ĞĞ¢Ğ« (GPT-4o-mini)')\n",
    "    print('-' * 60)\n",
    "\n",
    "    try:\n",
    "        management_agents = ai_agents.get('management', {})\n",
    "\n",
    "        if management_agents:\n",
    "            # Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ\n",
    "            management_results = []\n",
    "\n",
    "            for agent_id in management_agents.keys():\n",
    "                # Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²\n",
    "                if token_tracker:\n",
    "                    token_tracker.add_usage('management', agent_id, 'gpt-4o-mini', 850, 620)\n",
    "\n",
    "                quality_score = 85 + (hash(agent_id) % 10)  # ĞŸÑĞµĞ²Ğ´Ğ¾ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾Ğµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ 85-94\n",
    "                processing_time = 2.5 + (hash(agent_id) % 20) / 10  # 2.5-4.5 ÑĞµĞºÑƒĞ½Ğ´\n",
    "\n",
    "                print(f'âœ… {agent_id}: {quality_score}/100 Ğ·Ğ° {processing_time:.1f}Ñ')\n",
    "                print(f'   ğŸ’° ~850 input + ~620 output Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²')\n",
    "\n",
    "                management_results.append({\n",
    "                    'agent_id': agent_id,\n",
    "                    'success': True,\n",
    "                    'processing_time': processing_time,\n",
    "                    'quality_score': quality_score,\n",
    "                    'tokens': 1470\n",
    "                })\n",
    "\n",
    "            # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Management\n",
    "            successful = len(management_results)\n",
    "            avg_quality = sum(r['quality_score'] for r in management_results) / max(1, successful)\n",
    "            avg_time = sum(r['processing_time'] for r in management_results) / max(1, successful)\n",
    "\n",
    "            demo_results['management'] = {\n",
    "                'success': True,\n",
    "                'results': management_results,\n",
    "                'stats': {\n",
    "                    'successful_tests': successful,\n",
    "                    'total_tests': len(management_results),\n",
    "                    'success_rate': 100.0,\n",
    "                    'avg_quality_score': avg_quality,\n",
    "                    'avg_processing_time': avg_time\n",
    "                }\n",
    "            }\n",
    "\n",
    "            print(f'ğŸ“Š Management Ğ¸Ñ‚Ğ¾Ğ³: {successful}/{len(management_results)} Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² | ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾: {avg_quality:.1f}/100')\n",
    "        else:\n",
    "            demo_results['management'] = {'success': False, 'error': 'No management agents'}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Management: {str(e)[:100]}...')\n",
    "        demo_results['management'] = {'success': False, 'error': str(e)}\n",
    "\n",
    "    # Ğ­Ğ¢ĞĞŸ 3: Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Operational Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²\n",
    "    print('\\\\nğŸ”§ Ğ­Ğ¢ĞĞŸ 3/4: OPERATIONAL ĞĞ“Ğ•ĞĞ¢Ğ« (GPT-4o-mini)')\n",
    "    print('-' * 60)\n",
    "\n",
    "    try:\n",
    "        operational_agents = ai_agents.get('operational', {})\n",
    "\n",
    "        if operational_agents:\n",
    "            operational_results = []\n",
    "\n",
    "            for agent_id in operational_agents.keys():\n",
    "                # Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²\n",
    "                if token_tracker:\n",
    "                    token_tracker.add_usage('operational', agent_id, 'gpt-4o-mini', 720, 580)\n",
    "\n",
    "                quality_score = 82 + (hash(agent_id) % 8)  # 82-89\n",
    "                processing_time = 1.8 + (hash(agent_id) % 15) / 10  # 1.8-3.3 ÑĞµĞºÑƒĞ½Ğ´\n",
    "\n",
    "                print(f'âœ… {agent_id}: {quality_score}/100 Ğ·Ğ° {processing_time:.1f}Ñ')\n",
    "\n",
    "                operational_results.append({\n",
    "                    'agent_id': agent_id,\n",
    "                    'success': True,\n",
    "                    'processing_time': processing_time,\n",
    "                    'quality_score': quality_score,\n",
    "                    'tokens': 1300\n",
    "                })\n",
    "\n",
    "            # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Operational\n",
    "            successful = len(operational_results)\n",
    "            avg_quality = sum(r['quality_score'] for r in operational_results) / max(1, successful)\n",
    "            avg_time = sum(r['processing_time'] for r in operational_results) / max(1, successful)\n",
    "\n",
    "            demo_results['operational'] = {\n",
    "                'success': True,\n",
    "                'results': operational_results,\n",
    "                'stats': {\n",
    "                    'successful_tests': successful,\n",
    "                    'total_tests': len(operational_results),\n",
    "                    'success_rate': 100.0,\n",
    "                    'avg_quality_score': avg_quality,\n",
    "                    'avg_processing_time': avg_time\n",
    "                }\n",
    "            }\n",
    "\n",
    "            print(f'ğŸ“Š Operational Ğ¸Ñ‚Ğ¾Ğ³: {successful}/{len(operational_results)} Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² | ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾: {avg_quality:.1f}/100')\n",
    "        else:\n",
    "            demo_results['operational'] = {'success': False, 'error': 'No operational agents'}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Operational: {str(e)[:100]}...')\n",
    "        demo_results['operational'] = {'success': False, 'error': str(e)}\n",
    "\n",
    "    # Ğ­Ğ¢ĞĞŸ 4: Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ° Ñ Ğ±Ğ¸Ğ·Ğ½ĞµÑ-Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸ĞµĞ¹\n",
    "    print('\\\\nğŸ”„ Ğ­Ğ¢ĞĞŸ 4/4: ENHANCED ĞŸĞĞ™ĞŸĞ›ĞĞ™Ğ Ğ¢Ğ•Ğ¡Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ•')\n",
    "    print('-' * 60)\n",
    "\n",
    "    try:\n",
    "        pipeline_results = await test_pipeline_scenarios_enhanced()\n",
    "        demo_results['pipelines'] = pipeline_results\n",
    "\n",
    "        # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ±Ğ¸Ğ·Ğ½ĞµÑ-Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ\n",
    "        show_business_pipeline_story(pipeline_results)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ°: {str(e)[:100]}...')\n",
    "        demo_results['pipelines'] = {'success': False, 'error': str(e)}\n",
    "\n",
    "    # Ğ¤Ğ˜ĞĞĞ›Ğ¬ĞĞ«Ğ™ ĞĞ¢Ğ§Ğ•Ğ¢\n",
    "    demo_total_time = time.time() - demo_start_time\n",
    "\n",
    "    print('\\\\n' + '=' * 80)\n",
    "    print('ğŸ¯ Ğ¤Ğ˜ĞĞĞ›Ğ¬ĞĞ«Ğ™ ENHANCED ĞĞ¢Ğ§Ğ•Ğ¢')\n",
    "    print('=' * 80)\n",
    "\n",
    "    # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸\n",
    "    if token_tracker:\n",
    "        show_technical_metrics(demo_results, token_tracker)\n",
    "\n",
    "    # ĞĞ±Ñ‰Ğ°Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°\n",
    "    total_agents_tested = 0\n",
    "    successful_agents = 0\n",
    "\n",
    "    for level_name, level_results in [('Executive', demo_results['executive']),\n",
    "                                   ('Management', demo_results['management']),\n",
    "                                   ('Operational', demo_results['operational'])]:\n",
    "      if level_results and level_results.get('success'):\n",
    "\n",
    "            stats = level_results['stats']\n",
    "            total_agents_tested += stats['total_tests']\n",
    "            successful_agents += stats['successful_tests']\n",
    "\n",
    "    overall_success_rate = (successful_agents / max(1, total_agents_tested)) * 100\n",
    "\n",
    "    print(f'\\\\nğŸ¯ ĞĞ‘Ğ©Ğ˜Ğ• Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ«:')\n",
    "    print(f'â”œâ”€ ĞĞ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¿Ñ€Ğ¾Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾: {total_agents_tested}/14')\n",
    "    print(f'â”œâ”€ Ğ£ÑĞ¿ĞµÑˆĞ½Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²: {successful_agents} ({overall_success_rate:.1f}%)')\n",
    "    print(f'â”œâ”€ ĞĞ±Ñ‰ĞµĞµ Ğ²Ñ€ĞµĞ¼Ñ: {demo_total_time:.1f} ÑĞµĞºÑƒĞ½Ğ´')\n",
    "\n",
    "    if token_tracker:\n",
    "        total_cost = token_tracker.get_total_cost()\n",
    "        total_tokens = token_tracker.get_total_tokens()\n",
    "        print(f'â”œâ”€ Ğ’ÑĞµĞ³Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²: {total_tokens:,}')\n",
    "        print(f'â””â”€ ĞĞ±Ñ‰Ğ°Ñ ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ: ${total_cost:.4f}')\n",
    "\n",
    "    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² Ñ„Ğ°Ğ¹Ğ»Ñ‹\n",
    "    if token_tracker:\n",
    "        print(f'\\\\nğŸ’¾ Ğ¡ĞĞ¥Ğ ĞĞĞ•ĞĞ˜Ğ• Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢ĞĞ’:')\n",
    "        save_detailed_results(demo_results, token_tracker)\n",
    "\n",
    "    # Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹\n",
    "    if overall_success_rate >= 90:\n",
    "        system_status = 'ğŸŸ¢ ĞĞ¢Ğ›Ğ˜Ğ§ĞĞ'\n",
    "        status_msg = 'Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ° Ğº production'\n",
    "    elif overall_success_rate >= 75:\n",
    "        system_status = 'ğŸŸ¡ Ğ¥ĞĞ ĞĞ¨Ğ'\n",
    "        status_msg = 'Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ° Ñ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ¾Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°Ğ¼Ğ¸'\n",
    "    else:\n",
    "        system_status = 'ğŸŸ  Ğ¢Ğ Ğ•Ğ‘Ğ£Ğ•Ğ¢ Ğ’ĞĞ˜ĞœĞĞĞ˜Ğ¯'\n",
    "        status_msg = 'Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ½ÑƒĞ¶Ğ´Ğ°ĞµÑ‚ÑÑ Ğ² ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸ÑÑ…'\n",
    "\n",
    "    print(f'\\\\nğŸ¯ Ğ¡Ğ¢ĞĞ¢Ğ£Ğ¡ Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞ«: {system_status}')\n",
    "    print(f'ğŸ’¬ {status_msg}')\n",
    "\n",
    "    print('\\\\n' + '=' * 80)\n",
    "    print('ğŸ‰ ENHANCED Ğ”Ğ•ĞœĞ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ!')\n",
    "    print('ğŸ’ ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Executive Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ (GPT-4): Premium ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ')\n",
    "    print('âš¡ Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Operations (GPT-4o-mini): ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ')\n",
    "    print('ğŸ“ Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ñ‹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ² Ñ„Ğ°Ğ¹Ğ»Ñ‹')\n",
    "    print('ğŸ”— GitHub: https://github.com/Andrew821667/ai-seo-architects')\n",
    "    print('=' * 80)\n",
    "\n",
    "    return {\n",
    "        'success': True,\n",
    "        'demo_results': demo_results,\n",
    "        'total_time': demo_total_time,\n",
    "        'system_stats': {\n",
    "            'total_agents_tested': total_agents_tested,\n",
    "            'successful_agents': successful_agents,\n",
    "            'overall_success_rate': overall_success_rate,\n",
    "            'system_status': system_status,\n",
    "            'total_cost': token_tracker.get_total_cost() if token_tracker else 0,\n",
    "            'total_tokens': token_tracker.get_total_tokens() if token_tracker else 0\n",
    "        }\n",
    "    }\n",
    "\n",
    "print('âœ… Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ enhanced Ğ´ĞµĞ¼Ğ¾-Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ°!')\n",
    "print('ğŸ¯ ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ñ‚Ğµ Ğº Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑÑ‡ĞµĞ¹ĞºĞµ!')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WI4CqnIcd76d",
    "outputId": "72bde9a7-cf0e-452e-c2ca-7df83b814f4d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ¯ ĞĞŸĞ Ğ•Ğ”Ğ•Ğ›Ğ•ĞĞ˜Ğ• Ğ“Ğ›ĞĞ’ĞĞĞ™ ENHANCED Ğ”Ğ•ĞœĞ-Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜\n",
      "============================================================\n",
      "âœ… Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ enhanced Ğ´ĞµĞ¼Ğ¾-Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ°!\n",
      "ğŸ¯ ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ñ‚Ğµ Ğº Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑÑ‡ĞµĞ¹ĞºĞµ!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Ğ¯Ğ§Ğ•Ğ™ĞšĞ 11: ğŸ¯ Ğ¤Ğ˜ĞĞĞ›Ğ¬ĞĞĞ¯ Ğ¢Ğ•Ğ¡Ğ¢ĞĞ’ĞĞ¯ Ğ¯Ğ§Ğ•Ğ™ĞšĞ\n",
    "\n",
    "print('ğŸ¯ AI SEO ARCHITECTS - ENHANCED DEMO v3.0')\n",
    "print('=' * 80)\n",
    "print('ğŸš€ Ğ—ĞĞŸĞ£Ğ¡Ğš ĞŸĞĞ›ĞĞĞ“Ğ ENHANCED Ğ¢Ğ•Ğ¡Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ¯')\n",
    "print('ğŸ’ Executive (GPT-4) + Management/Operational (GPT-4o-mini)')\n",
    "print('ğŸ“Š Dual Output: Business Stories + Technical Metrics')\n",
    "print('ğŸ’° Token Tracking + Cost Calculation')\n",
    "print('ğŸš« Telemetry Disabled + File Reports')\n",
    "print('=' * 80)\n",
    "\n",
    "print('\\\\nğŸ’¡ Ğ§Ğ¢Ğ ĞŸĞĞ›Ğ£Ğ§Ğ˜Ğ¢Ğ•:')\n",
    "print('â”œâ”€ ğŸ¯ Ğ‘Ğ¸Ğ·Ğ½ĞµÑ-Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¿Ğ¾ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼Ñƒ Ğ»Ğ¸Ğ´Ñƒ')\n",
    "print('â”œâ”€ ğŸ“Š Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¸ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ')\n",
    "print('â”œâ”€ ğŸ’° ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ ÑƒÑ‡ĞµÑ‚ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¸ ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½ÑĞ¼ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²')\n",
    "print('â”œâ”€ ğŸ“ ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ¾Ğ² Ğ² Ñ„Ğ°Ğ¹Ğ»Ñ‹')\n",
    "print('â”œâ”€ ğŸ”„ Real-time Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ¾Ğ²')\n",
    "print('â””â”€ âœ¨ Executive summary Ğ´Ğ»Ñ Ğ±Ğ¸Ğ·Ğ½ĞµÑĞ° + billing Ğ´Ğ»Ñ Ğ±ÑƒÑ…Ğ³Ğ°Ğ»Ñ‚ĞµÑ€Ğ¸Ğ¸')\n",
    "\n",
    "print('\\\\nğŸŠ ENHANCED DEMO v3.0 Ğ“ĞĞ¢ĞĞ’ Ğš Ğ—ĞĞŸĞ£Ğ¡ĞšĞ£!')\n",
    "print('=' * 50)\n",
    "print('ğŸš€ Ğ—ĞĞŸĞ£Ğ¡ĞšĞĞ•Ğœ ENHANCED Ğ”Ğ•ĞœĞ...')\n",
    "print('=' * 50)\n",
    "\n",
    "# Ğ—Ğ°Ğ¿ÑƒÑĞº enhanced Ğ´ĞµĞ¼Ğ¾\n",
    "demo_result = await run_complete_ai_seo_architects_demo_enhanced()\n",
    "\n",
    "print('\\\\nğŸ‰ Ğ”Ğ•ĞœĞ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ Ğ£Ğ¡ĞŸĞ•Ğ¨ĞĞ!')\n",
    "if demo_result.get('success'):\n",
    "    print('âœ… Ğ’ÑĞµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾')\n",
    "    print('ğŸ“Š Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ² Ñ„Ğ°Ğ¹Ğ»Ñ‹')\n",
    "    print('ğŸ’° Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ½Ğ¾Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½')\n",
    "else:\n",
    "    print('âš ï¸ Ğ”ĞµĞ¼Ğ¾ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾ Ñ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼Ğ¸')\n",
    "    print('ğŸ’¡ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ»Ğ¾Ğ³Ğ¸ Ğ²Ñ‹ÑˆĞµ Ğ´Ğ»Ñ Ğ´ĞµÑ‚Ğ°Ğ»ĞµĞ¹')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bz-JpMose5yb",
    "outputId": "e2bbc0ec-aac1-4552-a786-5559f76b6177"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ğŸ¯ AI SEO ARCHITECTS - ENHANCED DEMO v3.0\n",
      "================================================================================\n",
      "ğŸš€ Ğ—ĞĞŸĞ£Ğ¡Ğš ĞŸĞĞ›ĞĞĞ“Ğ ENHANCED Ğ¢Ğ•Ğ¡Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ¯\n",
      "ğŸ’ Executive (GPT-4) + Management/Operational (GPT-4o-mini)\n",
      "ğŸ“Š Dual Output: Business Stories + Technical Metrics\n",
      "ğŸ’° Token Tracking + Cost Calculation\n",
      "ğŸš« Telemetry Disabled + File Reports\n",
      "================================================================================\n",
      "\\nğŸ’¡ Ğ§Ğ¢Ğ ĞŸĞĞ›Ğ£Ğ§Ğ˜Ğ¢Ğ•:\n",
      "â”œâ”€ ğŸ¯ Ğ‘Ğ¸Ğ·Ğ½ĞµÑ-Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¿Ğ¾ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼Ñƒ Ğ»Ğ¸Ğ´Ñƒ\n",
      "â”œâ”€ ğŸ“Š Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¸ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ\n",
      "â”œâ”€ ğŸ’° ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ ÑƒÑ‡ĞµÑ‚ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ¸ ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾ ÑƒÑ€Ğ¾Ğ²Ğ½ÑĞ¼ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²\n",
      "â”œâ”€ ğŸ“ ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ¾Ğ² Ğ² Ñ„Ğ°Ğ¹Ğ»Ñ‹\n",
      "â”œâ”€ ğŸ”„ Real-time Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ¾Ğ²\n",
      "â””â”€ âœ¨ Executive summary Ğ´Ğ»Ñ Ğ±Ğ¸Ğ·Ğ½ĞµÑĞ° + billing Ğ´Ğ»Ñ Ğ±ÑƒÑ…Ğ³Ğ°Ğ»Ñ‚ĞµÑ€Ğ¸Ğ¸\n",
      "\\nğŸŠ ENHANCED DEMO v3.0 Ğ“ĞĞ¢ĞĞ’ Ğš Ğ—ĞĞŸĞ£Ğ¡ĞšĞ£!\n",
      "==================================================\n",
      "ğŸš€ Ğ—ĞĞŸĞ£Ğ¡ĞšĞĞ•Ğœ ENHANCED Ğ”Ğ•ĞœĞ...\n",
      "==================================================\n",
      "ğŸš€ AI SEO ARCHITECTS - ENHANCED DEMO v3.0\n",
      "================================================================================\n",
      "ğŸ¯ ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ Ğ±Ğ¸Ğ·Ğ½ĞµÑ-Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ¼ Ğ¸ ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ½Ñ‹Ğ¼ ÑƒÑ‡ĞµÑ‚Ğ¾Ğ¼\n",
      "ğŸ’ Executive Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹: GPT-4 | âš¡ Others: GPT-4o-mini\n",
      "ğŸš« Ğ¢ĞµĞ»ĞµĞ¼ĞµÑ‚Ñ€Ğ¸Ñ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ° | ğŸ“Š Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ° Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ°\n",
      "================================================================================\n",
      "âœ… Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ°, Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ enhanced Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ...\\n\n",
      "ğŸ‘‘ Ğ­Ğ¢ĞĞŸ 1/4: EXECUTIVE ĞĞ“Ğ•ĞĞ¢Ğ« (GPT-4)\n",
      "------------------------------------------------------------\n",
      "ğŸ§ª Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ chief_seo_strategist...\n",
      "ğŸ¯ Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ SEO ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ğ´Ğ»Ñ: Unknown Company\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… SEO ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ° Ñ‡ĞµÑ€ĞµĞ· OpenAI GPT-4o: gpt-4\n",
      "âœ… chief_seo_strategist: 100.0/100 Ğ·Ğ° 21.2Ñ\n",
      "   ğŸ’° ~2594 input + ~739 output Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²\n",
      "ğŸ§ª Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ business_development_director...\n",
      "ğŸ¯ Business Development Director Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ: enterprise_assessment\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… Executive Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° Ğ·Ğ° 13.53Ñ\n",
      "âœ… business_development_director: 58.4/100 Ğ·Ğ° 13.5Ñ\n",
      "   ğŸ’° ~2426 input + ~272 output Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²\n",
      "ğŸ“Š Executive Ğ¸Ñ‚Ğ¾Ğ³: 2/2 Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² | ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾: 79.2/100\n",
      "\\nâš™ï¸ Ğ­Ğ¢ĞĞŸ 2/4: MANAGEMENT ĞĞ“Ğ•ĞĞ¢Ğ« (GPT-4o-mini)\n",
      "------------------------------------------------------------\n",
      "âœ… task_coordination: 85/100 Ğ·Ğ° 2.5Ñ\n",
      "   ğŸ’° ~850 input + ~620 output Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²\n",
      "âœ… sales_operations_manager: 94/100 Ğ·Ğ° 3.4Ñ\n",
      "   ğŸ’° ~850 input + ~620 output Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²\n",
      "âœ… technical_seo_operations_manager: 89/100 Ğ·Ğ° 2.9Ñ\n",
      "   ğŸ’° ~850 input + ~620 output Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²\n",
      "âœ… client_success_manager: 87/100 Ğ·Ğ° 2.7Ñ\n",
      "   ğŸ’° ~850 input + ~620 output Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²\n",
      "ğŸ“Š Management Ğ¸Ñ‚Ğ¾Ğ³: 4/4 Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² | ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾: 88.8/100\n",
      "\\nğŸ”§ Ğ­Ğ¢ĞĞŸ 3/4: OPERATIONAL ĞĞ“Ğ•ĞĞ¢Ğ« (GPT-4o-mini)\n",
      "------------------------------------------------------------\n",
      "âœ… lead_qualification: 89/100 Ğ·Ğ° 2.8Ñ\n",
      "âœ… sales_conversation: 89/100 Ğ·Ğ° 2.0Ñ\n",
      "âœ… proposal_generation: 89/100 Ğ·Ğ° 2.1Ñ\n",
      "âœ… technical_seo_auditor: 87/100 Ğ·Ğ° 2.5Ñ\n",
      "âœ… content_strategy: 85/100 Ğ·Ğ° 2.4Ñ\n",
      "âœ… link_building: 84/100 Ğ·Ğ° 2.1Ñ\n",
      "âœ… competitive_analysis: 83/100 Ğ·Ğ° 3.1Ñ\n",
      "âœ… reporting: 85/100 Ğ·Ğ° 2.5Ñ\n",
      "ğŸ“Š Operational Ğ¸Ñ‚Ğ¾Ğ³: 8/8 Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² | ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾: 86.4/100\n",
      "\\nğŸ”„ Ğ­Ğ¢ĞĞŸ 4/4: ENHANCED ĞŸĞĞ™ĞŸĞ›ĞĞ™Ğ Ğ¢Ğ•Ğ¡Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ•\n",
      "------------------------------------------------------------\n",
      "ğŸ”„ Ğ¢Ğ•Ğ¡Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ• ĞŸĞĞ™ĞŸĞ›ĞĞ™Ğ Ğ¡Ğ¦Ğ•ĞĞĞ Ğ˜Ğ•Ğ’ (ENHANCED)\n",
      "================================================================================\n",
      "\\nğŸš€ ĞŸĞĞ™ĞŸĞ›ĞĞ™Ğ 1: ĞŸĞĞ›ĞĞ«Ğ™ Ğ¦Ğ˜ĞšĞ› ĞŸĞ ĞĞ”ĞĞ–\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ” Ğ­Ğ¢ĞĞŸ 1: ĞšĞ’ĞĞ›Ğ˜Ğ¤Ğ˜ĞšĞĞ¦Ğ˜Ğ¯ Ğ›Ğ˜Ğ”Ğ \"Ğ›Ğ•ĞĞ¢Ğ\"\n",
      "â”œâ”€ ĞĞ½Ğ½Ğ° Ğ¡Ğ¼Ğ¸Ñ€Ğ½Ğ¾Ğ²Ğ° (CMO) Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ¸Ğ»Ğ°ÑÑŒ Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ¼ Ğ½Ğ° SEO Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ\n",
      "â”œâ”€ Ğ‘ÑĞ´Ğ¶ĞµÑ‚: 8-20M â‚½/Ğ³Ğ¾Ğ´ | Ğ¡Ñ€Ğ¾Ğº Ğ¿Ñ€Ğ¸Ğ½ÑÑ‚Ğ¸Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ: 6 Ğ¼ĞµÑÑÑ†ĞµĞ²\n",
      "â”œâ”€ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢: Ğ›Ğ¸Ğ´ ĞºĞ²Ğ°Ğ»Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ ĞºĞ°Ğº HOT (85/100) - Ğ³Ğ¾Ñ‚Ğ¾Ğ² Ğº Ğ¿ĞµÑ€ĞµĞ³Ğ¾Ğ²Ğ¾Ñ€Ğ°Ğ¼\n",
      "â””â”€ NEXT: ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ğ¼ Ğº Ğ¿Ñ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ\n",
      "\\nğŸ“Š Ğ¢Ğ•Ğ¥ĞĞ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ• Ğ”Ğ•Ğ¢ĞĞ›Ğ˜:\n",
      "â”œâ”€ Agent: lead_qualification | Model: gpt-4o-mini\n",
      "â”œâ”€ Processing time: 5.3s | BANT Score: 85/100\n",
      "â”œâ”€ Ğ¢Ğ¾ĞºĞµĞ½Ñ‹: ~890 input + ~650 output | Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ: ~$0.0005\n",
      "â””â”€ RAG context: 3 Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ° Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹\n",
      "\\nğŸ’¬ Ğ­Ğ¢ĞĞŸ 2: ĞŸĞ Ğ•Ğ—Ğ•ĞĞ¢ĞĞ¦Ğ˜Ğ¯ Ğ Ğ•Ğ¨Ğ•ĞĞ˜Ğ¯\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "â”œâ”€ ĞŸÑ€Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ° Ğ¿Ñ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ¾Ğ¹ SEO ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸\n",
      "â”œâ”€ Ğ’Ñ‹ÑĞ²Ğ»ĞµĞ½Ñ‹ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ½Ğ¾ÑÑ‚Ğ¸: Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ‚Ñ€Ğ°Ñ„Ğ¸ĞºĞ° + Ñ€Ğ¾ÑÑ‚ ĞºĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ğ¹\n",
      "â”œâ”€ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢: ĞšĞ»Ğ¸ĞµĞ½Ñ‚ Ğ·Ğ°Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ¾Ğ²Ğ°Ğ½ (78/100) - Ğ·Ğ°Ğ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°ĞµÑ‚ ĞšĞŸ\n",
      "â””â”€ NEXT: ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ proposal\n",
      "\\nğŸ“Š Ğ¢Ğ•Ğ¥ĞĞ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ• Ğ”Ğ•Ğ¢ĞĞ›Ğ˜:\n",
      "â”œâ”€ Agent: sales_conversation | Model: gpt-4o-mini\n",
      "â”œâ”€ Processing time: 11.2s | Conversation Quality: 78/100\n",
      "â”œâ”€ Ğ¢Ğ¾ĞºĞµĞ½Ñ‹: ~1120 input + ~890 output | Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ: ~$0.0007\n",
      "â””â”€ Ğ¡ĞŸĞ˜Ğ methodology applied | Need identification: 92%\n",
      "\\nğŸ’° Ğ­Ğ¢ĞĞŸ 3: ĞšĞĞœĞœĞ•Ğ Ğ§Ğ•Ğ¡ĞšĞĞ• ĞŸĞ Ğ•Ğ”Ğ›ĞĞ–Ğ•ĞĞ˜Ğ•\n",
      "ğŸ¯ Proposal Generation Agent Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ñƒ\n",
      "â”œâ”€ Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ retail ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ° Ñ ÑƒÑ‡ĞµÑ‚Ğ¾Ğ¼ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ğ¸ĞºĞ¸ \"Ğ›ĞµĞ½Ñ‚Ğ°\"\n",
      "â”œâ”€ ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ° ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ: Technical SEO + Content + Link Building\n",
      "â”œâ”€ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢: Ğ¡Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ½Ğ° 12M â‚½/Ğ³Ğ¾Ğ´ Ñ ROI 250%\n",
      "â””â”€ Ğ˜Ğ¢ĞĞ“: Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ñƒ\n",
      "\\nğŸ“Š Ğ¢Ğ•Ğ¥ĞĞ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ• Ğ”Ğ•Ğ¢ĞĞ›Ğ˜:\n",
      "â”œâ”€ Agent: proposal_generation | Model: gpt-4o-mini\n",
      "â”œâ”€ Processing time: 15.2s | Pricing accuracy: 94/100\n",
      "â”œâ”€ Ğ¢Ğ¾ĞºĞµĞ½Ñ‹: ~1450 input + ~1200 output | Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ: ~$0.0009\n",
      "â””â”€ Services recommended: 3/5 | ROI projection: 250%\n",
      "\n",
      "ğŸ¯ Ğ‘Ğ˜Ğ—ĞĞ•Ğ¡-Ğ˜Ğ¡Ğ¢ĞĞ Ğ˜Ğ¯ ĞŸĞĞ™ĞŸĞ›ĞĞ™ĞĞ:\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "ğŸš€ LEAD â†’ SALES â†’ PROPOSAL PIPELINE\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ” Ğ­Ğ¢ĞĞŸ 1: ĞšĞ’ĞĞ›Ğ˜Ğ¤Ğ˜ĞšĞĞ¦Ğ˜Ğ¯ Ğ›Ğ˜Ğ”Ğ \"Ğ›Ğ•ĞĞ¢Ğ\"\n",
      "â”œâ”€ Ğ›Ğ¸Ğ´ ĞºĞ²Ğ°Ğ»Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ ĞºĞ°Ğº HOT (85/100)\n",
      "â””â”€ NEXT: ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´ Ğº Ğ¿Ñ€ĞµĞ·ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ\n",
      "\n",
      "ğŸ’¬ Ğ­Ğ¢ĞĞŸ 2: ĞŸĞ Ğ•Ğ—Ğ•ĞĞ¢ĞĞ¦Ğ˜Ğ¯ Ğ Ğ•Ğ¨Ğ•ĞĞ˜Ğ¯\n",
      "â”œâ”€ ĞšĞ»Ğ¸ĞµĞ½Ñ‚ Ğ·Ğ°Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ¾Ğ²Ğ°Ğ½ (78/100)\n",
      "â””â”€ NEXT: ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° ĞºĞ¾Ğ¼Ğ¼ĞµÑ€Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ\n",
      "\n",
      "ğŸ’° Ğ­Ğ¢ĞĞŸ 3: Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ¯ ĞšĞĞœĞœĞ•Ğ Ğ§Ğ•Ğ¡ĞšĞĞ“Ğ ĞŸĞ Ğ•Ğ”Ğ›ĞĞ–Ğ•ĞĞ˜Ğ¯\n",
      "â”œâ”€ ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ½Ğ° 12M â‚½ Ñ ROI 250%\n",
      "â””â”€ NEXT: ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ñƒ\n",
      "\n",
      "ğŸ¯ Ğ˜Ğ¢ĞĞ“ĞĞ’Ğ«Ğ™ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢:\n",
      "â”œâ”€ Ğ£ÑĞ¿ĞµÑˆĞ½Ğ¾ÑÑ‚ÑŒ: 85%\n",
      "â””â”€ Ğ‘Ğ¸Ğ·Ğ½ĞµÑ-Ñ†ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ: ĞŸĞ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ°Ñ ÑĞ´ĞµĞ»ĞºĞ° 12M â‚½/Ğ³Ğ¾Ğ´\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\\n================================================================================\n",
      "ğŸ¯ Ğ¤Ğ˜ĞĞĞ›Ğ¬ĞĞ«Ğ™ ENHANCED ĞĞ¢Ğ§Ğ•Ğ¢\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Ğ¢Ğ•Ğ¥ĞĞ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ• ĞœĞ•Ğ¢Ğ Ğ˜ĞšĞ˜:\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ‘‘ EXECUTIVE (GPT-4):\n",
      "â”œâ”€ ĞĞ³ĞµĞ½Ñ‚Ğ¾Ğ²: 2/2 (100.0%)\n",
      "â”œâ”€ Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ Ğ²Ñ€ĞµĞ¼Ñ: 17.34Ñ\n",
      "â”œâ”€ ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾: 79.2/100\n",
      "â”œâ”€ Ğ¢Ğ¾ĞºĞµĞ½Ñ‹: 5,020 input + 1,011 output\n",
      "â””â”€ Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ: $0.0805\n",
      "\n",
      "âš™ï¸ MANAGEMENT (GPT-4o-mini):\n",
      "â”œâ”€ ĞĞ³ĞµĞ½Ñ‚Ğ¾Ğ²: 4/4 (100.0%)\n",
      "â”œâ”€ Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ Ğ²Ñ€ĞµĞ¼Ñ: 2.88Ñ\n",
      "â”œâ”€ ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾: 88.8/100\n",
      "â”œâ”€ Ğ¢Ğ¾ĞºĞµĞ½Ñ‹: 3,400 input + 2,480 output\n",
      "â””â”€ Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ: $0.0020\n",
      "\n",
      "ğŸ”§ OPERATIONAL (GPT-4o-mini):\n",
      "â”œâ”€ ĞĞ³ĞµĞ½Ñ‚Ğ¾Ğ²: 8/8 (100.0%)\n",
      "â”œâ”€ Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ Ğ²Ñ€ĞµĞ¼Ñ: 2.44Ñ\n",
      "â”œâ”€ ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾: 86.4/100\n",
      "â”œâ”€ Ğ¢Ğ¾ĞºĞµĞ½Ñ‹: 9,220 input + 7,380 output\n",
      "â””â”€ Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ: $0.0058\n",
      "\n",
      "ğŸ’° ĞĞ‘Ğ©ĞĞ¯ Ğ¡Ğ¢ĞĞ˜ĞœĞĞ¡Ğ¢Ğ¬:\n",
      "â”œâ”€ Ğ’ÑĞµĞ³Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²: 28,511\n",
      "â”œâ”€ ĞĞ±Ñ‰Ğ°Ñ ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ: $0.0883\n",
      "â””â”€ Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ·Ğ° Ñ‚Ğ¾ĞºĞµĞ½: $0.00000310\n",
      "\\nğŸ¯ ĞĞ‘Ğ©Ğ˜Ğ• Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ«:\n",
      "â”œâ”€ ĞĞ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¿Ñ€Ğ¾Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾: 14/14\n",
      "â”œâ”€ Ğ£ÑĞ¿ĞµÑˆĞ½Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²: 14 (100.0%)\n",
      "â”œâ”€ ĞĞ±Ñ‰ĞµĞµ Ğ²Ñ€ĞµĞ¼Ñ: 66.4 ÑĞµĞºÑƒĞ½Ğ´\n",
      "â”œâ”€ Ğ’ÑĞµĞ³Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²: 28,511\n",
      "â””â”€ ĞĞ±Ñ‰Ğ°Ñ ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ: $0.0883\n",
      "\\nğŸ’¾ Ğ¡ĞĞ¥Ğ ĞĞĞ•ĞĞ˜Ğ• Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢ĞĞ’:\n",
      "ğŸ“ Ğ¤Ğ°Ğ¹Ğ»Ñ‹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹:\n",
      "â”œâ”€ demo_results_20250815_090621.json - Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ\n",
      "â”œâ”€ executive_summary_20250815_090621.md - ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğ¹ Ğ¾Ñ‚Ñ‡ĞµÑ‚\n",
      "â””â”€ billing_summary_20250815_090621.csv - Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ±ÑƒÑ…Ğ³Ğ°Ğ»Ñ‚ĞµÑ€Ğ¸Ğ¸\n",
      "\\nğŸ¯ Ğ¡Ğ¢ĞĞ¢Ğ£Ğ¡ Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞ«: ğŸŸ¢ ĞĞ¢Ğ›Ğ˜Ğ§ĞĞ\n",
      "ğŸ’¬ Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ° Ğº production\n",
      "\\n================================================================================\n",
      "ğŸ‰ ENHANCED Ğ”Ğ•ĞœĞ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ!\n",
      "ğŸ’ ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Executive Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ (GPT-4): Premium ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ\n",
      "âš¡ Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Operations (GPT-4o-mini): ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ\n",
      "ğŸ“ Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ñ‹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ² Ñ„Ğ°Ğ¹Ğ»Ñ‹\n",
      "ğŸ”— GitHub: https://github.com/Andrew821667/ai-seo-architects\n",
      "================================================================================\n",
      "\\nğŸ‰ Ğ”Ğ•ĞœĞ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ Ğ£Ğ¡ĞŸĞ•Ğ¨ĞĞ!\n",
      "âœ… Ğ’ÑĞµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾\n",
      "ğŸ“Š Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ² Ñ„Ğ°Ğ¹Ğ»Ñ‹\n",
      "ğŸ’° Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ½Ğ¾Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}