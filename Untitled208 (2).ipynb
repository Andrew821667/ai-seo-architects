{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tBLh9XNpOSB",
        "outputId": "45f25dea-3071-48b6-d0a0-7c546406db62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ –ö–õ–û–ù–ò–†–û–í–ê–ù–ò–ï AI SEO ARCHITECTS\n",
            "=============================================\n",
            "üîó –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π: https://github.com/Andrew821667/ai-seo-architects.git\n",
            "üìÅ –õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å: /content/ai-seo-architects\n",
            "‚¨áÔ∏è –ö–ª–æ–Ω–∏—Ä—É–µ–º –ø—Ä–æ–µ–∫—Ç...\n",
            "‚úÖ –ü—Ä–æ–µ–∫—Ç —É—Å–ø–µ—à–Ω–æ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω!\n",
            "üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è agents –Ω–∞–π–¥–µ–Ω–∞\n",
            "üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è core –Ω–∞–π–¥–µ–Ω–∞\n",
            "üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è knowledge –Ω–∞–π–¥–µ–Ω–∞\n",
            "üìç –†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: /content/ai-seo-architects\n",
            "‚úÖ –ü—É—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω –≤ Python path\n",
            "\n",
            "üéØ –°–¢–ê–¢–£–°: –ü—Ä–æ–µ–∫—Ç –≥–æ—Ç–æ–≤ –∫ —É—Å—Ç–∞–Ω–æ–≤–∫–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n",
            "‚û°Ô∏è –ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ —Å–ª–µ–¥—É—é—â–µ–π —è—á–µ–π–∫–µ\n"
          ]
        }
      ],
      "source": [
        "# üì¶ –Ø–ß–ï–ô–ö–ê 1: –ö–õ–û–ù–ò–†–û–í–ê–ù–ò–ï –ü–†–û–ï–ö–¢–ê AI SEO ARCHITECTS\n",
        "print(\"üì¶ –ö–õ–û–ù–ò–†–û–í–ê–ù–ò–ï AI SEO ARCHITECTS\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è\n",
        "REPO_URL = \"https://github.com/Andrew821667/ai-seo-architects.git\"\n",
        "LOCAL_PATH = \"/content/ai-seo-architects\"\n",
        "\n",
        "print(f\"üîó –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π: {REPO_URL}\")\n",
        "print(f\"üìÅ –õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å: {LOCAL_PATH}\")\n",
        "\n",
        "# –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é –≤–µ—Ä—Å–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å\n",
        "if os.path.exists(LOCAL_PATH):\n",
        "    print(\"üóëÔ∏è –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é –≤–µ—Ä—Å–∏—é –ø—Ä–æ–µ–∫—Ç–∞...\")\n",
        "    subprocess.run(['rm', '-rf', LOCAL_PATH], capture_output=True)\n",
        "\n",
        "# –ö–ª–æ–Ω–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π\n",
        "print(\"‚¨áÔ∏è –ö–ª–æ–Ω–∏—Ä—É–µ–º –ø—Ä–æ–µ–∫—Ç...\")\n",
        "try:\n",
        "    result = subprocess.run(['git', 'clone', REPO_URL, LOCAL_PATH],\n",
        "                          capture_output=True, text=True)\n",
        "\n",
        "    if result.returncode == 0:\n",
        "        print(\"‚úÖ –ü—Ä–æ–µ–∫—Ç —É—Å–ø–µ—à–Ω–æ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω!\")\n",
        "\n",
        "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É\n",
        "        if os.path.exists(f\"{LOCAL_PATH}/agents\"):\n",
        "            print(\"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è agents –Ω–∞–π–¥–µ–Ω–∞\")\n",
        "        if os.path.exists(f\"{LOCAL_PATH}/core\"):\n",
        "            print(\"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è core –Ω–∞–π–¥–µ–Ω–∞\")\n",
        "        if os.path.exists(f\"{LOCAL_PATH}/knowledge\"):\n",
        "            print(\"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è knowledge –Ω–∞–π–¥–µ–Ω–∞\")\n",
        "\n",
        "        # –ú–µ–Ω—è–µ–º —Ä–∞–±–æ—á—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é\n",
        "        os.chdir(LOCAL_PATH)\n",
        "        print(f\"üìç –†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.getcwd()}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"‚ùå –û—à–∏–±–∫–∞ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: {result.stderr}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}\")\n",
        "\n",
        "# –î–æ–±–∞–≤–ª—è–µ–º –≤ Python path\n",
        "import sys\n",
        "if LOCAL_PATH not in sys.path:\n",
        "    sys.path.insert(0, LOCAL_PATH)\n",
        "    print(\"‚úÖ –ü—É—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω –≤ Python path\")\n",
        "\n",
        "print(\"\\nüéØ –°–¢–ê–¢–£–°: –ü—Ä–æ–µ–∫—Ç –≥–æ—Ç–æ–≤ –∫ —É—Å—Ç–∞–Ω–æ–≤–∫–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\")\n",
        "print(\"‚û°Ô∏è –ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ —Å–ª–µ–¥—É—é—â–µ–π —è—á–µ–π–∫–µ\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üì¶ –Ø–ß–ï–ô–ö–ê 2: –£–°–¢–ê–ù–û–í–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô –ë–ï–ó –ö–û–ù–§–õ–ò–ö–¢–û–í\n",
        "print(\"üì¶ –£–°–¢–ê–ù–û–í–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô AI SEO ARCHITECTS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# –ò—Å–ø—Ä–∞–≤–ª—è–µ–º numpy/pandas –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã –∑–∞—Ä–∞–Ω–µ–µ\n",
        "print(\"üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò NUMPY/PANDAS:\")\n",
        "try:\n",
        "    # –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ –≤–µ—Ä—Å–∏–∏\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', '-q', 'numpy'],\n",
        "                   capture_output=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'numpy==1.24.3'],\n",
        "                   capture_output=True)\n",
        "    print(\"‚úÖ NumPy 1.24.3 —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
        "\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', '-q', 'pandas'],\n",
        "                   capture_output=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'pandas==2.0.3'],\n",
        "                   capture_output=True)\n",
        "    print(\"‚úÖ Pandas 2.0.3 —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: {e}\")\n",
        "\n",
        "# –ö–ª—é—á–µ–≤—ã–µ –ø–∞–∫–µ—Ç—ã –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞\n",
        "required_packages = [\n",
        "    'openai==1.35.0',           # –°–æ–≤–º–µ—Å—Ç–∏–º–∞—è —Å Colab –≤–µ—Ä—Å–∏—è\n",
        "    'langgraph==0.2.39',\n",
        "    'langchain==0.2.16',\n",
        "    'langchain-openai==0.1.25',\n",
        "    'langchain-community==0.2.17',\n",
        "    'faiss-cpu==1.7.4',\n",
        "    'pydantic==2.9.2',\n",
        "    'nest-asyncio==1.6.0',\n",
        "    'python-dotenv==1.0.1'\n",
        "]\n",
        "\n",
        "print(f\"\\nüîß –£–°–¢–ê–ù–û–í–ö–ê {len(required_packages)} –ö–õ–Æ–ß–ï–í–´–• –ü–ê–ö–ï–¢–û–í:\")\n",
        "success_count = 0\n",
        "\n",
        "for package in required_packages:\n",
        "    try:\n",
        "        package_name = package.split('==')[0]\n",
        "        print(f\"‚è≥ {package_name}...\", end=' ')\n",
        "\n",
        "        result = subprocess.run(\n",
        "            [sys.executable, '-m', 'pip', 'install', '-q', package],\n",
        "            capture_output=True, text=True\n",
        "        )\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print(\"‚úÖ\")\n",
        "            success_count += 1\n",
        "        else:\n",
        "            print(f\"‚ùå\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"üí•\")\n",
        "\n",
        "print(f\"\\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢: {success_count}/{len(required_packages)} —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ\")\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏–º–ø–æ—Ä—Ç—ã\n",
        "print(\"\\nüß™ –ü–†–û–í–ï–†–ö–ê –ò–ú–ü–û–†–¢–û–í:\")\n",
        "critical_imports = [\n",
        "    ('openai', 'OpenAI –∫–ª–∏–µ–Ω—Ç'),\n",
        "    ('langgraph', 'LangGraph –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä'),\n",
        "    ('langchain', 'LangChain —Ñ—Ä–µ–π–º–≤–æ—Ä–∫'),\n",
        "    ('faiss', 'FAISS –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î'),\n",
        "    ('numpy', 'NumPy'),\n",
        "    ('nest_asyncio', 'Async –ø–æ–¥–¥–µ—Ä–∂–∫–∞')\n",
        "]\n",
        "\n",
        "working_imports = 0\n",
        "for module, description in critical_imports:\n",
        "    try:\n",
        "        __import__(module)\n",
        "        print(f\"‚úÖ {description}\")\n",
        "        working_imports += 1\n",
        "    except ImportError:\n",
        "        print(f\"‚ùå {description}\")\n",
        "    except ValueError as e:\n",
        "        if \"numpy.dtype size changed\" in str(e):\n",
        "            print(f\"‚ö†Ô∏è {description} (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –û–ö)\")\n",
        "            working_imports += 1\n",
        "        else:\n",
        "            print(f\"‚ùå {description}\")\n",
        "\n",
        "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ async –¥–ª—è Jupyter\n",
        "try:\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "    print(\"‚úÖ Async –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞\")\n",
        "    working_imports += 1\n",
        "except:\n",
        "    print(\"‚ùå Async –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞\")\n",
        "\n",
        "# –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞\n",
        "if working_imports >= 5:\n",
        "    print(f\"\\nüöÄ –û–¢–õ–ò–ß–ù–û! {working_imports}/{len(critical_imports)+1} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –≥–æ—Ç–æ–≤—ã\")\n",
        "    print(\"‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ OpenAI API\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è –ß–ê–°–¢–ò–ß–ù–ê–Ø –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å: {working_imports}/{len(critical_imports)+1}\")\n",
        "    print(\"üîß –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã\")\n",
        "\n",
        "print(\"\\nüéØ –°–¢–ê–¢–£–°: –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≥–æ—Ç–æ–≤—ã\")\n",
        "print(\"‚û°Ô∏è –ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ OpenAI API\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMH2dcqPpTCY",
        "outputId": "1989e64a-1847-40ab-b6b1-6bae47da4094"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ –£–°–¢–ê–ù–û–í–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô AI SEO ARCHITECTS\n",
            "==================================================\n",
            "üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò NUMPY/PANDAS:\n",
            "‚úÖ NumPy 1.24.3 —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\n",
            "‚úÖ Pandas 2.0.3 —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\n",
            "\n",
            "üîß –£–°–¢–ê–ù–û–í–ö–ê 9 –ö–õ–Æ–ß–ï–í–´–• –ü–ê–ö–ï–¢–û–í:\n",
            "‚è≥ openai... ‚úÖ\n",
            "‚è≥ langgraph... ‚úÖ\n",
            "‚è≥ langchain... ‚úÖ\n",
            "‚è≥ langchain-openai... ‚úÖ\n",
            "‚è≥ langchain-community... ‚úÖ\n",
            "‚è≥ faiss-cpu... ‚úÖ\n",
            "‚è≥ pydantic... ‚úÖ\n",
            "‚è≥ nest-asyncio... ‚úÖ\n",
            "‚è≥ python-dotenv... ‚úÖ\n",
            "\n",
            "üìä –†–ï–ó–£–õ–¨–¢–ê–¢: 9/9 —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ\n",
            "\n",
            "üß™ –ü–†–û–í–ï–†–ö–ê –ò–ú–ü–û–†–¢–û–í:\n",
            "‚úÖ OpenAI –∫–ª–∏–µ–Ω—Ç\n",
            "‚úÖ LangGraph –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä\n",
            "‚úÖ LangChain —Ñ—Ä–µ–π–º–≤–æ—Ä–∫\n",
            "‚úÖ FAISS –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î\n",
            "‚úÖ NumPy\n",
            "‚úÖ Async –ø–æ–¥–¥–µ—Ä–∂–∫–∞\n",
            "‚úÖ Async –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞\n",
            "\n",
            "üöÄ –û–¢–õ–ò–ß–ù–û! 7/7 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –≥–æ—Ç–æ–≤—ã\n",
            "‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ OpenAI API\n",
            "\n",
            "üéØ –°–¢–ê–¢–£–°: –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≥–æ—Ç–æ–≤—ã\n",
            "‚û°Ô∏è –ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ OpenAI API\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üîë –Ø–ß–ï–ô–ö–ê 3: –ù–ê–°–¢–†–û–ô–ö–ê OPENAI API –î–õ–Ø –†–ï–ê–õ–¨–ù–û–ô –†–ê–ë–û–¢–´ –ê–ì–ï–ù–¢–û–í\n",
        "print(\"üîë –ù–ê–°–¢–†–û–ô–ö–ê OPENAI API –î–õ–Ø –ê–ì–ï–ù–¢–û–í\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# –û—á–∏—â–∞–µ–º –≤—Å–µ proxy –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ä–∞–∑—É\n",
        "print(\"üßπ –û—á–∏—â–∞–µ–º proxy –Ω–∞—Å—Ç—Ä–æ–π–∫–∏...\")\n",
        "proxy_vars = ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy', 'ALL_PROXY', 'all_proxy']\n",
        "for var in proxy_vars:\n",
        "    os.environ.pop(var, None)\n",
        "print(\"‚úÖ Proxy –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ—á–∏—â–µ–Ω—ã\")\n",
        "\n",
        "# –ü–æ–ª—É—á–∞–µ–º API –∫–ª—é—á\n",
        "print(\"üîç –ü–æ–ª—É—á–∞–µ–º OpenAI API –∫–ª—é—á...\")\n",
        "api_key = None\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    api_key = userdata.get('OPENAI_API_KEY')\n",
        "    if api_key:\n",
        "        print(f\"‚úÖ –ö–ª—é—á –ø–æ–ª—É—á–µ–Ω: {api_key[:7]}...{api_key[-8:]}\")\n",
        "        print(f\"üî¢ –î–ª–∏–Ω–∞: {len(api_key)} —Å–∏–º–≤–æ–ª–æ–≤\")\n",
        "    else:\n",
        "        raise Exception(\"–ö–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå –û—à–∏–±–∫–∞: {e}\")\n",
        "    print(\"\\nüìù –ù–ê–°–¢–†–û–ô–¢–ï API –ö–õ–Æ–ß:\")\n",
        "    print(\"1. –ù–∞–∂–º–∏—Ç–µ üîë –≤ –ª–µ–≤–æ–º –º–µ–Ω—é Colab\")\n",
        "    print(\"2. –î–æ–±–∞–≤—å—Ç–µ: Name = OPENAI_API_KEY\")\n",
        "    print(\"3. Value = –≤–∞—à –∫–ª—é—á –æ—Ç OpenAI\")\n",
        "    print(\"4. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ —ç—Ç—É —è—á–µ–π–∫—É\")\n",
        "    raise Exception(\"OpenAI API –∫–ª—é—á –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω!\")\n",
        "\n",
        "# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–ª—é—á –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "# –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ø–æ—Å–æ–±–æ–≤ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è\n",
        "print(\"\\nüß™ –¢–ï–°–¢–ò–†–£–ï–ú OPENAI API...\")\n",
        "\n",
        "# –°–ø–æ—Å–æ–± 1: –ß–µ—Ä–µ–∑ requests (–æ–±—Ö–æ–¥–∏—Ç proxy –ø—Ä–æ–±–ª–µ–º—ã)\n",
        "import requests\n",
        "import json\n",
        "\n",
        "def test_openai_requests():\n",
        "    \"\"\"–¢–µ—Å—Ç —á–µ—Ä–µ–∑ –ø—Ä—è–º—ã–µ HTTP –∑–∞–ø—Ä–æ—Å—ã\"\"\"\n",
        "    try:\n",
        "        url = \"https://api.openai.com/v1/chat/completions\"\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {api_key}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        data = {\n",
        "            \"model\": \"gpt-4o-mini\",\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": \"–û—Ç–≤–µ—Ç—å: API —Ä–∞–±–æ—Ç–∞–µ—Ç\"}],\n",
        "            \"max_tokens\": 10\n",
        "        }\n",
        "\n",
        "        response = requests.post(url, headers=headers, json=data, timeout=30)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            content = result['choices'][0]['message']['content']\n",
        "            tokens = result['usage']['total_tokens']\n",
        "            return {\"success\": True, \"content\": content, \"tokens\": tokens, \"method\": \"requests\"}\n",
        "        else:\n",
        "            return {\"success\": False, \"error\": f\"HTTP {response.status_code}\"}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "# –°–ø–æ—Å–æ–± 2: –ß–µ—Ä–µ–∑ OpenAI library —Å –æ–±—Ö–æ–¥–æ–º proxy\n",
        "def test_openai_library():\n",
        "    \"\"\"–¢–µ—Å—Ç —á–µ—Ä–µ–∑ OpenAI library\"\"\"\n",
        "    try:\n",
        "        import openai\n",
        "\n",
        "        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–ª—é—á –Ω–∞–ø—Ä—è–º—É—é\n",
        "        openai.api_key = api_key\n",
        "\n",
        "        # –¢–µ—Å—Ç —á–µ—Ä–µ–∑ –Ω–æ–≤—ã–π API\n",
        "        response = openai.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": \"–û—Ç–≤–µ—Ç—å: Library —Ä–∞–±–æ—Ç–∞–µ—Ç\"}],\n",
        "            max_tokens=10\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"content\": response.choices[0].message.content,\n",
        "            \"tokens\": response.usage.total_tokens,\n",
        "            \"method\": \"library\"\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"success\": False, \"error\": str(e)}\n",
        "\n",
        "# –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±–∞ —Å–ø–æ—Å–æ–±–∞\n",
        "print(\"1Ô∏è‚É£ –¢–µ—Å—Ç —á–µ—Ä–µ–∑ requests...\")\n",
        "requests_result = test_openai_requests()\n",
        "if requests_result[\"success\"]:\n",
        "    print(f\"   ‚úÖ –£—Å–ø–µ—Ö! –û—Ç–≤–µ—Ç: '{requests_result['content']}'\")\n",
        "    print(f\"   üî¢ –¢–æ–∫–µ–Ω—ã: {requests_result['tokens']}\")\n",
        "else:\n",
        "    print(f\"   ‚ùå –û—à–∏–±–∫–∞: {requests_result['error'][:100]}\")\n",
        "\n",
        "print(\"2Ô∏è‚É£ –¢–µ—Å—Ç —á–µ—Ä–µ–∑ OpenAI library...\")\n",
        "library_result = test_openai_library()\n",
        "if library_result[\"success\"]:\n",
        "    print(f\"   ‚úÖ –£—Å–ø–µ—Ö! –û—Ç–≤–µ—Ç: '{library_result['content']}'\")\n",
        "    print(f\"   üî¢ –¢–æ–∫–µ–Ω—ã: {library_result['tokens']}\")\n",
        "else:\n",
        "    print(f\"   ‚ùå –û—à–∏–±–∫–∞: {library_result['error'][:100]}\")\n",
        "\n",
        "# –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π —Ä–∞–±–æ—á–∏–π –º–µ—Ç–æ–¥\n",
        "working_method = None\n",
        "if requests_result[\"success\"]:\n",
        "    working_method = \"requests\"\n",
        "    print(\"\\nüéØ –í–´–ë–†–ê–ù –ú–ï–¢–û–î: HTTP requests (–Ω–∞–¥–µ–∂–Ω—ã–π)\")\n",
        "elif library_result[\"success\"]:\n",
        "    working_method = \"library\"\n",
        "    print(\"\\nüéØ –í–´–ë–†–ê–ù –ú–ï–¢–û–î: OpenAI library\")\n",
        "else:\n",
        "    print(\"\\n‚ùå –ù–ò –û–î–ò–ù –ú–ï–¢–û–î –ù–ï –†–ê–ë–û–¢–ê–ï–¢!\")\n",
        "    raise Exception(\"OpenAI API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!\")\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤\n",
        "def universal_openai_call(messages, model=\"gpt-4o-mini\", max_tokens=2000, temperature=0.3):\n",
        "    \"\"\"–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ OpenAI API –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤\"\"\"\n",
        "\n",
        "    if working_method == \"requests\":\n",
        "        try:\n",
        "            url = \"https://api.openai.com/v1/chat/completions\"\n",
        "            headers = {\n",
        "                \"Authorization\": f\"Bearer {api_key}\",\n",
        "                \"Content-Type\": \"application/json\"\n",
        "            }\n",
        "            data = {\n",
        "                \"model\": model,\n",
        "                \"messages\": messages,\n",
        "                \"max_tokens\": max_tokens,\n",
        "                \"temperature\": temperature\n",
        "            }\n",
        "\n",
        "            response = requests.post(url, headers=headers, json=data, timeout=60)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                result = response.json()\n",
        "                return {\n",
        "                    \"success\": True,\n",
        "                    \"content\": result['choices'][0]['message']['content'],\n",
        "                    \"tokens\": result['usage']['total_tokens'],\n",
        "                    \"method\": \"requests\"\n",
        "                }\n",
        "            else:\n",
        "                return {\"success\": False, \"error\": f\"HTTP {response.status_code}: {response.text}\"}\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\"success\": False, \"error\": f\"Requests error: {str(e)}\"}\n",
        "\n",
        "    elif working_method == \"library\":\n",
        "        try:\n",
        "            import openai\n",
        "            response = openai.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=messages,\n",
        "                max_tokens=max_tokens,\n",
        "                temperature=temperature\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"content\": response.choices[0].message.content,\n",
        "                \"tokens\": response.usage.total_tokens,\n",
        "                \"method\": \"library\"\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\"success\": False, \"error\": f\"Library error: {str(e)}\"}\n",
        "\n",
        "    else:\n",
        "        return {\"success\": False, \"error\": \"No working method available\"}\n",
        "\n",
        "# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é –≥–ª–æ–±–∞–ª—å–Ω–æ –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤\n",
        "globals()['UNIVERSAL_OPENAI_CALL'] = universal_openai_call\n",
        "globals()['OPENAI_API_KEY'] = api_key\n",
        "globals()['OPENAI_WORKING_METHOD'] = working_method\n",
        "\n",
        "# –§–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç —Ñ—É–Ω–∫—Ü–∏–∏\n",
        "print(\"\\nüî¨ –§–ò–ù–ê–õ–¨–ù–´–ô –¢–ï–°–¢ –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–û–ô –§–£–ù–ö–¶–ò–ò:\")\n",
        "test_messages = [{\"role\": \"user\", \"content\": \"–°–∫–∞–∂–∏ '–°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞!' –Ω–∞ —Ä—É—Å—Å–∫–æ–º\"}]\n",
        "final_result = universal_openai_call(test_messages, max_tokens=10)\n",
        "\n",
        "if final_result[\"success\"]:\n",
        "    print(f\"‚úÖ –§—É–Ω–∫—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç: {final_result['content']}\")\n",
        "    print(f\"üî¢ –¢–æ–∫–µ–Ω—ã: {final_result['tokens']}\")\n",
        "    print(f\"üõ†Ô∏è –ú–µ—Ç–æ–¥: {final_result['method']}\")\n",
        "    print(\"\\nüéâ OPENAI API –ü–û–õ–ù–û–°–¢–¨–Æ –ì–û–¢–û–í –î–õ–Ø –ê–ì–ï–ù–¢–û–í!\")\n",
        "    print(\"‚úÖ –§—É–Ω–∫—Ü–∏—è UNIVERSAL_OPENAI_CALL –¥–æ—Å—Ç—É–ø–Ω–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ\")\n",
        "else:\n",
        "    print(f\"‚ùå –û—à–∏–±–∫–∞: {final_result['error']}\")\n",
        "    raise Exception(\"–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç!\")\n",
        "\n",
        "print(\"\\nüéØ –°–¢–ê–¢–£–°: OpenAI API –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω\")\n",
        "print(\"‚û°Ô∏è –ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—é –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è API\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_1i7Y0Vqbvz",
        "outputId": "b313659b-bf32-468a-f140-1435be576cd4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîë –ù–ê–°–¢–†–û–ô–ö–ê OPENAI API –î–õ–Ø –ê–ì–ï–ù–¢–û–í\n",
            "========================================\n",
            "üßπ –û—á–∏—â–∞–µ–º proxy –Ω–∞—Å—Ç—Ä–æ–π–∫–∏...\n",
            "‚úÖ Proxy –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ—á–∏—â–µ–Ω—ã\n",
            "üîç –ü–æ–ª—É—á–∞–µ–º OpenAI API –∫–ª—é—á...\n",
            "‚úÖ –ö–ª—é—á –ø–æ–ª—É—á–µ–Ω: sk-proj...CeCqIqgA\n",
            "üî¢ –î–ª–∏–Ω–∞: 164 —Å–∏–º–≤–æ–ª–æ–≤\n",
            "\n",
            "üß™ –¢–ï–°–¢–ò–†–£–ï–ú OPENAI API...\n",
            "1Ô∏è‚É£ –¢–µ—Å—Ç —á–µ—Ä–µ–∑ requests...\n",
            "   ‚úÖ –£—Å–ø–µ—Ö! –û—Ç–≤–µ—Ç: '–î–∞, API —Ä–∞–±–æ—Ç–∞–µ—Ç. –ï—Å–ª–∏ —É —Ç–µ–±—è –µ—Å—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç'\n",
            "   üî¢ –¢–æ–∫–µ–Ω—ã: 22\n",
            "2Ô∏è‚É£ –¢–µ—Å—Ç —á–µ—Ä–µ–∑ OpenAI library...\n",
            "   ‚úÖ –£—Å–ø–µ—Ö! –û—Ç–≤–µ—Ç: '–î–∞, –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç. –ö–∞–∫–æ–π —É –≤–∞—Å'\n",
            "   üî¢ –¢–æ–∫–µ–Ω—ã: 22\n",
            "\n",
            "üéØ –í–´–ë–†–ê–ù –ú–ï–¢–û–î: HTTP requests (–Ω–∞–¥–µ–∂–Ω—ã–π)\n",
            "\n",
            "üî¨ –§–ò–ù–ê–õ–¨–ù–´–ô –¢–ï–°–¢ –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–û–ô –§–£–ù–ö–¶–ò–ò:\n",
            "‚úÖ –§—É–Ω–∫—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç: –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞!\n",
            "üî¢ –¢–æ–∫–µ–Ω—ã: 23\n",
            "üõ†Ô∏è –ú–µ—Ç–æ–¥: requests\n",
            "\n",
            "üéâ OPENAI API –ü–û–õ–ù–û–°–¢–¨–Æ –ì–û–¢–û–í –î–õ–Ø –ê–ì–ï–ù–¢–û–í!\n",
            "‚úÖ –§—É–Ω–∫—Ü–∏—è UNIVERSAL_OPENAI_CALL –¥–æ—Å—Ç—É–ø–Ω–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ\n",
            "\n",
            "üéØ –°–¢–ê–¢–£–°: OpenAI API –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω\n",
            "‚û°Ô∏è –ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—é –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è API\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üîç –ê–ù–ê–õ–ò–ó –°–¢–†–£–ö–¢–£–†–´ –ü–†–û–ï–ö–¢–ê AI SEO ARCHITECTS\n",
        "print(\"üîç –ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó –°–¢–†–£–ö–¢–£–†–´ –ü–†–û–ï–ö–¢–ê\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É\n",
        "project_path = \"/content/ai-seo-architects\"\n",
        "\n",
        "print(\"\\nüìÅ –°–¢–†–£–ö–¢–£–†–ê –ü–ê–ü–ö–ò agents/:\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ —É—Ä–æ–≤–Ω–∏ –∞–≥–µ–Ω—Ç–æ–≤\n",
        "levels = ['executive', 'management', 'operational']\n",
        "\n",
        "for level in levels:\n",
        "    level_path = os.path.join(project_path, 'agents', level)\n",
        "    print(f\"\\nüìÇ {level.upper()} LEVEL:\")\n",
        "    if os.path.exists(level_path):\n",
        "        files = [f for f in os.listdir(level_path) if f.endswith('.py') and not f.startswith('__')]\n",
        "        for file in sorted(files):\n",
        "            file_path = os.path.join(level_path, file)\n",
        "            file_size = os.path.getsize(file_path)\n",
        "            print(f\"   ‚úÖ {file} ({file_size:,} bytes)\")\n",
        "\n",
        "            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª–∞—Å—Å–∞ –≤ —Ñ–∞–π–ª–µ\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "                if 'class ' in content:\n",
        "                    # –ù–∞—Ö–æ–¥–∏–º –∏–º—è –∫–ª–∞—Å—Å–∞\n",
        "                    for line in content.split('\\n'):\n",
        "                        if 'class ' in line and 'Agent' in line:\n",
        "                            class_name = line.split('class ')[1].split('(')[0].strip()\n",
        "                            print(f\"      ‚îî‚îÄ –ö–ª–∞—Å—Å: {class_name}\")\n",
        "                            break\n",
        "    else:\n",
        "        print(f\"   ‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ê–ì–ï–ù–¢–û–í:\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–≥–µ–Ω—Ç–æ–≤\n",
        "total_agents = 0\n",
        "agent_list = []\n",
        "\n",
        "for level in levels:\n",
        "    level_path = os.path.join(project_path, 'agents', level)\n",
        "    if os.path.exists(level_path):\n",
        "        py_files = [f for f in os.listdir(level_path) if f.endswith('.py') and not f.startswith('__')]\n",
        "        total_agents += len(py_files)\n",
        "        for f in py_files:\n",
        "            agent_name = f.replace('.py', '').replace('_', ' ').title()\n",
        "            agent_list.append((level, agent_name, f))\n",
        "\n",
        "print(f\"ü§ñ –í–°–ï–ì–û –ù–ê–ô–î–ï–ù–û –ê–ì–ï–ù–¢–û–í: {total_agents}\")\n",
        "print(\"\\nüìã –ü–û–õ–ù–´–ô –°–ü–ò–°–û–ö –ê–ì–ï–ù–¢–û–í:\")\n",
        "for level, name, filename in agent_list:\n",
        "    print(f\"   [{level:12}] {name:40} ({filename})\")\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä—è–µ–º knowledge –±–∞–∑—ã\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üìö –ë–ê–ó–´ –ó–ù–ê–ù–ò–ô (knowledge/):\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "knowledge_path = os.path.join(project_path, 'knowledge')\n",
        "for level in levels:\n",
        "    level_path = os.path.join(knowledge_path, level)\n",
        "    print(f\"\\nüìÇ {level.upper()} KNOWLEDGE:\")\n",
        "    if os.path.exists(level_path):\n",
        "        files = [f for f in os.listdir(level_path) if f.endswith('.md')]\n",
        "        for file in sorted(files):\n",
        "            file_path = os.path.join(level_path, file)\n",
        "            file_size = os.path.getsize(file_path)\n",
        "            print(f\"   üìÑ {file} ({file_size:,} bytes)\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JDYDsCaiSgV",
        "outputId": "0a276f6f-0325-4067-f68b-79e97aefcc92"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç –ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó –°–¢–†–£–ö–¢–£–†–´ –ü–†–û–ï–ö–¢–ê\n",
            "============================================================\n",
            "\n",
            "üìÅ –°–¢–†–£–ö–¢–£–†–ê –ü–ê–ü–ö–ò agents/:\n",
            "------------------------------------------------------------\n",
            "\n",
            "üìÇ EXECUTIVE LEVEL:\n",
            "   ‚úÖ business_development_director.py (41,370 bytes)\n",
            "      ‚îî‚îÄ –ö–ª–∞—Å—Å: BusinessDevelopmentDirectorAgent\n",
            "   ‚úÖ chief_seo_strategist.py (53,501 bytes)\n",
            "      ‚îî‚îÄ –ö–ª–∞—Å—Å: ChiefSEOStrategistAgent\n",
            "\n",
            "üìÇ MANAGEMENT LEVEL:\n",
            "   ‚úÖ client_success_manager.py (42,133 bytes)\n",
            "      ‚îî‚îÄ –ö–ª–∞—Å—Å: ClientSuccessManagerAgent\n",
            "   ‚úÖ sales_operations_manager.py (54,550 bytes)\n",
            "      ‚îî‚îÄ –ö–ª–∞—Å—Å: SalesOperationsManagerAgent\n",
            "   ‚úÖ task_coordination.py (15,453 bytes)\n",
            "      ‚îî‚îÄ –ö–ª–∞—Å—Å: TaskCoordinationAgent\n",
            "   ‚úÖ technical_seo_operations_manager.py (51,679 bytes)\n",
            "      ‚îî‚îÄ –ö–ª–∞—Å—Å: TechnicalSEOOperationsManagerAgent\n",
            "\n",
            "üìÇ OPERATIONAL LEVEL:\n",
            "   ‚úÖ competitive_analysis.py (70,304 bytes)\n",
            "      ‚îî‚îÄ –ö–ª–∞—Å—Å: CompetitiveAnalysisAgent\n",
            "   ‚úÖ content_strategy.py (90,080 bytes)\n",
            "      ‚îî‚îÄ –ö–ª–∞—Å—Å: ContentStrategyAgent\n",
            "   ‚úÖ lead_qualification.py (49,091 bytes)\n",
            "      ‚îî‚îÄ –ö–ª–∞—Å—Å: LeadQualificationAgent\n",
            "   ‚úÖ link_building.py (50,254 bytes)\n",
            "      ‚îî‚îÄ –ö–ª–∞—Å—Å: LinkBuildingAgent\n",
            "   ‚úÖ proposal_generation.py (46,877 bytes)\n",
            "      ‚îî‚îÄ –ö–ª–∞—Å—Å: ProposalGenerationAgent\n",
            "   ‚úÖ reporting.py (59,504 bytes)\n",
            "      ‚îî‚îÄ –ö–ª–∞—Å—Å: ReportingAgent\n",
            "   ‚úÖ sales_conversation.py (39,993 bytes)\n",
            "      ‚îî‚îÄ –ö–ª–∞—Å—Å: SalesConversationAgent\n",
            "   ‚úÖ technical_seo_auditor.py (62,401 bytes)\n",
            "      ‚îî‚îÄ –ö–ª–∞—Å—Å: TechnicalSEOAuditorAgent\n",
            "\n",
            "============================================================\n",
            "üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ê–ì–ï–ù–¢–û–í:\n",
            "------------------------------------------------------------\n",
            "ü§ñ –í–°–ï–ì–û –ù–ê–ô–î–ï–ù–û –ê–ì–ï–ù–¢–û–í: 14\n",
            "\n",
            "üìã –ü–û–õ–ù–´–ô –°–ü–ò–°–û–ö –ê–ì–ï–ù–¢–û–í:\n",
            "   [executive   ] Business Development Director            (business_development_director.py)\n",
            "   [executive   ] Chief Seo Strategist                     (chief_seo_strategist.py)\n",
            "   [management  ] Client Success Manager                   (client_success_manager.py)\n",
            "   [management  ] Technical Seo Operations Manager         (technical_seo_operations_manager.py)\n",
            "   [management  ] Sales Operations Manager                 (sales_operations_manager.py)\n",
            "   [management  ] Task Coordination                        (task_coordination.py)\n",
            "   [operational ] Link Building                            (link_building.py)\n",
            "   [operational ] Lead Qualification                       (lead_qualification.py)\n",
            "   [operational ] Sales Conversation                       (sales_conversation.py)\n",
            "   [operational ] Competitive Analysis                     (competitive_analysis.py)\n",
            "   [operational ] Content Strategy                         (content_strategy.py)\n",
            "   [operational ] Reporting                                (reporting.py)\n",
            "   [operational ] Proposal Generation                      (proposal_generation.py)\n",
            "   [operational ] Technical Seo Auditor                    (technical_seo_auditor.py)\n",
            "\n",
            "============================================================\n",
            "üìö –ë–ê–ó–´ –ó–ù–ê–ù–ò–ô (knowledge/):\n",
            "------------------------------------------------------------\n",
            "\n",
            "üìÇ EXECUTIVE KNOWLEDGE:\n",
            "   üìÑ business_development_director.md (22,769 bytes)\n",
            "   üìÑ chief_seo_strategist.md (24,395 bytes)\n",
            "\n",
            "üìÇ MANAGEMENT KNOWLEDGE:\n",
            "   üìÑ client_success_manager.md (32,436 bytes)\n",
            "   üìÑ sales_operations_manager.md (28,950 bytes)\n",
            "   üìÑ task_coordination.md (36,285 bytes)\n",
            "   üìÑ technical_seo_operations_manager.md (37,957 bytes)\n",
            "\n",
            "üìÇ OPERATIONAL KNOWLEDGE:\n",
            "   üìÑ competitive_analysis.md (18,152 bytes)\n",
            "   üìÑ content_strategy.md (27,644 bytes)\n",
            "   üìÑ lead_qualification.md (38,587 bytes)\n",
            "   üìÑ link_building.md (14,064 bytes)\n",
            "   üìÑ proposal_generation.md (36,072 bytes)\n",
            "   üìÑ reporting.md (17,706 bytes)\n",
            "   üìÑ sales_conversation.md (41,826 bytes)\n",
            "   üìÑ technical_seo_auditor.md (46,280 bytes)\n",
            "\n",
            "============================================================\n",
            "‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üß™ –ü–†–û–í–ï–†–ö–ê –ò–ú–ü–û–†–¢–ê –í–°–ï–• –ê–ì–ï–ù–¢–û–í\n",
        "print(\"üß™ –ü–†–û–í–ï–†–ö–ê –í–û–ó–ú–û–ñ–ù–û–°–¢–ò –ò–ú–ü–û–†–¢–ê –ê–ì–ï–ù–¢–û–í\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/ai-seo-architects')\n",
        "\n",
        "# –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
        "agents_to_check = [\n",
        "    # Executive Level\n",
        "    ('agents.executive.chief_seo_strategist', 'ChiefSEOStrategistAgent'),\n",
        "    ('agents.executive.business_development_director', 'BusinessDevelopmentDirectorAgent'),\n",
        "\n",
        "    # Management Level\n",
        "    ('agents.management.task_coordination', 'TaskCoordinationAgent'),\n",
        "    ('agents.management.sales_operations_manager', 'SalesOperationsManagerAgent'),\n",
        "    ('agents.management.technical_seo_operations_manager', 'TechnicalSEOOperationsManagerAgent'),\n",
        "    ('agents.management.client_success_manager', 'ClientSuccessManagerAgent'),\n",
        "\n",
        "    # Operational Level\n",
        "    ('agents.operational.lead_qualification', 'LeadQualificationAgent'),\n",
        "    ('agents.operational.sales_conversation', 'SalesConversationAgent'),\n",
        "    ('agents.operational.proposal_generation', 'ProposalGenerationAgent'),\n",
        "    ('agents.operational.technical_seo_auditor', 'TechnicalSEOAuditorAgent'),\n",
        "    ('agents.operational.content_strategy', 'ContentStrategyAgent'),\n",
        "    ('agents.operational.link_building', 'LinkBuildingAgent'),\n",
        "    ('agents.operational.competitive_analysis', 'CompetitiveAnalysisAgent'),\n",
        "    ('agents.operational.reporting', 'ReportingAgent'),\n",
        "]\n",
        "\n",
        "successful_imports = []\n",
        "failed_imports = []\n",
        "\n",
        "for module_path, class_name in agents_to_check:\n",
        "    try:\n",
        "        module = __import__(module_path, fromlist=[class_name])\n",
        "        if hasattr(module, class_name):\n",
        "            successful_imports.append((module_path, class_name))\n",
        "            print(f\"‚úÖ {class_name:45} - –ò–ú–ü–û–†–¢–ò–†–û–í–ê–ù\")\n",
        "        else:\n",
        "            failed_imports.append((module_path, class_name, \"–ö–ª–∞—Å—Å –Ω–µ –Ω–∞–π–¥–µ–Ω\"))\n",
        "            print(f\"‚ùå {class_name:45} - –ö–ª–∞—Å—Å –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –º–æ–¥—É–ª–µ\")\n",
        "    except ImportError as e:\n",
        "        failed_imports.append((module_path, class_name, str(e)))\n",
        "        print(f\"‚ùå {class_name:45} - –ú–æ–¥—É–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n",
        "    except Exception as e:\n",
        "        failed_imports.append((module_path, class_name, str(e)))\n",
        "        print(f\"‚ö†Ô∏è {class_name:45} - –û—à–∏–±–∫–∞: {str(e)[:50]}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´:\")\n",
        "print(f\"   ‚úÖ –£—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {len(successful_imports)} –∞–≥–µ–Ω—Ç–æ–≤\")\n",
        "print(f\"   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å: {len(failed_imports)} –∞–≥–µ–Ω—Ç–æ–≤\")\n",
        "print(f\"   üìä –ü—Ä–æ—Ü–µ–Ω—Ç –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏: {len(successful_imports)/14*100:.1f}%\")\n",
        "\n",
        "if successful_imports:\n",
        "    print(\"\\n‚úÖ –ì–û–¢–û–í–´–ï –ö –†–ê–ë–û–¢–ï –ê–ì–ï–ù–¢–´:\")\n",
        "    for module, cls in successful_imports:\n",
        "        print(f\"   ‚Ä¢ {cls}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eWDi1eZiZ5K",
        "outputId": "da29905d-1441-48bc-d5b8-b905009a01a8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ –ü–†–û–í–ï–†–ö–ê –í–û–ó–ú–û–ñ–ù–û–°–¢–ò –ò–ú–ü–û–†–¢–ê –ê–ì–ï–ù–¢–û–í\n",
            "============================================================\n",
            "‚úÖ ChiefSEOStrategistAgent                       - –ò–ú–ü–û–†–¢–ò–†–û–í–ê–ù\n",
            "‚úÖ BusinessDevelopmentDirectorAgent              - –ò–ú–ü–û–†–¢–ò–†–û–í–ê–ù\n",
            "‚úÖ TaskCoordinationAgent                         - –ò–ú–ü–û–†–¢–ò–†–û–í–ê–ù\n",
            "‚úÖ SalesOperationsManagerAgent                   - –ò–ú–ü–û–†–¢–ò–†–û–í–ê–ù\n",
            "‚úÖ TechnicalSEOOperationsManagerAgent            - –ò–ú–ü–û–†–¢–ò–†–û–í–ê–ù\n",
            "‚úÖ ClientSuccessManagerAgent                     - –ò–ú–ü–û–†–¢–ò–†–û–í–ê–ù\n",
            "‚úÖ LeadQualificationAgent                        - –ò–ú–ü–û–†–¢–ò–†–û–í–ê–ù\n",
            "‚úÖ SalesConversationAgent                        - –ò–ú–ü–û–†–¢–ò–†–û–í–ê–ù\n",
            "‚úÖ ProposalGenerationAgent                       - –ò–ú–ü–û–†–¢–ò–†–û–í–ê–ù\n",
            "‚úÖ TechnicalSEOAuditorAgent                      - –ò–ú–ü–û–†–¢–ò–†–û–í–ê–ù\n",
            "‚úÖ ContentStrategyAgent                          - –ò–ú–ü–û–†–¢–ò–†–û–í–ê–ù\n",
            "‚úÖ LinkBuildingAgent                             - –ò–ú–ü–û–†–¢–ò–†–û–í–ê–ù\n",
            "‚úÖ CompetitiveAnalysisAgent                      - –ò–ú–ü–û–†–¢–ò–†–û–í–ê–ù\n",
            "‚úÖ ReportingAgent                                - –ò–ú–ü–û–†–¢–ò–†–û–í–ê–ù\n",
            "\n",
            "============================================================\n",
            "üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´:\n",
            "   ‚úÖ –£—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: 14 –∞–≥–µ–Ω—Ç–æ–≤\n",
            "   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å: 0 –∞–≥–µ–Ω—Ç–æ–≤\n",
            "   üìä –ü—Ä–æ—Ü–µ–Ω—Ç –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏: 100.0%\n",
            "\n",
            "‚úÖ –ì–û–¢–û–í–´–ï –ö –†–ê–ë–û–¢–ï –ê–ì–ï–ù–¢–´:\n",
            "   ‚Ä¢ ChiefSEOStrategistAgent\n",
            "   ‚Ä¢ BusinessDevelopmentDirectorAgent\n",
            "   ‚Ä¢ TaskCoordinationAgent\n",
            "   ‚Ä¢ SalesOperationsManagerAgent\n",
            "   ‚Ä¢ TechnicalSEOOperationsManagerAgent\n",
            "   ‚Ä¢ ClientSuccessManagerAgent\n",
            "   ‚Ä¢ LeadQualificationAgent\n",
            "   ‚Ä¢ SalesConversationAgent\n",
            "   ‚Ä¢ ProposalGenerationAgent\n",
            "   ‚Ä¢ TechnicalSEOAuditorAgent\n",
            "   ‚Ä¢ ContentStrategyAgent\n",
            "   ‚Ä¢ LinkBuildingAgent\n",
            "   ‚Ä¢ CompetitiveAnalysisAgent\n",
            "   ‚Ä¢ ReportingAgent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üöÄ –Ø–ß–ï–ô–ö–ê 6: –ú–ê–°–°–û–í–ê–Ø –í–ï–ö–¢–û–†–ò–ó–ê–¶–ò–Ø –í–°–ï–• –ë–ê–ó –ó–ù–ê–ù–ò–ô –î–õ–Ø –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–ò\n",
        "print(\"üöÄ –ú–ê–°–°–û–í–ê–Ø –í–ï–ö–¢–û–†–ò–ó–ê–¶–ò–Ø –í–°–ï–• –ë–ê–ó –ó–ù–ê–ù–ò–ô AI SEO ARCHITECTS\")\n",
        "print(\"=\" * 70)\n",
        "print(\"–°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã –¥–ª—è –≤—Å–µ—Ö 14 –∞–≥–µ–Ω—Ç–æ–≤ –º–∏—Ä–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import hashlib\n",
        "\n",
        "# –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É\n",
        "project_path = \"/content/ai-seo-architects\"\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –±–∞–∑\n",
        "vector_store_path = f\"{project_path}/data/vector_stores\"\n",
        "os.makedirs(vector_store_path, exist_ok=True)\n",
        "\n",
        "print(f\"üìÅ –í–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {vector_store_path}\")\n",
        "\n",
        "# –§—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ OpenAI\n",
        "def create_embedding(text, model=\"text-embedding-ada-002\"):\n",
        "    \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —á–µ—Ä–µ–∑ OpenAI API\"\"\"\n",
        "    try:\n",
        "        import requests\n",
        "\n",
        "        api_key = globals().get('OPENAI_API_KEY')\n",
        "        if not api_key:\n",
        "            raise Exception(\"OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n",
        "\n",
        "        url = \"https://api.openai.com/v1/embeddings\"\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {api_key}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        data = {\n",
        "            \"model\": model,\n",
        "            \"input\": text\n",
        "        }\n",
        "\n",
        "        response = requests.post(url, headers=headers, json=data, timeout=30)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            return result['data'][0]['embedding']\n",
        "        else:\n",
        "            raise Exception(f\"API Error: {response.status_code}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}\")\n",
        "        return None\n",
        "\n",
        "# –§—É–Ω–∫—Ü–∏—è —Ä–∞–∑–±–∏–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏\n",
        "def split_text_into_chunks(text, chunk_size=2000, overlap=200):\n",
        "    \"\"\"–†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏–µ—Å—è —á–∞–Ω–∫–∏\"\"\"\n",
        "    chunks = []\n",
        "    words = text.split()\n",
        "\n",
        "    for i in range(0, len(words), chunk_size - overlap):\n",
        "        chunk_words = words[i:i + chunk_size]\n",
        "        chunk_text = ' '.join(chunk_words)\n",
        "        if len(chunk_text.strip()) > 100:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞\n",
        "            chunks.append({\n",
        "                'text': chunk_text,\n",
        "                'start_word': i,\n",
        "                'end_word': min(i + chunk_size, len(words)),\n",
        "                'word_count': len(chunk_words)\n",
        "            })\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π\n",
        "print(\"\\nüìä –ê–ù–ê–õ–ò–ó –í–°–ï–• –ë–ê–ó –ó–ù–ê–ù–ò–ô:\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "knowledge_base_path = f\"{project_path}/knowledge\"\n",
        "all_knowledge_files = []\n",
        "\n",
        "levels = ['executive', 'management', 'operational']\n",
        "for level in levels:\n",
        "    level_path = os.path.join(knowledge_base_path, level)\n",
        "    if os.path.exists(level_path):\n",
        "        md_files = glob.glob(f\"{level_path}/*.md\")\n",
        "        for file_path in md_files:\n",
        "            file_size = os.path.getsize(file_path)\n",
        "            file_name = os.path.basename(file_path)\n",
        "            agent_name = file_name.replace('.md', '')\n",
        "\n",
        "            all_knowledge_files.append({\n",
        "                'level': level,\n",
        "                'agent_name': agent_name,\n",
        "                'file_path': file_path,\n",
        "                'file_name': file_name,\n",
        "                'size_bytes': file_size,\n",
        "                'size_kb': file_size / 1024\n",
        "            })\n",
        "\n",
        "            print(f\"üìÑ {level:12} | {agent_name:35} | {file_size/1024:.1f} KB\")\n",
        "\n",
        "total_size_kb = sum([f['size_kb'] for f in all_knowledge_files])\n",
        "print(f\"\\nüìä –í–°–ï–ì–û –ù–ê–ô–î–ï–ù–û: {len(all_knowledge_files)} –±–∞–∑ –∑–Ω–∞–Ω–∏–π\")\n",
        "print(f\"üì¶ –û–ë–©–ò–ô –†–ê–ó–ú–ï–†: {total_size_kb:.1f} KB ({total_size_kb/1024:.1f} MB)\")\n",
        "\n",
        "# –ù–∞—á–∏–Ω–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—é\n",
        "print(f\"\\nüîÑ –ù–ê–ß–ò–ù–ê–ï–ú –í–ï–ö–¢–û–†–ò–ó–ê–¶–ò–Æ {len(all_knowledge_files)} –ë–ê–ó –ó–ù–ê–ù–ò–ô...\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "vectorization_results = []\n",
        "total_chunks = 0\n",
        "total_embeddings = 0\n",
        "\n",
        "for i, kb_file in enumerate(all_knowledge_files, 1):\n",
        "    print(f\"\\n{i:2d}/14 üîÑ {kb_file['agent_name']:35} ({kb_file['size_kb']:.1f} KB)\")\n",
        "\n",
        "    try:\n",
        "        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª\n",
        "        with open(kb_file['file_path'], 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\n",
        "        file_hash = hashlib.md5(content.encode()).hexdigest()[:8]\n",
        "\n",
        "        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏\n",
        "        chunks = split_text_into_chunks(content, chunk_size=1000, overlap=150)\n",
        "        print(f\"      üìù –°–æ–∑–¥–∞–Ω–æ {len(chunks)} —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤\")\n",
        "\n",
        "        # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞\n",
        "        chunk_embeddings = []\n",
        "        success_count = 0\n",
        "\n",
        "        for j, chunk in enumerate(chunks):\n",
        "            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∫ —á–∞–Ω–∫—É\n",
        "            contextualized_text = f\"\"\"\n",
        "–ê–≥–µ–Ω—Ç: {kb_file['agent_name']}\n",
        "–£—Ä–æ–≤–µ–Ω—å: {kb_file['level']}\n",
        "–†–∞–∑–¥–µ–ª {j+1}/{len(chunks)}:\n",
        "\n",
        "{chunk['text']}\n",
        "\"\"\"\n",
        "\n",
        "            embedding = create_embedding(contextualized_text.strip())\n",
        "            if embedding:\n",
        "                chunk_embeddings.append({\n",
        "                    'chunk_id': j,\n",
        "                    'text': chunk['text'][:500] + '...' if len(chunk['text']) > 500 else chunk['text'],\n",
        "                    'full_text': chunk['text'],\n",
        "                    'embedding': embedding,\n",
        "                    'word_count': chunk['word_count'],\n",
        "                    'metadata': {\n",
        "                        'agent': kb_file['agent_name'],\n",
        "                        'level': kb_file['level'],\n",
        "                        'chunk_index': j,\n",
        "                        'total_chunks': len(chunks),\n",
        "                        'file_hash': file_hash\n",
        "                    }\n",
        "                })\n",
        "                success_count += 1\n",
        "\n",
        "            # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤\n",
        "            if len(chunks) > 10 and (j + 1) % 5 == 0:\n",
        "                print(f\"         üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {j+1}/{len(chunks)} —á–∞–Ω–∫–æ–≤\")\n",
        "\n",
        "        print(f\"      ‚úÖ –°–æ–∑–¥–∞–Ω–æ {success_count}/{len(chunks)} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\")\n",
        "\n",
        "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –¥–ª—è –∞–≥–µ–Ω—Ç–∞\n",
        "        vector_file_path = f\"{vector_store_path}/{kb_file['agent_name']}_vectors.json\"\n",
        "\n",
        "        vector_data = {\n",
        "            'agent_name': kb_file['agent_name'],\n",
        "            'level': kb_file['level'],\n",
        "            'file_hash': file_hash,\n",
        "            'created_at': datetime.now().isoformat(),\n",
        "            'total_chunks': len(chunks),\n",
        "            'successful_embeddings': success_count,\n",
        "            'embedding_model': 'text-embedding-ada-002',\n",
        "            'embedding_dimension': 1536,\n",
        "            'chunks': chunk_embeddings\n",
        "        }\n",
        "\n",
        "        with open(vector_file_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(vector_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        file_size_mb = os.path.getsize(vector_file_path) / (1024 * 1024)\n",
        "        print(f\"      üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {os.path.basename(vector_file_path)} ({file_size_mb:.2f} MB)\")\n",
        "\n",
        "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
        "        vectorization_results.append({\n",
        "            'agent_name': kb_file['agent_name'],\n",
        "            'level': kb_file['level'],\n",
        "            'original_size_kb': kb_file['size_kb'],\n",
        "            'chunks_created': len(chunks),\n",
        "            'embeddings_created': success_count,\n",
        "            'vector_file_size_mb': file_size_mb,\n",
        "            'success_rate': success_count / len(chunks) * 100 if chunks else 0\n",
        "        })\n",
        "\n",
        "        total_chunks += len(chunks)\n",
        "        total_embeddings += success_count\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"      ‚ùå –û–®–ò–ë–ö–ê: {str(e)}\")\n",
        "        vectorization_results.append({\n",
        "            'agent_name': kb_file['agent_name'],\n",
        "            'level': kb_file['level'],\n",
        "            'error': str(e)\n",
        "        })\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üéØ –ò–¢–û–ì–ò –í–ï–ö–¢–û–†–ò–ó–ê–¶–ò–ò:\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "successful_agents = [r for r in vectorization_results if 'error' not in r]\n",
        "failed_agents = [r for r in vectorization_results if 'error' in r]\n",
        "\n",
        "print(f\"‚úÖ –£–°–ü–ï–®–ù–û –í–ï–ö–¢–û–†–ò–ó–û–í–ê–ù–û: {len(successful_agents)}/14 –∞–≥–µ–Ω—Ç–æ–≤\")\n",
        "print(f\"‚ùå –û–®–ò–ë–ö–ò: {len(failed_agents)} –∞–≥–µ–Ω—Ç–æ–≤\")\n",
        "print(f\"üì¶ –í–°–ï–ì–û –ß–ê–ù–ö–û–í: {total_chunks:,}\")\n",
        "print(f\"üß† –í–°–ï–ì–û –≠–ú–ë–ï–î–î–ò–ù–ì–û–í: {total_embeddings:,}\")\n",
        "\n",
        "if successful_agents:\n",
        "    total_vector_size = sum([r['vector_file_size_mb'] for r in successful_agents])\n",
        "    avg_success_rate = sum([r['success_rate'] for r in successful_agents]) / len(successful_agents)\n",
        "\n",
        "    print(f\"üíæ –†–ê–ó–ú–ï–† –í–ï–ö–¢–û–†–ù–´–• –ë–ê–ó: {total_vector_size:.1f} MB\")\n",
        "    print(f\"üìä –°–†–ï–î–ù–ò–ô SUCCESS RATE: {avg_success_rate:.1f}%\")\n",
        "\n",
        "print(f\"\\nüìÅ –í–°–ï –í–ï–ö–¢–û–†–ù–´–ï –ë–ê–ó–´ –°–û–•–†–ê–ù–ï–ù–´ –í: {vector_store_path}\")\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—ã–π —Ñ–∞–π–ª —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏\n",
        "summary_data = {\n",
        "    'project': 'AI SEO Architects',\n",
        "    'vectorization_date': datetime.now().isoformat(),\n",
        "    'total_agents': 14,\n",
        "    'successful_vectorizations': len(successful_agents),\n",
        "    'total_chunks': total_chunks,\n",
        "    'total_embeddings': total_embeddings,\n",
        "    'embedding_model': 'text-embedding-ada-002',\n",
        "    'embedding_dimension': 1536,\n",
        "    'agents': vectorization_results\n",
        "}\n",
        "\n",
        "summary_path = f\"{vector_store_path}/vectorization_summary.json\"\n",
        "with open(summary_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(summary_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"üìã –°–í–û–î–ö–ê –°–û–•–†–ê–ù–ï–ù–ê: {os.path.basename(summary_path)}\")\n",
        "\n",
        "print(\"\\nüéâ –ú–ê–°–°–û–í–ê–Ø –í–ï–ö–¢–û–†–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!\")\n",
        "print(\"‚û°Ô∏è –ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ —Å–ª–µ–¥—É—é—â–µ–π —è—á–µ–π–∫–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ RAG –ø–æ–∏—Å–∫–∞\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7ue8Bs6ndbi",
        "outputId": "8b54ab11-486f-4076-fecc-b7003bb53fde"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ –ú–ê–°–°–û–í–ê–Ø –í–ï–ö–¢–û–†–ò–ó–ê–¶–ò–Ø –í–°–ï–• –ë–ê–ó –ó–ù–ê–ù–ò–ô AI SEO ARCHITECTS\n",
            "======================================================================\n",
            "–°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã –¥–ª—è –≤—Å–µ—Ö 14 –∞–≥–µ–Ω—Ç–æ–≤ –º–∏—Ä–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
            "======================================================================\n",
            "üìÅ –í–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: /content/ai-seo-architects/data/vector_stores\n",
            "\n",
            "üìä –ê–ù–ê–õ–ò–ó –í–°–ï–• –ë–ê–ó –ó–ù–ê–ù–ò–ô:\n",
            "----------------------------------------------------------------------\n",
            "üìÑ executive    | chief_seo_strategist                | 23.8 KB\n",
            "üìÑ executive    | business_development_director       | 22.2 KB\n",
            "üìÑ management   | client_success_manager              | 31.7 KB\n",
            "üìÑ management   | sales_operations_manager            | 28.3 KB\n",
            "üìÑ management   | task_coordination                   | 35.4 KB\n",
            "üìÑ management   | technical_seo_operations_manager    | 37.1 KB\n",
            "üìÑ operational  | proposal_generation                 | 35.2 KB\n",
            "üìÑ operational  | link_building                       | 13.7 KB\n",
            "üìÑ operational  | reporting                           | 17.3 KB\n",
            "üìÑ operational  | competitive_analysis                | 17.7 KB\n",
            "üìÑ operational  | content_strategy                    | 27.0 KB\n",
            "üìÑ operational  | lead_qualification                  | 37.7 KB\n",
            "üìÑ operational  | sales_conversation                  | 40.8 KB\n",
            "üìÑ operational  | technical_seo_auditor               | 45.2 KB\n",
            "\n",
            "üìä –í–°–ï–ì–û –ù–ê–ô–î–ï–ù–û: 14 –±–∞–∑ –∑–Ω–∞–Ω–∏–π\n",
            "üì¶ –û–ë–©–ò–ô –†–ê–ó–ú–ï–†: 413.2 KB (0.4 MB)\n",
            "\n",
            "üîÑ –ù–ê–ß–ò–ù–ê–ï–ú –í–ï–ö–¢–û–†–ò–ó–ê–¶–ò–Æ 14 –ë–ê–ó –ó–ù–ê–ù–ò–ô...\n",
            "----------------------------------------------------------------------\n",
            "\n",
            " 1/14 üîÑ chief_seo_strategist                (23.8 KB)\n",
            "      üìù –°–æ–∑–¥–∞–Ω–æ 3 —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤\n",
            "      ‚úÖ –°–æ–∑–¥–∞–Ω–æ 3/3 —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
            "      üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: chief_seo_strategist_vectors.json (0.12 MB)\n",
            "\n",
            " 2/14 üîÑ business_development_director       (22.2 KB)\n",
            "      üìù –°–æ–∑–¥–∞–Ω–æ 3 —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤\n",
            "      ‚úÖ –°–æ–∑–¥–∞–Ω–æ 3/3 —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
            "      üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: business_development_director_vectors.json (0.12 MB)\n",
            "\n",
            " 3/14 üîÑ client_success_manager              (31.7 KB)\n",
            "      üìù –°–æ–∑–¥–∞–Ω–æ 3 —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤\n",
            "      ‚úÖ –°–æ–∑–¥–∞–Ω–æ 3/3 —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
            "      üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: client_success_manager_vectors.json (0.13 MB)\n",
            "\n",
            " 4/14 üîÑ sales_operations_manager            (28.3 KB)\n",
            "      üìù –°–æ–∑–¥–∞–Ω–æ 3 —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤\n",
            "      ‚úÖ –°–æ–∑–¥–∞–Ω–æ 3/3 —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
            "      üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: sales_operations_manager_vectors.json (0.13 MB)\n",
            "\n",
            " 5/14 üîÑ task_coordination                   (35.4 KB)\n",
            "      üìù –°–æ–∑–¥–∞–Ω–æ 3 —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤\n",
            "      ‚úÖ –°–æ–∑–¥–∞–Ω–æ 3/3 —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
            "      üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: task_coordination_vectors.json (0.14 MB)\n",
            "\n",
            " 6/14 üîÑ technical_seo_operations_manager    (37.1 KB)\n",
            "      üìù –°–æ–∑–¥–∞–Ω–æ 5 —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤\n",
            "      ‚úÖ –°–æ–∑–¥–∞–Ω–æ 5/5 —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
            "      üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: technical_seo_operations_manager_vectors.json (0.20 MB)\n",
            "\n",
            " 7/14 üîÑ proposal_generation                 (35.2 KB)\n",
            "      üìù –°–æ–∑–¥–∞–Ω–æ 5 —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤\n",
            "      ‚úÖ –°–æ–∑–¥–∞–Ω–æ 5/5 —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
            "      üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: proposal_generation_vectors.json (0.20 MB)\n",
            "\n",
            " 8/14 üîÑ link_building                       (13.7 KB)\n",
            "      üìù –°–æ–∑–¥–∞–Ω–æ 2 —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤\n",
            "      ‚úÖ –°–æ–∑–¥–∞–Ω–æ 2/2 —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
            "      üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: link_building_vectors.json (0.08 MB)\n",
            "\n",
            " 9/14 üîÑ reporting                           (17.3 KB)\n",
            "      üìù –°–æ–∑–¥–∞–Ω–æ 2 —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤\n",
            "      ‚úÖ –°–æ–∑–¥–∞–Ω–æ 2/2 —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
            "      üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: reporting_vectors.json (0.08 MB)\n",
            "\n",
            "10/14 üîÑ competitive_analysis                (17.7 KB)\n",
            "      üìù –°–æ–∑–¥–∞–Ω–æ 2 —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤\n",
            "      ‚úÖ –°–æ–∑–¥–∞–Ω–æ 2/2 —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
            "      üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: competitive_analysis_vectors.json (0.08 MB)\n",
            "\n",
            "11/14 üîÑ content_strategy                    (27.0 KB)\n",
            "      üìù –°–æ–∑–¥–∞–Ω–æ 3 —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤\n",
            "      ‚úÖ –°–æ–∑–¥–∞–Ω–æ 3/3 —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
            "      üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: content_strategy_vectors.json (0.13 MB)\n",
            "\n",
            "12/14 üîÑ lead_qualification                  (37.7 KB)\n",
            "      üìù –°–æ–∑–¥–∞–Ω–æ 5 —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤\n",
            "      ‚úÖ –°–æ–∑–¥–∞–Ω–æ 5/5 —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
            "      üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: lead_qualification_vectors.json (0.21 MB)\n",
            "\n",
            "13/14 üîÑ sales_conversation                  (40.8 KB)\n",
            "      üìù –°–æ–∑–¥–∞–Ω–æ 5 —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤\n",
            "      ‚úÖ –°–æ–∑–¥–∞–Ω–æ 5/5 —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
            "      üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: sales_conversation_vectors.json (0.21 MB)\n",
            "\n",
            "14/14 üîÑ technical_seo_auditor               (45.2 KB)\n",
            "      üìù –°–æ–∑–¥–∞–Ω–æ 5 —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤\n",
            "      ‚úÖ –°–æ–∑–¥–∞–Ω–æ 5/5 —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
            "      üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: technical_seo_auditor_vectors.json (0.21 MB)\n",
            "\n",
            "======================================================================\n",
            "üéØ –ò–¢–û–ì–ò –í–ï–ö–¢–û–†–ò–ó–ê–¶–ò–ò:\n",
            "======================================================================\n",
            "‚úÖ –£–°–ü–ï–®–ù–û –í–ï–ö–¢–û–†–ò–ó–û–í–ê–ù–û: 14/14 –∞–≥–µ–Ω—Ç–æ–≤\n",
            "‚ùå –û–®–ò–ë–ö–ò: 0 –∞–≥–µ–Ω—Ç–æ–≤\n",
            "üì¶ –í–°–ï–ì–û –ß–ê–ù–ö–û–í: 49\n",
            "üß† –í–°–ï–ì–û –≠–ú–ë–ï–î–î–ò–ù–ì–û–í: 49\n",
            "üíæ –†–ê–ó–ú–ï–† –í–ï–ö–¢–û–†–ù–´–• –ë–ê–ó: 2.1 MB\n",
            "üìä –°–†–ï–î–ù–ò–ô SUCCESS RATE: 100.0%\n",
            "\n",
            "üìÅ –í–°–ï –í–ï–ö–¢–û–†–ù–´–ï –ë–ê–ó–´ –°–û–•–†–ê–ù–ï–ù–´ –í: /content/ai-seo-architects/data/vector_stores\n",
            "üìã –°–í–û–î–ö–ê –°–û–•–†–ê–ù–ï–ù–ê: vectorization_summary.json\n",
            "\n",
            "üéâ –ú–ê–°–°–û–í–ê–Ø –í–ï–ö–¢–û–†–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!\n",
            "‚û°Ô∏è –ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ —Å–ª–µ–¥—É—é—â–µ–π —è—á–µ–π–∫–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ RAG –ø–æ–∏—Å–∫–∞\n"
          ]
        }
      ]
    }
  ]
}