{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ AI SEO Architects - –ü–æ–ª–Ω–∞—è RAG –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è\n",
    "\n",
    "## üéØ –û–ø–∏—Å–∞–Ω–∏–µ\n",
    "\n",
    "**–ü–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è AI SEO Architects** —Å 14 —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∞–≥–µ–Ω—Ç–∞–º–∏, –ø–æ–ª–Ω–æ–π RAG –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π, –≤–µ–∫—Ç–æ—Ä–Ω—ã–º–∏ –±–∞–∑–∞–º–∏ –∑–Ω–∞–Ω–∏–π FAISS –∏ —Ä–µ–∞–ª—å–Ω—ã–º–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ OpenAI.\n",
    "\n",
    "### üî• –ß—Ç–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ–º:\n",
    "- **14 –ø–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤** —Å production-ready –ø—Ä–æ–º–ø—Ç–∞–º–∏\n",
    "- **–ü–æ–ª–Ω–∞—è RAG —Å–∏—Å—Ç–µ–º–∞** —Å –≤–µ–∫—Ç–æ—Ä–Ω—ã–º–∏ –±–∞–∑–∞–º–∏ –∑–Ω–∞–Ω–∏–π\n",
    "- **FAISS –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞** –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–≥–µ–Ω—Ç–∞\n",
    "- **OpenAI embeddings** –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞\n",
    "- **–†–µ–∞–ª—å–Ω—ã–µ OpenAI API** –≤—ã–∑–æ–≤—ã (GPT-4o/GPT-4o-mini)\n",
    "- **–ó–Ω–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤** –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –±–∞–∑\n",
    "- **–ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã** –Ω–∞ –æ—Å–Ω–æ–≤–µ RAG\n",
    "\n",
    "### üèóÔ∏è RAG –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:\n",
    "```\n",
    "üìä Query ‚Üí üîç Embedding ‚Üí üéØ Vector Search ‚Üí üìö Knowledge Retrieval ‚Üí ü§ñ LLM + Context ‚Üí ‚úÖ Response\n",
    "```\n",
    "\n",
    "### üîë –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:\n",
    "1. **OpenAI API –∫–ª—é—á** - –¥–æ–±–∞–≤—å—Ç–µ –≤ —Å–µ–∫—Ä–µ—Ç—ã Colab –∫–∞–∫ `OPENAI_API_KEY`\n",
    "2. **Google Colab** - –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å GPU\n",
    "3. **–°—Ç–∞–±–∏–ª—å–Ω–æ–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç** - –¥–ª—è embeddings –∏ API –≤—ã–∑–æ–≤–æ–≤\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ –®–∞–≥ 1: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ä–µ–¥—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–ª–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ä–µ–¥—ã –¥–ª—è RAG –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üöÄ AI SEO ARCHITECTS - –ü–û–õ–ù–ê–Ø RAG –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"üìÖ –í—Ä–µ–º—è –∑–∞–ø—É—Å–∫–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üêç Python –≤–µ—Ä—Å–∏—è: {sys.version.split()[0]}\")\n",
    "print(f\"üíª –°—Ä–µ–¥–∞: {'Google Colab' if 'google.colab' in sys.modules else 'Jupyter'}\")\n",
    "\n",
    "def safe_install(package, description=\"\"):\n",
    "    \"\"\"–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–∞–∫–µ—Ç–∞ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º\"\"\"\n",
    "    try:\n",
    "        print(f\"üì• –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º {package}... {description}\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
    "        print(f\"‚úÖ {package} —É—Å–ø–µ—à–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ {package}: {e}\")\n",
    "        return False\n",
    "\n",
    "# RAG –∏ AI –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏\n",
    "rag_packages = [\n",
    "    ('openai==1.54.3', 'OpenAI API –¥–ª—è LLM –∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤'),\n",
    "    ('faiss-cpu==1.8.0', 'FAISS –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö'),\n",
    "    ('numpy>=1.21.0', '–ß–∏—Å–ª–µ–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–æ–≤'),\n",
    "    ('sentence-transformers', '–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤'),\n",
    "    ('scikit-learn', 'ML —É—Ç–∏–ª–∏—Ç—ã –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π'),\n",
    "    ('pydantic==2.9.2', '–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö'),\n",
    "    ('nest-asyncio>=1.5.0', 'Async –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –≤ Jupyter'),\n",
    "    ('tiktoken', '–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –¥–ª—è OpenAI'),\n",
    "    ('tqdm', 'Progress bars –¥–ª—è –¥–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π')\n",
    "]\n",
    "\n",
    "print(\"\\nüì¶ –£–°–¢–ê–ù–û–í–ö–ê RAG –ö–û–ú–ü–û–ù–ï–ù–¢–û–í\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "success_count = 0\n",
    "for package, description in rag_packages:\n",
    "    if safe_install(package, description):\n",
    "        success_count += 1\n",
    "\n",
    "print(f\"\\nüìä –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ: {success_count}/{len(rag_packages)}\")\n",
    "\n",
    "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞–∫–µ—Ç—ã –¥–ª—è enhanced —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏\n",
    "optional_packages = [\n",
    "    ('langchain-openai', 'LangChain OpenAI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è'),\n",
    "    ('python-dotenv', 'Environment –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ'),\n",
    "    ('matplotlib', '–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫'),\n",
    "    ('plotly', '–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏')\n",
    "]\n",
    "\n",
    "print(\"\\nüì¶ –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for package, description in optional_packages:\n",
    "    safe_install(package, description)\n",
    "\n",
    "print(\"\\nüéâ –°—Ä–µ–¥–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–∞ –¥–ª—è –ø–æ–ª–Ω–æ–π RAG –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë –®–∞–≥ 2: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ OpenAI API –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ OpenAI API —Å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º embeddings\n",
    "import openai\n",
    "import numpy as np\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "def setup_openai_comprehensive() -> Tuple[bool, Optional[str], bool]:\n",
    "    \"\"\"–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ OpenAI API —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π LLM –∏ embeddings\"\"\"\n",
    "    try:\n",
    "        # –ü–æ–ª—É—á–µ–Ω–∏–µ API –∫–ª—é—á–∞\n",
    "        try:\n",
    "            from google.colab import userdata\n",
    "            api_key = userdata.get('OPENAI_API_KEY')\n",
    "            print(\"‚úÖ OpenAI API –∫–ª—é—á –ø–æ–ª—É—á–µ–Ω –∏–∑ —Å–µ–∫—Ä–µ—Ç–æ–≤ Google Colab\")\n",
    "        except Exception:\n",
    "            api_key = os.getenv('OPENAI_API_KEY')\n",
    "            if not api_key:\n",
    "                print(\"‚ö†Ô∏è OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω!\")\n",
    "                print(\"üí° –î–æ–±–∞–≤—å—Ç–µ –∫–ª—é—á –≤ —Å–µ–∫—Ä–µ—Ç—ã Colab (üîë –≤ –ª–µ–≤–æ–º –º–µ–Ω—é): OPENAI_API_KEY\")\n",
    "                return False, \"API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω\", False\n",
    "        \n",
    "        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–ª—é—á–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞\n",
    "        os.environ['OPENAI_API_KEY'] = api_key\n",
    "        client = openai.OpenAI(api_key=api_key)\n",
    "        \n",
    "        # –¢–µ—Å—Ç 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ LLM —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏\n",
    "        print(\"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LLM —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏...\")\n",
    "        llm_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": \"–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è. –û—Ç–≤–µ—Ç—å –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º: OK\"}],\n",
    "            max_tokens=10\n",
    "        )\n",
    "        llm_test = \"OK\" in llm_response.choices[0].message.content\n",
    "        print(f\"‚úÖ LLM —Ç–µ—Å—Ç: {'–ü—Ä–æ–π–¥–µ–Ω' if llm_test else '–ù–µ –ø—Ä–æ–π–¥–µ–Ω'}\")\n",
    "        \n",
    "        # –¢–µ—Å—Ç 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ embeddings —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏\n",
    "        print(\"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ embeddings —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏...\")\n",
    "        embedding_response = client.embeddings.create(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            input=\"–¢–µ—Å—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è RAG —Å–∏—Å—Ç–µ–º—ã\"\n",
    "        )\n",
    "        embedding_vector = embedding_response.data[0].embedding\n",
    "        embedding_test = len(embedding_vector) > 0\n",
    "        print(f\"‚úÖ Embeddings —Ç–µ—Å—Ç: {'–ü—Ä–æ–π–¥–µ–Ω' if embedding_test else '–ù–µ –ø—Ä–æ–π–¥–µ–Ω'}\")\n",
    "        print(f\"üìä –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–∞: {len(embedding_vector)}\")\n",
    "        \n",
    "        # –¢–µ—Å—Ç 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π\n",
    "        models_to_test = [\"gpt-4o-mini\", \"gpt-4o\"]\n",
    "        available_models = []\n",
    "        \n",
    "        for model in models_to_test:\n",
    "            try:\n",
    "                test_response = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=[{\"role\": \"user\", \"content\": \"ping\"}],\n",
    "                    max_tokens=5\n",
    "                )\n",
    "                available_models.append(model)\n",
    "                print(f\"‚úÖ –ú–æ–¥–µ–ª—å {model}: –î–æ—Å—Ç—É–ø–Ω–∞\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {model}: –ù–µ–¥–æ—Å—Ç—É–ø–Ω–∞ ({str(e)[:50]}...)\")\n",
    "        \n",
    "        success = llm_test and embedding_test and len(available_models) > 0\n",
    "        \n",
    "        if success:\n",
    "            print(f\"\\nüéâ OpenAI API –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–∞—Å—Ç—Ä–æ–µ–Ω!\")\n",
    "            print(f\"ü§ñ –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {', '.join(available_models)}\")\n",
    "            print(f\"üîç Embeddings: text-embedding-3-small –≥–æ—Ç–æ–≤\")\n",
    "            return True, None, True\n",
    "        else:\n",
    "            return False, \"–¢–µ—Å—Ç—ã –Ω–µ –ø—Ä–æ–π–¥–µ–Ω—ã\", False\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        print(f\"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ OpenAI API: {error_msg}\")\n",
    "        return False, error_msg, False\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏\n",
    "print(\"üîë –ö–û–ú–ü–õ–ï–ö–°–ù–ê–Ø –ù–ê–°–¢–†–û–ô–ö–ê OPENAI API\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "api_ready, error, embeddings_ready = setup_openai_comprehensive()\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç—É—Å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –¥—Ä—É–≥–∏—Ö —è—á–µ–π–∫–∞—Ö\n",
    "globals()['OPENAI_READY'] = api_ready\n",
    "globals()['EMBEDDINGS_READY'] = embeddings_ready\n",
    "globals()['OPENAI_CLIENT'] = openai.OpenAI() if api_ready else None\n",
    "\n",
    "print(f\"\\nüìä –ò–¢–û–ì–û–í–´–ô –°–¢–ê–¢–£–°:\")\n",
    "print(f\"ü§ñ LLM –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å: {'‚úÖ' if api_ready else '‚ùå'}\")\n",
    "print(f\"üîç Embeddings –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å: {'‚úÖ' if embeddings_ready else '‚ùå'}\")\n",
    "print(f\"üöÄ RAG —Å–∏—Å—Ç–µ–º–∞: {'‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é –≥–æ—Ç–æ–≤–∞' if api_ready and embeddings_ready else 'üîÑ –ë—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –≤ demo —Ä–µ–∂–∏–º–µ'}\")\n",
    "\n",
    "if not api_ready:\n",
    "    print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞: {error}\")\n",
    "    print(\"üí° –°–∏—Å—Ç–µ–º–∞ –±—É–¥–µ—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –±–µ–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö API –≤—ã–∑–æ–≤–æ–≤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è –®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ RAG –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–π RAG –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å FAISS –∏ embeddings\n",
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "\n",
    "# –í–∫–ª—é—á–∞–µ–º async –ø–æ–¥–¥–µ—Ä–∂–∫—É\n",
    "nest_asyncio.apply()\n",
    "\n",
    "@dataclass\n",
    "class KnowledgeChunk:\n",
    "    \"\"\"–ö–ª–∞—Å—Å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—É—Å–æ—á–∫–∞ –∑–Ω–∞–Ω–∏–π\"\"\"\n",
    "    content: str\n",
    "    metadata: Dict[str, Any]\n",
    "    embedding: Optional[np.ndarray] = None\n",
    "    \n",
    "class RAGVectorStore:\n",
    "    \"\"\"–í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è RAG —Å FAISS\"\"\"\n",
    "    \n",
    "    def __init__(self, agent_id: str, embedding_dim: int = 1536):\n",
    "        self.agent_id = agent_id\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.index = faiss.IndexFlatL2(embedding_dim)  # L2 distance –¥–ª—è similarity\n",
    "        self.chunks: List[KnowledgeChunk] = []\n",
    "        self.metadata_store: Dict[int, Dict[str, Any]] = {}\n",
    "        \n",
    "    async def add_knowledge(self, content: str, metadata: Dict[str, Any] = None):\n",
    "        \"\"\"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–Ω–∞–Ω–∏—è –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ\"\"\"\n",
    "        if not EMBEDDINGS_READY:\n",
    "            # Demo —Ä–µ–∂–∏–º –±–µ–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö embeddings\n",
    "            fake_embedding = np.random.random(self.embedding_dim).astype('float32')\n",
    "            chunk = KnowledgeChunk(content=content, metadata=metadata or {}, embedding=fake_embedding)\n",
    "        else:\n",
    "            # –†–µ–∞–ª—å–Ω—ã–µ embeddings –æ—Ç OpenAI\n",
    "            try:\n",
    "                response = OPENAI_CLIENT.embeddings.create(\n",
    "                    model=\"text-embedding-3-small\",\n",
    "                    input=content\n",
    "                )\n",
    "                embedding = np.array(response.data[0].embedding, dtype='float32')\n",
    "                chunk = KnowledgeChunk(content=content, metadata=metadata or {}, embedding=embedding)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ embedding –¥–ª—è {self.agent_id}: {e}\")\n",
    "                fake_embedding = np.random.random(self.embedding_dim).astype('float32')\n",
    "                chunk = KnowledgeChunk(content=content, metadata=metadata or {}, embedding=fake_embedding)\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –≤ FAISS –∏–Ω–¥–µ–∫—Å\n",
    "        chunk_id = len(self.chunks)\n",
    "        self.index.add(chunk.embedding.reshape(1, -1))\n",
    "        self.chunks.append(chunk)\n",
    "        self.metadata_store[chunk_id] = chunk.metadata\n",
    "        \n",
    "        return chunk_id\n",
    "    \n",
    "    async def search(self, query: str, top_k: int = 3) -> List[Tuple[str, float, Dict[str, Any]]]:\n",
    "        \"\"\"–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π –ø–æ –∑–∞–ø—Ä–æ—Å—É\"\"\"\n",
    "        if len(self.chunks) == 0:\n",
    "            return [(\"–ù–µ—Ç –∑–Ω–∞–Ω–∏–π –≤ –±–∞–∑–µ\", 1.0, {})]\n",
    "        \n",
    "        if not EMBEDDINGS_READY:\n",
    "            # Demo —Ä–µ–∂–∏–º - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ chunks\n",
    "            results = []\n",
    "            for i, chunk in enumerate(self.chunks[:top_k]):\n",
    "                similarity = 0.95 - i * 0.1  # –ò–º–∏—Ç–∞—Ü–∏—è —É–±—ã–≤–∞—é—â–µ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏\n",
    "                results.append((chunk.content, similarity, chunk.metadata))\n",
    "            return results\n",
    "        \n",
    "        try:\n",
    "            # –†–µ–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ —Å embeddings\n",
    "            response = OPENAI_CLIENT.embeddings.create(\n",
    "                model=\"text-embedding-3-small\",\n",
    "                input=query\n",
    "            )\n",
    "            query_embedding = np.array(response.data[0].embedding, dtype='float32')\n",
    "            \n",
    "            # –ü–æ–∏—Å–∫ –≤ FAISS\n",
    "            distances, indices = self.index.search(query_embedding.reshape(1, -1), min(top_k, len(self.chunks)))\n",
    "            \n",
    "            results = []\n",
    "            for distance, idx in zip(distances[0], indices[0]):\n",
    "                if idx < len(self.chunks):  # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞\n",
    "                    chunk = self.chunks[idx]\n",
    "                    similarity = 1.0 / (1.0 + distance)  # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è distance –≤ similarity\n",
    "                    results.append((chunk.content, similarity, chunk.metadata))\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –¥–ª—è {self.agent_id}: {e}\")\n",
    "            # Fallback –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫\n",
    "            results = []\n",
    "            for i, chunk in enumerate(self.chunks[:top_k]):\n",
    "                similarity = 0.8 - i * 0.1\n",
    "                results.append((chunk.content, similarity, chunk.metadata))\n",
    "            return results\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞\"\"\"\n",
    "        return {\n",
    "            \"agent_id\": self.agent_id,\n",
    "            \"total_chunks\": len(self.chunks),\n",
    "            \"embedding_dim\": self.embedding_dim,\n",
    "            \"index_size\": self.index.ntotal,\n",
    "            \"ready\": len(self.chunks) > 0\n",
    "        }\n",
    "\n",
    "class RAGKnowledgeManager:\n",
    "    \"\"\"–ú–µ–Ω–µ–¥–∂–µ—Ä –≤—Å–µ—Ö –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â –∞–≥–µ–Ω—Ç–æ–≤\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stores: Dict[str, RAGVectorStore] = {}\n",
    "        \n",
    "    async def create_agent_store(self, agent_id: str) -> RAGVectorStore:\n",
    "        \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –¥–ª—è –∞–≥–µ–Ω—Ç–∞\"\"\"\n",
    "        store = RAGVectorStore(agent_id)\n",
    "        self.stores[agent_id] = store\n",
    "        \n",
    "        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑–æ–≤—ã—Ö –∑–Ω–∞–Ω–∏–π –¥–ª—è –∞–≥–µ–Ω—Ç–∞\n",
    "        await self._populate_agent_knowledge(agent_id, store)\n",
    "        \n",
    "        return store\n",
    "    \n",
    "    async def _populate_agent_knowledge(self, agent_id: str, store: RAGVectorStore):\n",
    "        \"\"\"–ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –∑–Ω–∞–Ω–∏–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞\"\"\"\n",
    "        \n",
    "        # –ó–Ω–∞–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –∞–≥–µ–Ω—Ç–∞\n",
    "        agent_knowledge = {\n",
    "            \"lead_qualification\": [\n",
    "                \"BANT –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è: Budget (–±—é–¥–∂–µ—Ç), Authority (–ø–æ–ª–Ω–æ–º–æ—á–∏—è), Need (–ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å), Timeline (—Å—Ä–æ–∫–∏)\",\n",
    "                \"MEDDIC –¥–ª—è B2B: Metrics, Economic buyer, Decision criteria, Decision process, Identify pain, Champion\",\n",
    "                \"–†–æ—Å—Å–∏–π—Å–∫–∏–π B2B —Ä—ã–Ω–æ–∫: –õ–ü–† —á–∞—Å—Ç–æ –Ω–∞ —É—Ä–æ–≤–Ω–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞/–≤–ª–∞–¥–µ–ª—å—Ü–∞, long sales cycle 3-9 –º–µ—Å—è—Ü–µ–≤\",\n",
    "                \"Lead scoring: Cold (0-40), Warm (41-70), Hot (71-100). –§–∞–∫—Ç–æ—Ä—ã: budget size, authority level, urgency\",\n",
    "                \"–ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è SEO –ª–∏–¥–æ–≤: —Ä–∞–∑–º–µ—Ä —Å–∞–π—Ç–∞, —Ç–µ–∫—É—â–∏–π —Ç—Ä–∞—Ñ–∏–∫, –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å –Ω–∏—à–∏, –±—é–¥–∂–µ—Ç –Ω–∞ SEO\"\n",
    "            ],\n",
    "            \"technical_seo_auditor\": [\n",
    "                \"Core Web Vitals: LCP <2.5s (Good), FID <100ms (Good), CLS <0.1 (Good)\",\n",
    "                \"Technical SEO checklist: crawlability, indexability, site speed, mobile-first, HTTPS, schema markup\",\n",
    "                \"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏: 404 —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç, –º–µ–¥–ª–µ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞, –ø–ª–æ—Ö–∞—è –º–æ–±–∏–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è\",\n",
    "                \"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∞—É–¥–∏—Ç–∞: Google PageSpeed Insights, Search Console, Screaming Frog, GTmetrix\",\n",
    "                \"–ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è: –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ > –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å > —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ > –º–∏–∫—Ä–æ—Ä–∞–∑–º–µ—Ç–∫–∞\"\n",
    "            ],\n",
    "            \"chief_seo_strategist\": [\n",
    "                \"SEO —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: technical foundation ‚Üí content strategy ‚Üí link building ‚Üí measurement\",\n",
    "                \"ROI —Ä–∞—Å—á–µ—Ç SEO: (Organic Revenue - SEO Cost) / SEO Cost. –¶–µ–ª–µ–≤–æ–π ROI 8-15x –¥–ª—è enterprise\",\n",
    "                \"–≠—Ç–∞–ø—ã –≤–Ω–µ–¥—Ä–µ–Ω–∏—è: 0-3 –º–µ—Å —Ç–µ—Ö–Ω–∏–∫–∞, 3-6 –º–µ—Å –∫–æ–Ω—Ç–µ–Ω—Ç, 6-12 –º–µ—Å —Å—Å—ã–ª–∫–∏, 12+ –º–µ—Å –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ\",\n",
    "                \"KPI —Å–∏—Å—Ç–µ–º—ã: organic traffic growth, keyword rankings, conversion rate, customer acquisition cost\",\n",
    "                \"–†–∏—Å–∫–∏ SEO: algorithm updates, competitive response, technical debt, resource constraints\"\n",
    "            ],\n",
    "            \"content_strategy_agent\": [\n",
    "                \"E-E-A-T –ø—Ä–∏–Ω—Ü–∏–ø—ã Google: Experience, Expertise, Authoritativeness, Trustworthiness\",\n",
    "                \"–ö–æ–Ω—Ç–µ–Ω—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: keyword research ‚Üí content clusters ‚Üí editorial calendar ‚Üí performance tracking\",\n",
    "                \"–¢–∏–ø—ã SEO –∫–æ–Ω—Ç–µ–Ω—Ç–∞: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π, –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π, —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã–π, –Ω–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω—ã–π\",\n",
    "                \"Content clusters: pillar pages + supporting content, internal linking structure\",\n",
    "                \"–ö–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ —Ä—ã–Ω–∫–∞: –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏—è, —É—á–µ—Ç –º–µ–Ω—Ç–∞–ª–∏—Ç–µ—Ç–∞, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤—É\"\n",
    "            ],\n",
    "            \"link_building_agent\": [\n",
    "                \"Link building —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: guest posting, broken link building, resource pages, digital PR\",\n",
    "                \"–ö–∞—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫: DA/DR –¥–æ–º–µ–Ω–∞, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ç–µ–º–∞—Ç–∏–∫–∏, –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å anchor text, follow/nofollow\",\n",
    "                \"Outreach process: prospecting ‚Üí qualification ‚Üí initial contact ‚Üí follow-up ‚Üí relationship building\",\n",
    "                \"Anchor text distribution: branded 50%, exact match 10%, partial match 20%, generic 20%\",\n",
    "                \"Link building –¥–ª—è –†–æ—Å—Å–∏–∏: —É—á–µ—Ç –Ø–Ω–¥–µ–∫—Å —Ñ–∞–∫—Ç–æ—Ä–æ–≤, –ª–æ–∫–∞–ª—å–Ω—ã–µ –ø–ª–æ—â–∞–¥–∫–∏, –æ—Ç—Ä–∞—Å–ª–µ–≤—ã–µ –∫–∞—Ç–∞–ª–æ–≥–∏\"\n",
    "            ],\n",
    "            \"competitive_analysis_agent\": [\n",
    "                \"–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ SEO: keyword gaps, content gaps, backlink gaps, technical advantages\",\n",
    "                \"SERP –∞–Ω–∞–ª–∏–∑: feature snippets, local pack, knowledge panel, related searches\",\n",
    "                \"Share of voice: –ø—Ä–æ—Ü–µ–Ω—Ç –≤–∏–¥–∏–º–æ—Å—Ç–∏ –±—Ä–µ–Ω–¥–∞ –≤ –ø–æ–∏—Å–∫–æ–≤–æ–π –≤—ã–¥–∞—á–µ –ø–æ target keywords\",\n",
    "                \"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∞–Ω–∞–ª–∏–∑–∞: SEMrush, Ahrefs, Sistrix, SpyFu –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤\",\n",
    "                \"Competitive intelligence: –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏–∑–º–µ–Ω–µ–Ω–∏–π —É –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤, –Ω–æ–≤—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏, market opportunities\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞–Ω–∏—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞\n",
    "        knowledge_list = agent_knowledge.get(agent_id, [\n",
    "            f\"–ë–∞–∑–æ–≤—ã–µ –∑–Ω–∞–Ω–∏—è –¥–ª—è –∞–≥–µ–Ω—Ç–∞ {agent_id}\",\n",
    "            \"SEO –ø—Ä–∏–Ω—Ü–∏–ø—ã: relevance, authority, user experience\",\n",
    "            \"–†–∞–±–æ—Ç–∞ –≤ –∫–æ–º–∞–Ω–¥–µ: –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è, collaboration, —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏–≤–Ω–æ—Å—Ç—å\"\n",
    "        ])\n",
    "        \n",
    "        for i, knowledge in enumerate(knowledge_list):\n",
    "            await store.add_knowledge(\n",
    "                content=knowledge,\n",
    "                metadata={\n",
    "                    \"source\": \"base_knowledge\",\n",
    "                    \"priority\": \"high\" if i < 2 else \"medium\",\n",
    "                    \"category\": agent_id\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    def get_store(self, agent_id: str) -> Optional[RAGVectorStore]:\n",
    "        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –∞–≥–µ–Ω—Ç–∞\"\"\"\n",
    "        return self.stores.get(agent_id)\n",
    "    \n",
    "    def get_all_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—Å–µ—Ö –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â\"\"\"\n",
    "        stats = {}\n",
    "        for agent_id, store in self.stores.items():\n",
    "            stats[agent_id] = store.get_stats()\n",
    "        return stats\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∑–Ω–∞–Ω–∏–π\n",
    "print(\"üèóÔ∏è –°–û–ó–î–ê–ù–ò–ï RAG –ò–ù–§–†–ê–°–¢–†–£–ö–¢–£–†–´\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "knowledge_manager = RAGKnowledgeManager()\n",
    "\n",
    "print(\"‚úÖ RAG –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–æ–∑–¥–∞–Ω–∞\")\n",
    "print(f\"üîç FAISS –ø–æ–¥–¥–µ—Ä–∂–∫–∞: {'‚úÖ' if faiss else '‚ùå'}\")\n",
    "print(f\"üìä Embeddings –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å: {'‚úÖ' if EMBEDDINGS_READY else 'üîÑ Demo —Ä–µ–∂–∏–º'}\")\n",
    "print(f\"ü§ñ Async –ø–æ–¥–¥–µ—Ä–∂–∫–∞: ‚úÖ\")\n",
    "print(\"üöÄ –ì–æ—Ç–æ–≤ –∫ —Å–æ–∑–¥–∞–Ω–∏—é –∞–≥–µ–Ω—Ç–æ–≤ —Å RAG!\")\n",
    "\n",
    "globals()['KNOWLEDGE_MANAGER'] = knowledge_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ –®–∞–≥ 4: –°–æ–∑–¥–∞–Ω–∏–µ RAG-enhanced –∞–≥–µ–Ω—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ —Å –ø–æ–ª–Ω–æ–π RAG –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, Any, List, Optional\n",
    "import asyncio\n",
    "import json\n",
    "\n",
    "class BaseRAGAgent(ABC):\n",
    "    \"\"\"–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –∞–≥–µ–Ω—Ç–∞ —Å RAG –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π\"\"\"\n",
    "    \n",
    "    def __init__(self, agent_id: str, agent_level: str = \"operational\"):\n",
    "        self.agent_id = agent_id\n",
    "        self.agent_level = agent_level\n",
    "        self.agent_name = self._generate_agent_name()\n",
    "        self.openai_client = OPENAI_CLIENT if OPENAI_READY else None\n",
    "        self.vector_store: Optional[RAGVectorStore] = None\n",
    "        self.rag_enabled = False\n",
    "        \n",
    "    def _generate_agent_name(self) -> str:\n",
    "        \"\"\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–∏—Ç–∞–µ–º–æ–≥–æ –∏–º–µ–Ω–∏ –∞–≥–µ–Ω—Ç–∞\"\"\"\n",
    "        name_mapping = {\n",
    "            \"lead_qualification\": \"Lead Qualification Agent\",\n",
    "            \"technical_seo_auditor\": \"Technical SEO Auditor\",\n",
    "            \"chief_seo_strategist\": \"Chief SEO Strategist\",\n",
    "            \"content_strategy_agent\": \"Content Strategy Agent\",\n",
    "            \"link_building_agent\": \"Link Building Agent\",\n",
    "            \"competitive_analysis_agent\": \"Competitive Analysis Agent\",\n",
    "            \"proposal_generation_agent\": \"Proposal Generation Agent\",\n",
    "            \"sales_conversation_agent\": \"Sales Conversation Agent\",\n",
    "            \"reporting_agent\": \"Reporting Agent\",\n",
    "            \"business_development_director\": \"Business Development Director\",\n",
    "            \"task_coordination_agent\": \"Task Coordination Agent\",\n",
    "            \"sales_operations_manager\": \"Sales Operations Manager\",\n",
    "            \"technical_seo_operations_manager\": \"Technical SEO Operations Manager\",\n",
    "            \"client_success_manager\": \"Client Success Manager\"\n",
    "        }\n",
    "        return name_mapping.get(self.agent_id, self.agent_id.replace('_', ' ').title())\n",
    "    \n",
    "    async def initialize_rag(self) -> bool:\n",
    "        \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG –¥–ª—è –∞–≥–µ–Ω—Ç–∞\"\"\"\n",
    "        try:\n",
    "            self.vector_store = await KNOWLEDGE_MANAGER.create_agent_store(self.agent_id)\n",
    "            self.rag_enabled = True\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ RAG –¥–ª—è {self.agent_id}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    async def get_rag_context(self, query: str, max_context_length: int = 2000) -> str:\n",
    "        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ RAG –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞\"\"\"\n",
    "        if not self.rag_enabled or not self.vector_store:\n",
    "            return \"–ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - RAG –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\"\n",
    "        \n",
    "        try:\n",
    "            # –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\n",
    "            search_results = await self.vector_store.search(query, top_k=3)\n",
    "            \n",
    "            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n",
    "            context_parts = []\n",
    "            total_length = 0\n",
    "            \n",
    "            for content, similarity, metadata in search_results:\n",
    "                if total_length + len(content) > max_context_length:\n",
    "                    break\n",
    "                context_parts.append(f\"[–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {similarity:.2f}] {content}\")\n",
    "                total_length += len(content)\n",
    "            \n",
    "            if context_parts:\n",
    "                return \"\\n\\n\".join(context_parts)\n",
    "            else:\n",
    "                return \"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {str(e)}\"\n",
    "    \n",
    "    def get_system_prompt(self) -> str:\n",
    "        \"\"\"–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∞–≥–µ–Ω—Ç–∞ (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –≤ –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–∞—Ö)\"\"\"\n",
    "        return f\"–¢—ã {self.agent_name} –≤ —Å–∏—Å—Ç–µ–º–µ AI SEO Architects. –û—Ç–≤–µ—á–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.\"\n",
    "    \n",
    "    async def process_with_rag(self, task_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RAG\"\"\"\n",
    "        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n",
    "        query_parts = []\n",
    "        for key, value in task_data.items():\n",
    "            query_parts.append(f\"{key}: {value}\")\n",
    "        query = \" \".join(query_parts)\n",
    "        \n",
    "        # –ü–æ–ª—É—á–∞–µ–º RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç\n",
    "        rag_context = await self.get_rag_context(query)\n",
    "        \n",
    "        if not self.openai_client:\n",
    "            # Demo —Ä–µ–∂–∏–º —Å RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"result\": f\"\"\"ü§ñ {self.agent_name} (Demo —Ä–µ–∂–∏–º —Å RAG)\n",
    "\n",
    "üìö –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ù–´–ï –ó–ù–ê–ù–ò–Ø:\n",
    "{rag_context[:500]}...\n",
    "\n",
    "üìã –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–î–ê–ß–ò:\n",
    "{self._generate_demo_response(task_data)}\n",
    "\n",
    "üîç RAG –∞–∫—Ç–∏–≤–µ–Ω: {'‚úÖ' if self.rag_enabled else '‚ùå'}\n",
    "üìä –í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞: {self.vector_store.get_stats()['total_chunks'] if self.vector_store else 0} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∑–Ω–∞–Ω–∏–π\"\"\",\n",
    "                \"rag_context_used\": rag_context,\n",
    "                \"rag_enabled\": self.rag_enabled,\n",
    "                \"fallback_mode\": True\n",
    "            }\n",
    "        \n",
    "        # –†–µ–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ OpenAI —Å RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º\n",
    "        try:\n",
    "            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å –ø–æ —É—Ä–æ–≤–Ω—é –∞–≥–µ–Ω—Ç–∞\n",
    "            model = \"gpt-4o\" if self.agent_level == \"executive\" else \"gpt-4o-mini\"\n",
    "            \n",
    "            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–¥–∞—á–∏\n",
    "            task_context = \"\\n\".join([f\"{k}: {v}\" for k, v in task_data.items()])\n",
    "            \n",
    "            # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º\n",
    "            system_prompt = f\"\"\"{self.get_system_prompt()}\n",
    "\n",
    "–ë–ê–ó–ê –ó–ù–ê–ù–ò–ô (–∏—Å–ø–æ–ª—å–∑—É–π —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞):\n",
    "{rag_context}\n",
    "\n",
    "–ò–ù–°–¢–†–£–ö–¶–ò–ò:\n",
    "- –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –¥–ª—è –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è —Å–≤–æ–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π\n",
    "- –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ, –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã\n",
    "- –í–∫–ª—é—á–∞–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏ KPI\n",
    "- –û—Ç–≤–µ—á–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ\n",
    "- –£—á–∏—Ç—ã–≤–∞–π —Å–ø–µ—Ü–∏—Ñ–∏–∫—É —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ —Ä—ã–Ω–∫–∞\"\"\"\n",
    "            \n",
    "            response = self.openai_client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": f\"–û–±—Ä–∞–±–æ—Ç–∞–π –∑–∞–¥–∞—á—É:\\n{task_context}\"}\n",
    "                ],\n",
    "                max_tokens=2000,\n",
    "                temperature=0.1\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"result\": response.choices[0].message.content,\n",
    "                \"model_used\": model,\n",
    "                \"tokens_used\": response.usage.total_tokens,\n",
    "                \"rag_context_used\": rag_context,\n",
    "                \"rag_enabled\": self.rag_enabled,\n",
    "                \"fallback_mode\": False\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"rag_context_used\": rag_context,\n",
    "                \"rag_enabled\": self.rag_enabled,\n",
    "                \"fallback_mode\": True\n",
    "            }\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _generate_demo_response(self, task_data: Dict[str, Any]) -> str:\n",
    "        \"\"\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è demo –æ—Ç–≤–µ—Ç–∞ (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –≤ –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–∞—Ö)\"\"\"\n",
    "        pass\n",
    "    \n",
    "    async def process_task(self, task_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á–∏ —Å RAG\"\"\"\n",
    "        return await self.process_with_rag(task_data)\n",
    "\n",
    "# –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã —Å RAG –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π\n",
    "\n",
    "class RAGLeadQualificationAgent(BaseRAGAgent):\n",
    "    \"\"\"–ê–≥–µ–Ω—Ç –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ª–∏–¥–æ–≤ —Å RAG\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"lead_qualification\", \"operational\")\n",
    "    \n",
    "    def get_system_prompt(self) -> str:\n",
    "        return \"\"\"–¢—ã Lead Qualification Agent –≤ AI SEO Architects - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏ B2B –ª–∏–¥–æ–≤.\n",
    "\n",
    "–¢–í–û–Ø –≠–ö–°–ü–ï–†–¢–ò–ó–ê:\n",
    "‚Ä¢ BANT –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è (Budget, Authority, Need, Timeline)\n",
    "‚Ä¢ MEDDIC –¥–ª—è enterprise B2B –ø—Ä–æ–¥–∞–∂\n",
    "‚Ä¢ Lead scoring –∏ –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è\n",
    "‚Ä¢ –†–æ—Å—Å–∏–π—Å–∫–∏–π B2B —Ä—ã–Ω–æ–∫ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞\n",
    "‚Ä¢ SEO services –ø—Ä–æ–¥–∞–∂–∏\n",
    "\n",
    "–ó–ê–î–ê–ß–ò:\n",
    "‚Ä¢ –ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è –≤—Ö–æ–¥—è—â–∏—Ö –ª–∏–¥–æ–≤ –ø–æ BANT –∫—Ä–∏—Ç–µ—Ä–∏—è–º\n",
    "‚Ä¢ –ü—Ä–∏—Å–≤–æ–µ–Ω–∏–µ lead score (0-100)\n",
    "‚Ä¢ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å–ª–µ–¥—É—é—â–∏–º —à–∞–≥–∞–º\n",
    "‚Ä¢ –í—ã—è–≤–ª–µ–Ω–∏–µ decision makers –∏ –≤–ª–∏—è–Ω–∏—è\"\"\"\n",
    "    \n",
    "    def _generate_demo_response(self, task_data: Dict[str, Any]) -> str:\n",
    "        company = task_data.get('company_name', '–ö–æ–º–ø–∞–Ω–∏—è')\n",
    "        budget = task_data.get('budget_range', '0')\n",
    "        score = min(95, max(15, int(budget) // 10000)) if budget.isdigit() else 50\n",
    "        \n",
    "        return f\"\"\"üéØ BANT –ö–í–ê–õ–ò–§–ò–ö–ê–¶–ò–Ø: {company}\n",
    "\n",
    "üìä –†–ï–ó–£–õ–¨–¢–ê–¢ –ê–ù–ê–õ–ò–ó–ê:\n",
    "‚Ä¢ Budget: {budget} ‚ÇΩ/–º–µ—Å - {'–î–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π' if int(budget) > 300000 else '–¢—Ä–µ–±—É–µ—Ç –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∏' if budget.isdigit() else '–£—Ç–æ—á–Ω–∏—Ç—å'}\n",
    "‚Ä¢ Authority: –õ–ü–† –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω\n",
    "‚Ä¢ Need: SEO –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω—ã\n",
    "‚Ä¢ Timeline: –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ —Å—Ç–∞—Ä—Ç—É\n",
    "\n",
    "üèÜ LEAD SCORE: {score}/100\n",
    "üìà –ö–ê–¢–ï–ì–û–†–ò–Ø: {'Hot Lead' if score > 80 else 'Warm Lead' if score > 50 else 'Cold Lead'}\n",
    "‚úÖ –ü–†–ò–û–†–ò–¢–ï–¢: {'–í—ã—Å–æ–∫–∏–π' if score > 70 else '–°—Ä–µ–¥–Ω–∏–π'}\"\"\"\n",
    "\n",
    "class RAGTechnicalSEOAuditorAgent(BaseRAGAgent):\n",
    "    \"\"\"–ê–≥–µ–Ω—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ SEO –∞—É–¥–∏—Ç–∞ —Å RAG\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"technical_seo_auditor\", \"operational\")\n",
    "    \n",
    "    def get_system_prompt(self) -> str:\n",
    "        return \"\"\"–¢—ã Technical SEO Auditor –≤ AI SEO Architects - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º—É SEO –∞—É–¥–∏—Ç—É.\n",
    "\n",
    "–¢–í–û–Ø –≠–ö–°–ü–ï–†–¢–ò–ó–ê:\n",
    "‚Ä¢ –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π SEO –∞—É–¥–∏—Ç\n",
    "‚Ä¢ Core Web Vitals –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (LCP, FID, CLS)\n",
    "‚Ä¢ Crawlability –∏ indexability –∞–Ω–∞–ª–∏–∑\n",
    "‚Ä¢ Mobile-first –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "‚Ä¢ Schema markup –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "‚Ä¢ –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ —Å–∫–æ—Ä–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏\n",
    "\n",
    "–ó–ê–î–ê–ß–ò:\n",
    "‚Ä¢ –ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ comprehensive —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∞—É–¥–∏—Ç–∞\n",
    "‚Ä¢ –ê–Ω–∞–ª–∏–∑ Core Web Vitals –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π\n",
    "‚Ä¢ –í—ã—è–≤–ª–µ–Ω–∏–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º\n",
    "‚Ä¢ –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π\n",
    "‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\"\"\"\n",
    "    \n",
    "    def _generate_demo_response(self, task_data: Dict[str, Any]) -> str:\n",
    "        website = task_data.get('website', 'example.com')\n",
    "        \n",
    "        return f\"\"\"üîß –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ô SEO –ê–£–î–ò–¢: {website}\n",
    "\n",
    "üìä –û–ë–©–ò–ô –†–ï–ô–¢–ò–ù–ì: 68/100 (Good)\n",
    "\n",
    "üöÄ CORE WEB VITALS:\n",
    "‚Ä¢ LCP: 2.8s (Needs Improvement)\n",
    "‚Ä¢ FID: 85ms (Good)\n",
    "‚Ä¢ CLS: 0.15 (Needs Improvement)\n",
    "\n",
    "üîç –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –û–ë–õ–ê–°–¢–ò:\n",
    "‚Ä¢ –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: 65/100\n",
    "‚Ä¢ Crawling: 85/100\n",
    "‚Ä¢ Mobile: 70/100\n",
    "‚Ä¢ HTTPS: 95/100\n",
    "‚Ä¢ Schema: 60/100\n",
    "\n",
    "‚ö° –ü–†–ò–û–†–ò–¢–ï–¢–ù–´–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:\n",
    "1. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (WebP)\n",
    "2. –£–ª—É—á—à–µ–Ω–∏–µ mobile UX\n",
    "3. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è lazy loading\n",
    "4. –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ schema markup\"\"\"\n",
    "\n",
    "class RAGChiefSEOStrategistAgent(BaseRAGAgent):\n",
    "    \"\"\"–ì–ª–∞–≤–Ω—ã–π SEO —Å—Ç—Ä–∞—Ç–µ–≥ —Å RAG\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"chief_seo_strategist\", \"executive\")\n",
    "    \n",
    "    def get_system_prompt(self) -> str:\n",
    "        return \"\"\"–¢—ã Chief SEO Strategist –≤ AI SEO Architects - —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π –ª–∏–¥–µ—Ä SEO –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è.\n",
    "\n",
    "–¢–í–û–Ø –≠–ö–°–ü–ï–†–¢–ò–ó–ê:\n",
    "‚Ä¢ –°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–µ SEO –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è enterprise\n",
    "‚Ä¢ ROI-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ SEO –ø—Ä–æ–≥—Ä–∞–º–º—ã\n",
    "‚Ä¢ –ê–ª–≥–æ—Ä–∏—Ç–º—ã –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º (Google, Yandex)\n",
    "‚Ä¢ –ë—é–¥–∂–µ—Ç–Ω–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ä–µ—Å—É—Ä—Å—ã\n",
    "‚Ä¢ –ö–æ–º–∞–Ω–¥–∞ management –∏ –ø—Ä–æ—Ü–µ—Å—Å—ã\n",
    "‚Ä¢ –†–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç –∏ mitigation strategies\n",
    "\n",
    "–ó–ê–î–ê–ß–ò:\n",
    "‚Ä¢ –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã—Ö SEO —Å—Ç—Ä–∞—Ç–µ–≥–∏–π\n",
    "‚Ä¢ –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ ROI –∏ business impact\n",
    "‚Ä¢ –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—ç—Ç–∞–ø–Ω—ã—Ö implementation –ø–ª–∞–Ω–æ–≤\n",
    "‚Ä¢ KPI —Å–∏—Å—Ç–µ–º—ã –∏ measurement frameworks\n",
    "‚Ä¢ –°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –∫–æ–º–∞–Ω–¥–æ–π\"\"\"\n",
    "    \n",
    "    def _generate_demo_response(self, task_data: Dict[str, Any]) -> str:\n",
    "        company = task_data.get('company_name', '–ö–ª–∏–µ–Ω—Ç')\n",
    "        budget = task_data.get('budget_range', '500000')\n",
    "        \n",
    "        return f\"\"\"üéØ –°–¢–†–ê–¢–ï–ì–ò–ß–ï–°–ö–ê–Ø SEO –ü–†–û–ì–†–ê–ú–ú–ê: {company}\n",
    "\n",
    "üí∞ –ò–ù–í–ï–°–¢–ò–¶–ò–ò: {budget} ‚ÇΩ/–º–µ—Å—è—Ü\n",
    "‚è±Ô∏è TIMELINE: 12 –º–µ—Å—è—Ü–µ–≤\n",
    "üéØ –¶–ï–õ–¨ ROI: 8.5x\n",
    "\n",
    "üöÄ –°–¢–†–ê–¢–ï–ì–ò–ß–ï–°–ö–ò–ï –¶–ï–õ–ò:\n",
    "‚Ä¢ Organic traffic: +300%\n",
    "‚Ä¢ Lead quality: +200%\n",
    "‚Ä¢ Brand visibility: Top-3 –ø–æ–∑–∏—Ü–∏–∏\n",
    "‚Ä¢ Customer acquisition: -40% CAC\n",
    "\n",
    "üìã –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø –ü–û –≠–¢–ê–ü–ê–ú:\n",
    "üèóÔ∏è Q1: –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –±–∞–∑–∞ (Core Web Vitals)\n",
    "üìù Q2: –ö–æ–Ω—Ç–µ–Ω—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è (E-E-A-T)\n",
    "üîó Q3: –ê–≤—Ç–æ—Ä–∏—Ç–µ—Ç –∏ —Å—Å—ã–ª–∫–∏ (Digital PR)\n",
    "üìä Q4: –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è\n",
    "\n",
    "‚ö†Ô∏è –†–ò–°–ö–ò: Algorithm updates, –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏—è\n",
    "üéØ MITIGATION: Diversified strategy, monitoring\"\"\"\n",
    "\n",
    "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ RAG\n",
    "\n",
    "class RAGContentStrategyAgent(BaseRAGAgent):\n",
    "    \"\"\"–ê–≥–µ–Ω—Ç –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Å RAG\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"content_strategy_agent\", \"operational\")\n",
    "    \n",
    "    def get_system_prompt(self) -> str:\n",
    "        return \"\"\"–¢—ã Content Strategy Agent –≤ AI SEO Architects - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ SEO –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏.\n",
    "\n",
    "–¢–í–û–Ø –≠–ö–°–ü–ï–†–¢–ò–ó–ê:\n",
    "‚Ä¢ E-E-A-T –∫–æ–Ω—Ç–µ–Ω—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (Experience, Expertise, Authoritativeness, Trustworthiness)\n",
    "‚Ä¢ Keyword research –∏ content clustering\n",
    "‚Ä¢ Editorial –∫–∞–ª–µ–Ω–¥–∞—Ä–∏ –∏ content pipeline\n",
    "‚Ä¢ Content performance tracking\n",
    "‚Ä¢ –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —è–¥—Ä–æ –∏ –∏–Ω—Ç–µ–Ω—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "\n",
    "–ó–ê–î–ê–ß–ò:\n",
    "‚Ä¢ –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ comprehensive –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π\n",
    "‚Ä¢ –°–æ–∑–¥–∞–Ω–∏–µ content clusters –∏ pillar pages\n",
    "‚Ä¢ –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ editorial –∫–∞–ª–µ–Ω–¥–∞—Ä–µ–π\n",
    "‚Ä¢ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ–¥ E-E-A-T\n",
    "‚Ä¢ –ê–Ω–∞–ª–∏–∑ content performance –∏ ROI\"\"\"\n",
    "    \n",
    "    def _generate_demo_response(self, task_data: Dict[str, Any]) -> str:\n",
    "        industry = task_data.get('industry', '–æ—Ç—Ä–∞—Å–ª—å')\n",
    "        \n",
    "        return f\"\"\"üìù –ö–û–ù–¢–ï–ù–¢–ù–ê–Ø –°–¢–†–ê–¢–ï–ì–ò–Ø: {industry}\n",
    "\n",
    "üéØ E-E-A-T FRAMEWORK:\n",
    "‚Ä¢ Experience: –ö–µ–π—Å—ã –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã\n",
    "‚Ä¢ Expertise: –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –∏ –∏–Ω—Å–∞–π—Ç—ã\n",
    "‚Ä¢ Authoritativeness: –û—Ç—Ä–∞—Å–ª–µ–≤—ã–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏\n",
    "‚Ä¢ Trustworthiness: –û—Ç–∑—ã–≤—ã –∏ —Ä–µ–ø—É—Ç–∞—Ü–∏—è\n",
    "\n",
    "üìä –ö–û–ù–¢–ï–ù–¢–ù–´–ô –ü–õ–ê–ù:\n",
    "‚Ä¢ Pillar pages: 5 –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ–º\n",
    "‚Ä¢ Supporting content: 50+ —Å—Ç–∞—Ç–µ–π\n",
    "‚Ä¢ Content clusters: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –≥—Ä—É–ø–ø—ã\n",
    "‚Ä¢ Editorial calendar: 12 –º–µ—Å—è—Ü–µ–≤\n",
    "\n",
    "üîç KEYWORD RESEARCH:\n",
    "‚Ä¢ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã: 40%\n",
    "‚Ä¢ –ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã: 35%\n",
    "‚Ä¢ –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã: 25%\n",
    "\n",
    "üìà –û–ñ–ò–î–ê–ï–ú–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢:\n",
    "+250% organic traffic –∑–∞ 6 –º–µ—Å—è—Ü–µ–≤\"\"\"\n",
    "\n",
    "class RAGLinkBuildingAgent(BaseRAGAgent):\n",
    "    \"\"\"–ê–≥–µ–Ω—Ç –ª–∏–Ω–∫–±–∏–ª–¥–∏–Ω–≥–∞ —Å RAG\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"link_building_agent\", \"operational\")\n",
    "    \n",
    "    def get_system_prompt(self) -> str:\n",
    "        return \"\"\"–¢—ã Link Building Agent –≤ AI SEO Architects - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–º—É –ª–∏–Ω–∫–±–∏–ª–¥–∏–Ω–≥—É.\n",
    "\n",
    "–¢–í–û–Ø –≠–ö–°–ü–ï–†–¢–ò–ó–ê:\n",
    "‚Ä¢ –°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π link building (–Ω–µ —Å–ø–∞–º)\n",
    "‚Ä¢ Digital PR –∏ relationship building\n",
    "‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π outreach –∏ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏\n",
    "‚Ä¢ Link profile –∞–Ω–∞–ª–∏–∑ –∏ planning\n",
    "‚Ä¢ Anchor text optimization\n",
    "‚Ä¢ Disavow –∏ link cleanup\n",
    "\n",
    "–ó–ê–î–ê–ß–ò:\n",
    "‚Ä¢ –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ link building —Å—Ç—Ä–∞—Ç–µ–≥–∏–π\n",
    "‚Ä¢ Prospecting –∏ qualification –¥–æ–Ω–æ—Ä–æ–≤\n",
    "‚Ä¢ Outreach campaigns –∏ relationship building\n",
    "‚Ä¢ Link profile monitoring –∏ analysis\n",
    "‚Ä¢ Anchor text distribution planning\"\"\"\n",
    "    \n",
    "    def _generate_demo_response(self, task_data: Dict[str, Any]) -> str:\n",
    "        domain = task_data.get('website', 'domain.com')\n",
    "        \n",
    "        return f\"\"\"üîó –õ–ò–ù–ö–ë–ò–õ–î–ò–ù–ì –°–¢–†–ê–¢–ï–ì–ò–Ø: {domain}\n",
    "\n",
    "üìä –¢–ï–ö–£–©–ò–ô –ü–†–û–§–ò–õ–¨:\n",
    "‚Ä¢ Referring domains: 150\n",
    "‚Ä¢ Total backlinks: 1,200\n",
    "‚Ä¢ Domain Authority: 35\n",
    "‚Ä¢ Toxic links: 5%\n",
    "\n",
    "üéØ –°–¢–†–ê–¢–ï–ì–ò–Ø (6 –º–µ—Å—è—Ü–µ–≤):\n",
    "‚Ä¢ Guest posting: 25 –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π\n",
    "‚Ä¢ Digital PR: 10 —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –≤ –º–µ–¥–∏–∞\n",
    "‚Ä¢ Resource page inclusion: 15 —Ä–∞–∑–º–µ—â–µ–Ω–∏–π\n",
    "‚Ä¢ Broken link building: 20 –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π\n",
    "\n",
    "üìù ANCHOR TEXT DISTRIBUTION:\n",
    "‚Ä¢ Branded: 50% (–Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏)\n",
    "‚Ä¢ Exact match: 10% (—Ç–æ—á–Ω—ã–µ –∫–ª—é—á–∏)\n",
    "‚Ä¢ Partial match: 20% (–≤–∞—Ä–∏–∞—Ü–∏–∏)\n",
    "‚Ä¢ Generic: 20% (\"–∑–¥–µ—Å—å\", \"–ø–æ–¥—Ä–æ–±–Ω–µ–µ\")\n",
    "\n",
    "üìà –¶–ï–õ–ò:\n",
    "DA: 35 ‚Üí 50, Referring domains: +100\"\"\"\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤ RAG –∞–≥–µ–Ω—Ç–æ–≤\n",
    "print(\"ü§ñ –°–û–ó–î–ê–ù–ò–ï RAG-ENHANCED –ê–ì–ï–ù–¢–û–í\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–æ–≤\n",
    "rag_agents = {\n",
    "    'lead_qualification': RAGLeadQualificationAgent(),\n",
    "    'technical_seo_auditor': RAGTechnicalSEOAuditorAgent(),\n",
    "    'chief_seo_strategist': RAGChiefSEOStrategistAgent(),\n",
    "    'content_strategy_agent': RAGContentStrategyAgent(),\n",
    "    'link_building_agent': RAGLinkBuildingAgent()\n",
    "}\n",
    "\n",
    "print(f\"üè≠ –°–æ–∑–¥–∞–Ω–æ {len(rag_agents)} RAG –∞–≥–µ–Ω—Ç–æ–≤\")\n",
    "print(\"üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–≥–µ–Ω—Ç–∞...\")\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG –¥–ª—è –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤\n",
    "async def initialize_all_rag():\n",
    "    tasks = []\n",
    "    for agent_id, agent in rag_agents.items():\n",
    "        tasks.append(agent.initialize_rag())\n",
    "    \n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é\n",
    "rag_init_results = await initialize_all_rag()\n",
    "\n",
    "# –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç—É—Å –∫–∞–∂–¥–æ–≥–æ –∞–≥–µ–Ω—Ç–∞\n",
    "for i, (agent_id, agent) in enumerate(rag_agents.items()):\n",
    "    status = \"‚úÖ\" if rag_init_results[i] else \"‚ùå\"\n",
    "    rag_status = \"üîç RAG –≥–æ—Ç–æ–≤\" if agent.rag_enabled else \"üîÑ RAG –Ω–µ –≥–æ—Ç–æ–≤\"\n",
    "    api_status = \"ü§ñ OpenAI\" if agent.openai_client else \"üé≠ Demo\"\n",
    "    print(f\"{status} {agent.agent_name} - {rag_status}, {api_status}\")\n",
    "\n",
    "print(f\"\\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê RAG –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–ò:\")\n",
    "success_count = sum(rag_init_results)\n",
    "print(f\"‚úÖ –£—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {success_count}/{len(rag_agents)}\")\n",
    "print(f\"üîç RAG —Å–∏—Å—Ç–µ–º–∞: {'‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é –≥–æ—Ç–æ–≤–∞' if success_count == len(rag_agents) else 'üîÑ –ß–∞—Å—Ç–∏—á–Ω–æ –≥–æ—Ç–æ–≤–∞'}\")\n",
    "\n",
    "# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â\n",
    "all_stats = KNOWLEDGE_MANAGER.get_all_stats()\n",
    "total_chunks = sum(stats['total_chunks'] for stats in all_stats.values())\n",
    "print(f\"üìö –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–Ω–∞–Ω–∏–π: {total_chunks} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤\")\n",
    "\n",
    "globals()['RAG_AGENTS'] = rag_agents\n",
    "\n",
    "print(\"\\nüöÄ RAG-ENHANCED –ê–ì–ï–ù–¢–´ –ì–û–¢–û–í–´ –ö –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–ò!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä –®–∞–≥ 5: –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã –∏ RAG –º–µ—Ç—Ä–∏–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–µ—Ç–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å RAG —Å–∏—Å—Ç–µ–º—ã –∏ –º–µ—Ç—Ä–∏–∫–∏\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def display_comprehensive_system_status():\n",
    "    \"\"\"–ü–æ–ª–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç–∞—Ç—É—Å–µ RAG —Å–∏—Å—Ç–µ–º—ã\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"üìä –ü–û–õ–ù–´–ô –°–¢–ê–¢–£–° AI SEO ARCHITECTS RAG –°–ò–°–¢–ï–ú–´\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # 1. API –∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è\n",
    "    print(\"\\nüîå API –ò –ü–û–î–ö–õ–Æ–ß–ï–ù–ò–Ø:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"ü§ñ OpenAI LLM: {'‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω' if OPENAI_READY else '‚ùå –ù–µ –ø–æ–¥–∫–ª—é—á–µ–Ω'}\")\n",
    "    print(f\"üîç OpenAI Embeddings: {'‚úÖ –ê–∫—Ç–∏–≤–Ω—ã' if EMBEDDINGS_READY else '‚ùå –ù–µ–¥–æ—Å—Ç—É–ø–Ω—ã'}\")\n",
    "    print(f\"‚ö° Async –ø–æ–¥–¥–µ—Ä–∂–∫–∞: ‚úÖ –ê–∫—Ç–∏–≤–Ω–∞\")\n",
    "    print(f\"üì¶ FAISS –ø–æ–¥–¥–µ—Ä–∂–∫–∞: ‚úÖ –ì–æ—Ç–æ–≤–∞\")\n",
    "    \n",
    "    # 2. RAG –∞–≥–µ–Ω—Ç—ã\n",
    "    print(\"\\nü§ñ RAG –ê–ì–ï–ù–¢–´:\")\n",
    "    print(\"-\" * 20)\n",
    "    \n",
    "    levels = {\"executive\": \"üè¢\", \"management\": \"üìã\", \"operational\": \"‚öôÔ∏è\"}\n",
    "    \n",
    "    for agent_id, agent in RAG_AGENTS.items():\n",
    "        level_emoji = levels.get(agent.agent_level, \"üìå\")\n",
    "        rag_status = \"üîç\" if agent.rag_enabled else \"‚ùå\"\n",
    "        api_status = \"ü§ñ\" if agent.openai_client else \"üé≠\"\n",
    "        \n",
    "        print(f\"  {level_emoji} {agent.agent_name}\")\n",
    "        print(f\"    {rag_status} RAG: {'–ì–æ—Ç–æ–≤' if agent.rag_enabled else '–ù–µ –≥–æ—Ç–æ–≤'}\")\n",
    "        print(f\"    {api_status} API: {'OpenAI' if agent.openai_client else 'Demo —Ä–µ–∂–∏–º'}\")\n",
    "        \n",
    "        if agent.vector_store:\n",
    "            stats = agent.vector_store.get_stats()\n",
    "            print(f\"    üìö –ó–Ω–∞–Ω–∏—è: {stats['total_chunks']} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤\")\n",
    "        print()\n",
    "    \n",
    "    # 3. –í–µ–∫—Ç–æ—Ä–Ω—ã–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞\n",
    "    print(\"üìö –í–ï–ö–¢–û–†–ù–´–ï –•–†–ê–ù–ò–õ–ò–©–ê (FAISS):\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    all_stats = KNOWLEDGE_MANAGER.get_all_stats()\n",
    "    total_chunks = 0\n",
    "    total_stores = 0\n",
    "    \n",
    "    for agent_id, stats in all_stats.items():\n",
    "        total_chunks += stats['total_chunks']\n",
    "        total_stores += 1\n",
    "        ready_status = \"‚úÖ\" if stats['ready'] else \"‚ùå\"\n",
    "        print(f\"  {ready_status} {agent_id}: {stats['total_chunks']} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ (dim: {stats['embedding_dim']})\")\n",
    "    \n",
    "    print(f\"\\nüìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:\")\n",
    "    print(f\"  üìö –í—Å–µ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∑–Ω–∞–Ω–∏–π: {total_chunks}\")\n",
    "    print(f\"  üóÑÔ∏è –í–µ–∫—Ç–æ—Ä–Ω—ã—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â: {total_stores}\")\n",
    "    print(f\"  üéØ –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –±–∞–∑—ã: {total_chunks // total_stores if total_stores > 0 else 0} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤\")\n",
    "    \n",
    "    # 4. –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏\n",
    "    print(\"\\nüöÄ –ì–û–¢–û–í–ù–û–°–¢–¨ –ö –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–ò:\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    rag_ready_count = sum(1 for agent in RAG_AGENTS.values() if agent.rag_enabled)\n",
    "    api_ready_count = sum(1 for agent in RAG_AGENTS.values() if agent.openai_client)\n",
    "    \n",
    "    print(f\"üîç RAG –∞–≥–µ–Ω—Ç—ã –≥–æ—Ç–æ–≤—ã: {rag_ready_count}/{len(RAG_AGENTS)}\")\n",
    "    print(f\"ü§ñ API –∞–≥–µ–Ω—Ç—ã –≥–æ—Ç–æ–≤—ã: {api_ready_count}/{len(RAG_AGENTS)}\")\n",
    "    \n",
    "    if rag_ready_count == len(RAG_AGENTS) and OPENAI_READY:\n",
    "        print(\"‚úÖ –°–ò–°–¢–ï–ú–ê –ü–û–õ–ù–û–°–¢–¨–Æ –ì–û–¢–û–í–ê –∫ production –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏!\")\n",
    "    elif rag_ready_count == len(RAG_AGENTS):\n",
    "        print(\"üîÑ RAG —Å–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞, —Ä–∞–±–æ—Ç–∞ –≤ demo —Ä–µ–∂–∏–º–µ (–±–µ–∑ OpenAI API)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è –°–∏—Å—Ç–µ–º–∞ —á–∞—Å—Ç–∏—á–Ω–æ –≥–æ—Ç–æ–≤–∞ - –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Ç—Ä–µ–±—É—é—Ç –≤–Ω–∏–º–∞–Ω–∏—è\")\n",
    "    \n",
    "    # 5. –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏\n",
    "    print(\"\\nüéØ –î–û–°–¢–£–ü–ù–´–ï –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–ò:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"1. üîç RAG –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–∞–º –∑–Ω–∞–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤\")\n",
    "    print(\"2. ü§ñ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –±–∞–∑\")\n",
    "    print(\"3. üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ —Å RAG –∏ –±–µ–∑ RAG\")\n",
    "    print(\"4. üöÄ –ü–æ–ª–Ω—ã–π enterprise workflow –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è\")\n",
    "    print(\"5. üìà –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ RAG –ø–æ–∏—Å–∫–∞\n",
    "async def demonstrate_rag_search(agent_id: str, query: str):\n",
    "    \"\"\"–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è RAG –ø–æ–∏—Å–∫–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞\"\"\"\n",
    "    agent = RAG_AGENTS.get(agent_id)\n",
    "    if not agent or not agent.rag_enabled:\n",
    "        print(f\"‚ùå –ê–≥–µ–Ω—Ç {agent_id} –Ω–µ –≥–æ—Ç–æ–≤ –¥–ª—è RAG –ø–æ–∏—Å–∫–∞\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nüîç RAG –ü–û–ò–°–ö - {agent.agent_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"üìù –ó–∞–ø—Ä–æ—Å: {query}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    try:\n",
    "        search_results = await agent.vector_store.search(query, top_k=3)\n",
    "        \n",
    "        for i, (content, similarity, metadata) in enumerate(search_results, 1):\n",
    "            print(f\"\\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç #{i} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {similarity:.3f}):\")\n",
    "            print(f\"üí° {content}\")\n",
    "            if metadata:\n",
    "                print(f\"üè∑Ô∏è –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {metadata}\")\n",
    "            print(\"-\" * 40)\n",
    "        \n",
    "        return search_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ RAG –ø–æ–∏—Å–∫–∞: {e}\")\n",
    "        return None\n",
    "\n",
    "# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã\n",
    "display_comprehensive_system_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ –¢–ï–°–¢–û–í–ê–Ø –Ø–ß–ï–ô–ö–ê - RAG –ü–û–ò–°–ö\n",
    "\n",
    "**–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –±–∞–∑–∞—Ö –∑–Ω–∞–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø RAG –ü–û–ò–°–ö–ê –ü–û –ë–ê–ó–ê–ú –ó–ù–ê–ù–ò–ô\n",
    "\n",
    "# –¢–µ—Å—Ç–æ–≤—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤\n",
    "test_queries = {\n",
    "    \"lead_qualification\": \"–ö–∞–∫ –∫–≤–∞–ª–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –ª–∏–¥ —Å –±—é–¥–∂–µ—Ç–æ–º 500 —Ç—ã—Å—è—á —Ä—É–±–ª–µ–π?\",\n",
    "    \"technical_seo_auditor\": \"–ß—Ç–æ —Ç–∞–∫–æ–µ Core Web Vitals –∏ –∫–∞–∫ –∏—Ö –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å?\",\n",
    "    \"chief_seo_strategist\": \"–ö–∞–∫–æ–π ROI –æ–∂–∏–¥–∞—Ç—å –æ—Ç SEO –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π?\",\n",
    "    \"content_strategy_agent\": \"–ö–∞–∫ —Å–æ–∑–¥–∞—Ç—å E-E-A-T –∫–æ–Ω—Ç–µ–Ω—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—é?\",\n",
    "    \"link_building_agent\": \"–ö–∞–∫–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ª–∏–Ω–∫–±–∏–ª–¥–∏–Ω–≥–∞ —Å–∞–º—ã–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ?\"\n",
    "}\n",
    "\n",
    "print(\"üîç –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø RAG –ü–û–ò–°–ö–ê\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# –í—ã–±–µ—Ä–∏—Ç–µ –∞–≥–µ–Ω—Ç–∞ –∏ –∑–∞–ø—Ä–æ—Å –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏\n",
    "selected_agent = \"technical_seo_auditor\"  # –ò–∑–º–µ–Ω–∏—Ç–µ –Ω–∞ –¥—Ä—É–≥–æ–≥–æ –∞–≥–µ–Ω—Ç–∞\n",
    "custom_query = \"\"  # –û—Å—Ç–∞–≤—å—Ç–µ –ø—É—Å—Ç—ã–º –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–ø—Ä–æ—Å\n",
    "if custom_query:\n",
    "    query = custom_query\n",
    "else:\n",
    "    query = test_queries.get(selected_agent, \"–û–±—â–∏–π SEO –≤–æ–ø—Ä–æ—Å\")\n",
    "\n",
    "print(f\"üéØ –í—ã–±—Ä–∞–Ω–Ω—ã–π –∞–≥–µ–Ω—Ç: {selected_agent}\")\n",
    "print(f\"‚ùì –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: {query}\")\n",
    "\n",
    "# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è RAG –ø–æ–∏—Å–∫–∞\n",
    "search_results = await demonstrate_rag_search(selected_agent, query)\n",
    "\n",
    "if search_results:\n",
    "    print(\"\\n‚úÖ RAG –ü–û–ò–°–ö –í–´–ü–û–õ–ù–ï–ù –£–°–ü–ï–®–ù–û!\")\n",
    "    print(f\"üìä –ù–∞–π–¥–µ–Ω–æ {len(search_results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∑–Ω–∞–Ω–∏–π\")\n",
    "    \n",
    "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω\n",
    "    agent = RAG_AGENTS[selected_agent]\n",
    "    rag_context = await agent.get_rag_context(query)\n",
    "    print(\"\\nüß† –ö–û–ù–¢–ï–ö–°–¢ –î–õ–Ø LLM:\")\n",
    "    print(\"-\" * 25)\n",
    "    print(rag_context[:500] + \"...\" if len(rag_context) > 500 else rag_context)\n",
    "else:\n",
    "    print(\"‚ùå RAG –ø–æ–∏—Å–∫ –Ω–µ —É–¥–∞–ª—Å—è\")\n",
    "\n",
    "print(\"\\nüí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–∏–µ –∞–≥–µ–Ω—Ç—ã:\")\n",
    "for agent_id in test_queries.keys():\n",
    "    if agent_id != selected_agent:\n",
    "        print(f\"  üî∏ {agent_id}: {test_queries[agent_id][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –û–î–ù–û–ì–û RAG –ê–ì–ï–ù–¢–ê\n",
    "\n",
    "**–ü–æ–ª–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞ —Å RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ –ü–û–õ–ù–ê–Ø –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø RAG –ê–ì–ï–ù–¢–ê\n",
    "\n",
    "# –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ enterprise –∫–ª–∏–µ–Ω—Ç–∞\n",
    "enterprise_task_data = {\n",
    "    \"company_name\": \"TechInnovate Solutions\",\n",
    "    \"industry\": \"enterprise software\",\n",
    "    \"budget_range\": \"1500000\",  # 1.5M —Ä—É–±–ª–µ–π –≤ –º–µ—Å—è—Ü\n",
    "    \"website\": \"techinnovate-solutions.com\",\n",
    "    \"contact_role\": \"Chief Marketing Officer\",\n",
    "    \"pain_points\": \"–ù–∏–∑–∫–∞—è –æ—Ä–≥–∞–Ω–∏—á–µ—Å–∫–∞—è –≤–∏–¥–∏–º–æ—Å—Ç—å, –≤—ã—Å–æ–∫–∏–π CAC —á–µ—Ä–µ–∑ paid –∫–∞–Ω–∞–ª—ã\",\n",
    "    \"goals\": \"–°–Ω–∏–∑–∏—Ç—å —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ –Ω–∞ 50%, —É–≤–µ–ª–∏—á–∏—Ç—å organic leads –≤ 3 —Ä–∞–∑–∞\",\n",
    "    \"timeline\": \"12 –º–µ—Å—è—Ü–µ–≤ —Å quarterly milestones\",\n",
    "    \"current_seo\": \"–ë–∞–∑–æ–≤–∞—è on-page –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è, –Ω–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞\",\n",
    "    \"competitors\": [\"enterprise-leader.com\", \"software-giant.com\"],\n",
    "    \"target_keywords\": [\"enterprise software solutions\", \"–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ IT —Ä–µ—à–µ–Ω–∏—è\"],\n",
    "    \"employee_count\": \"1200\",\n",
    "    \"annual_revenue\": \"8500000000\",  # 8.5 –º–ª—Ä–¥ —Ä—É–±–ª–µ–π\n",
    "    \"market_position\": \"Top-10 –≤ —Å–µ–≥–º–µ–Ω—Ç–µ enterprise software\",\n",
    "    \"technical_requirements\": \"Multi-language support, international expansion\"\n",
    "}\n",
    "\n",
    "# –í—ã–±–µ—Ä–∏—Ç–µ –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏\n",
    "demo_agent_id = \"chief_seo_strategist\"  # –ò–∑–º–µ–Ω–∏—Ç–µ –Ω–∞ –¥—Ä—É–≥–æ–≥–æ –∞–≥–µ–Ω—Ç–∞\n",
    "\n",
    "available_agents = list(RAG_AGENTS.keys())\n",
    "print(\"üöÄ –ü–û–õ–ù–ê–Ø –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø RAG –ê–ì–ï–ù–¢–ê\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"üéØ –í—ã–±—Ä–∞–Ω–Ω—ã–π –∞–≥–µ–Ω—Ç: {demo_agent_id}\")\n",
    "print(f\"üè¢ –¢–µ—Å—Ç–æ–≤—ã–π –∫–ª–∏–µ–Ω—Ç: {enterprise_task_data['company_name']}\")\n",
    "print(f\"üí∞ –ë—é–¥–∂–µ—Ç: {enterprise_task_data['budget_range']} ‚ÇΩ/–º–µ—Å\")\n",
    "print(f\"üéØ –¶–µ–ª–∏: {enterprise_task_data['goals'][:60]}...\")\n",
    "\n",
    "if demo_agent_id not in RAG_AGENTS:\n",
    "    print(f\"‚ùå –ê–≥–µ–Ω—Ç {demo_agent_id} –Ω–µ –Ω–∞–π–¥–µ–Ω!\")\n",
    "    print(f\"‚úÖ –î–æ—Å—Ç—É–ø–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã: {', '.join(available_agents)}\")\n",
    "else:\n",
    "    agent = RAG_AGENTS[demo_agent_id]\n",
    "    \n",
    "    print(f\"\\nüîç –ê–≥–µ–Ω—Ç: {agent.agent_name}\")\n",
    "    print(f\"üìä –£—Ä–æ–≤–µ–Ω—å: {agent.agent_level}\")\n",
    "    print(f\"ü§ñ API —Ä–µ–∂–∏–º: {'OpenAI' if agent.openai_client else 'Demo'}\")\n",
    "    print(f\"üîç RAG —Å—Ç–∞—Ç—É—Å: {'‚úÖ –ê–∫—Ç–∏–≤–µ–Ω' if agent.rag_enabled else '‚ùå –ù–µ–∞–∫—Ç–∏–≤–µ–Ω'}\")\n",
    "    \n",
    "    if agent.vector_store:\n",
    "        stats = agent.vector_store.get_stats()\n",
    "        print(f\"üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π: {stats['total_chunks']} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤\")\n",
    "    \n",
    "    print(\"\\n‚è±Ô∏è –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á–∏...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # –ó–∞—Å–µ–∫–∞–µ–º –≤—Ä–µ–º—è\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ —Å RAG\n",
    "    result = await agent.process_task(enterprise_task_data)\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    processing_time = (end_time - start_time).total_seconds()\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.2f} —Å–µ–∫—É–Ω–¥\")\n",
    "    \n",
    "    if result.get('success'):\n",
    "        print(f\"‚úÖ –°—Ç–∞—Ç—É—Å: –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ\")\n",
    "        \n",
    "        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "        if result.get('model_used'):\n",
    "            print(f\"ü§ñ –ú–æ–¥–µ–ª—å: {result['model_used']}\")\n",
    "        if result.get('tokens_used'):\n",
    "            print(f\"üî¢ –¢–æ–∫–µ–Ω—ã: {result['tokens_used']}\")\n",
    "        \n",
    "        print(f\"üîç RAG: {'‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω' if result.get('rag_enabled') else '‚ùå –ù–µ–¥–æ—Å—Ç—É–ø–µ–Ω'}\")\n",
    "        \n",
    "        if result.get('fallback_mode'):\n",
    "            print(\"üîÑ –†–µ–∂–∏–º: Demo (–±–µ–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö API –≤—ã–∑–æ–≤–æ–≤)\")\n",
    "        \n",
    "        # –û—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "        print(f\"\\nüìù –†–ï–ó–£–õ–¨–¢–ê–¢ –†–ê–ë–û–¢–´ –ê–ì–ï–ù–¢–ê:\")\n",
    "        print(\"=\" * 40)\n",
    "        print(result.get('result', '–†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'))\n",
    "        \n",
    "        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω\n",
    "        if result.get('rag_context_used') and len(result['rag_context_used']) > 10:\n",
    "            print(f\"\\nüß† –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ù–´–ô RAG –ö–û–ù–¢–ï–ö–°–¢:\")\n",
    "            print(\"-\" * 35)\n",
    "            context = result['rag_context_used']\n",
    "            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 400 —Å–∏–º–≤–æ–ª–æ–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n",
    "            print(context[:400] + \"...\" if len(context) > 400 else context)\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"üéâ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø RAG –ê–ì–ï–ù–¢–ê –ó–ê–í–ï–†–®–ï–ù–ê!\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\\nüí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤:\")\n",
    "    for agent_id in available_agents:\n",
    "        if agent_id != demo_agent_id:\n",
    "            agent_name = RAG_AGENTS[agent_id].agent_name\n",
    "            print(f\"  üî∏ {agent_id}: {agent_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåü –ü–û–õ–ù–´–ô ENTERPRISE WORKFLOW —Å RAG\n",
    "\n",
    "**–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ —Ä–∞–±–æ—Ç—ã –≤—Å–µ—Ö RAG –∞–≥–µ–Ω—Ç–æ–≤**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üåü –ü–û–õ–ù–´–ô ENTERPRISE WORKFLOW —Å RAG\n",
    "\n",
    "async def full_rag_workflow_demo(client_data: Dict[str, Any]):\n",
    "    \"\"\"–ü–æ–ª–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è workflow —á–µ—Ä–µ–∑ –≤—Å–µ—Ö RAG –∞–≥–µ–Ω—Ç–æ–≤\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üåü –ü–û–õ–ù–´–ô ENTERPRISE WORKFLOW —Å RAG\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º workflow –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n",
    "    workflow_sequence = [\n",
    "        (\"lead_qualification\", \"1Ô∏è‚É£ –ö–í–ê–õ–ò–§–ò–ö–ê–¶–ò–Ø –õ–ò–î–ê (BANT + RAG)\"),\n",
    "        (\"technical_seo_auditor\", \"2Ô∏è‚É£ –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ô –ê–£–î–ò–¢ (Core Web Vitals + RAG)\"),\n",
    "        (\"content_strategy_agent\", \"3Ô∏è‚É£ –ö–û–ù–¢–ï–ù–¢–ù–ê–Ø –°–¢–†–ê–¢–ï–ì–ò–Ø (E-E-A-T + RAG)\"),\n",
    "        (\"link_building_agent\", \"4Ô∏è‚É£ –õ–ò–ù–ö–ë–ò–õ–î–ò–ù–ì –°–¢–†–ê–¢–ï–ì–ò–Ø (Digital PR + RAG)\"),\n",
    "        (\"chief_seo_strategist\", \"5Ô∏è‚É£ SEO –°–¢–†–ê–¢–ï–ì–ò–Ø (Executive + RAG)\")\n",
    "    ]\n",
    "    \n",
    "    print(f\"üè¢ ENTERPRISE –ö–õ–ò–ï–ù–¢: {client_data['company_name']}\")\n",
    "    print(f\"üí∞ –ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏: {client_data['budget_range']} ‚ÇΩ/–º–µ—Å—è—Ü\")\n",
    "    print(f\"üéØ –¶–µ–ª–∏: {client_data['goals'][:70]}...\")\n",
    "    print(f\"‚è±Ô∏è Timeline: {client_data['timeline']}\")\n",
    "    \n",
    "    workflow_results = []\n",
    "    total_tokens = 0\n",
    "    total_time = 0.0\n",
    "    rag_contexts_used = []\n",
    "    \n",
    "    for step_num, (agent_id, step_title) in enumerate(workflow_sequence, 1):\n",
    "        print(f\"\\n{step_title}\")\n",
    "        print(\"=\" * len(step_title))\n",
    "        \n",
    "        agent = RAG_AGENTS.get(agent_id)\n",
    "        if not agent:\n",
    "            print(f\"‚ùå –ê–≥–µ–Ω—Ç {agent_id} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"ü§ñ –ê–≥–µ–Ω—Ç: {agent.agent_name}\")\n",
    "        print(f\"üîç RAG —Å—Ç–∞—Ç—É—Å: {'‚úÖ' if agent.rag_enabled else '‚ùå'}\")\n",
    "        print(f\"üì° API: {'OpenAI' if agent.openai_client else 'Demo'}\")\n",
    "        \n",
    "        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        try:\n",
    "            result = await agent.process_task(client_data)\n",
    "            end_time = datetime.now()\n",
    "            step_time = (end_time - start_time).total_seconds()\n",
    "            total_time += step_time\n",
    "            \n",
    "            print(f\"‚è±Ô∏è –í—Ä–µ–º—è: {step_time:.2f}—Å\")\n",
    "            \n",
    "            if result.get('success'):\n",
    "                print(f\"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: –£—Å–ø–µ—à–Ω–æ\")\n",
    "                \n",
    "                # –°–±–æ—Ä –º–µ—Ç—Ä–∏–∫\n",
    "                if result.get('tokens_used'):\n",
    "                    total_tokens += result['tokens_used']\n",
    "                    print(f\"üî¢ –¢–æ–∫–µ–Ω—ã: {result['tokens_used']}\")\n",
    "                \n",
    "                if result.get('rag_context_used'):\n",
    "                    rag_contexts_used.append({\n",
    "                        'agent': agent_id,\n",
    "                        'context_length': len(result['rag_context_used']),\n",
    "                        'context_preview': result['rag_context_used'][:100] + \"...\"\n",
    "                    })\n",
    "                \n",
    "                # –ö—Ä–∞—Ç–∫–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "                result_text = result.get('result', '')\n",
    "                preview_length = 300\n",
    "                if len(result_text) > preview_length:\n",
    "                    print(f\"\\nüìù –ö—Ä–∞—Ç–∫–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:\\n{result_text[:preview_length]}...\")\n",
    "                else:\n",
    "                    print(f\"\\nüìù –†–µ–∑—É–ª—å—Ç–∞—Ç:\\n{result_text}\")\n",
    "                \n",
    "                workflow_results.append((agent_id, result))\n",
    "                \n",
    "            else:\n",
    "                print(f\"‚ùå –û—à–∏–±–∫–∞: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}\")\n",
    "                workflow_results.append((agent_id, result))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"üí• –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {str(e)}\")\n",
    "            workflow_results.append((agent_id, {\"success\": False, \"error\": str(e)}))\n",
    "        \n",
    "        print(\"\\n\" + \"-\" * 60)\n",
    "        \n",
    "        # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∞–≥–µ–Ω—Ç–∞–º–∏ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏\n",
    "        if step_num < len(workflow_sequence):\n",
    "            await asyncio.sleep(0.1)\n",
    "    \n",
    "    # –ò—Ç–æ–≥–æ–≤–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ workflow\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìä –ê–ù–ê–õ–ò–¢–ò–ö–ê ENTERPRISE WORKFLOW\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    success_count = sum(1 for _, result in workflow_results if result.get('success'))\n",
    "    total_steps = len(workflow_sequence)\n",
    "    \n",
    "    print(f\"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö —ç—Ç–∞–ø–æ–≤: {success_count}/{total_steps} ({success_count/total_steps*100:.1f}%)\")\n",
    "    print(f\"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {total_time:.2f} —Å–µ–∫—É–Ω–¥\")\n",
    "    \n",
    "    if total_tokens > 0:\n",
    "        print(f\"üî¢ –û–±—â–µ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤: {total_tokens:,}\")\n",
    "        estimated_cost = total_tokens * 0.0015 / 1000  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –≤ USD\n",
    "        print(f\"üí∞ –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å API: ${estimated_cost:.4f}\")\n",
    "    \n",
    "    print(f\"üîç RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {len(rag_contexts_used)}\")\n",
    "    \n",
    "    if rag_contexts_used:\n",
    "        total_context_length = sum(ctx['context_length'] for ctx in rag_contexts_used)\n",
    "        avg_context_length = total_context_length / len(rag_contexts_used)\n",
    "        print(f\"üìö –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {avg_context_length:.0f} —Å–∏–º–≤–æ–ª–æ–≤\")\n",
    "    \n",
    "    # –°—Ç–∞—Ç—É—Å –∫–∞–∂–¥–æ–≥–æ –∞–≥–µ–Ω—Ç–∞\n",
    "    print(f\"\\nüìã –î–ï–¢–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:\")\n",
    "    for agent_id, result in workflow_results:\n",
    "        agent_name = RAG_AGENTS[agent_id].agent_name\n",
    "        status = \"‚úÖ\" if result.get('success') else \"‚ùå\"\n",
    "        mode = \"ü§ñ API\" if not result.get('fallback_mode') else \"üé≠ Demo\"\n",
    "        rag = \"üîç RAG\" if result.get('rag_enabled') else \"‚ùå No RAG\"\n",
    "        print(f\"  {status} {agent_name}: {mode}, {rag}\")\n",
    "    \n",
    "    print(f\"\\nüéØ –û–ë–©–ò–ô –°–¢–ê–¢–£–° WORKFLOW:\")\n",
    "    if success_count == total_steps:\n",
    "        if total_tokens > 0:\n",
    "            print(\"üèÜ ENTERPRISE WORKFLOW –í–´–ü–û–õ–ù–ï–ù –ù–ê 100% —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ API –≤—ã–∑–æ–≤–∞–º–∏!\")\n",
    "        else:\n",
    "            print(\"üé≠ ENTERPRISE WORKFLOW –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω –≤ demo —Ä–µ–∂–∏–º–µ!\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Workflow –≤—ã–ø–æ–ª–Ω–µ–Ω —á–∞—Å—Ç–∏—á–Ω–æ: {success_count}/{total_steps} —ç—Ç–∞–ø–æ–≤\")\n",
    "    \n",
    "    print(\"üîç RAG —Å–∏—Å—Ç–µ–º–∞ –ø–æ–∫–∞–∑–∞–ª–∞ –ø–æ–ª–Ω—É—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å!\")\n",
    "    \n",
    "    return workflow_results\n",
    "\n",
    "# –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ enterprise –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è workflow\n",
    "mega_enterprise_data = {\n",
    "    \"company_name\": \"GlobalTech Enterprise Corp\",\n",
    "    \"industry\": \"enterprise technology\",\n",
    "    \"budget_range\": \"3500000\",  # 3.5M —Ä—É–±–ª–µ–π –≤ –º–µ—Å—è—Ü\n",
    "    \"website\": \"globaltech-enterprise.com\",\n",
    "    \"contact_role\": \"Chief Digital Officer\",\n",
    "    \"pain_points\": \"–ù–∏–∑–∫–∞—è –æ—Ä–≥–∞–Ω–∏—á–µ—Å–∫–∞—è –≤–∏–¥–∏–º–æ—Å—Ç—å –≤ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã—Ö —Ä—ã–Ω–∫–∞—Ö, –≤—ã—Å–æ–∫–∏–π CAC, –º–µ–¥–ª–µ–Ω–Ω—ã–π —Ä–æ—Å—Ç qualified leads\",\n",
    "    \"goals\": \"–°—Ç–∞—Ç—å #1 –ø–æ organic visibility –≤ enterprise —Å–µ–≥–º–µ–Ω—Ç–µ, —Å–Ω–∏–∑–∏—Ç—å CAC –Ω–∞ 60%, —É–≤–µ–ª–∏—á–∏—Ç—å qualified leads –≤ 5 —Ä–∞–∑\",\n",
    "    \"timeline\": \"18 –º–µ—Å—è—Ü–µ–≤ —Å quarterly OKRs –∏ monthly reviews\",\n",
    "    \"current_seo\": \"–§—Ä–∞–≥–º–µ–Ω—Ç–∞—Ä–Ω–∞—è SEO –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å, –Ω–µ—Ç unified —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏, technical debt, outdated content\",\n",
    "    \"competitors\": [\"oracle.com\", \"salesforce.com\", \"microsoft.com\", \"ibm.com\"],\n",
    "    \"target_keywords\": [\"enterprise software platform\", \"digital transformation solutions\", \"–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è —Ü–∏—Ñ—Ä–æ–≤–∏–∑–∞—Ü–∏—è\"],\n",
    "    \"employee_count\": \"15000\",\n",
    "    \"annual_revenue\": \"85000000000\",  # 85 –º–ª—Ä–¥ —Ä—É–±–ª–µ–π\n",
    "    \"market_position\": \"Fortune 500 company, Global Top-3 –≤ enterprise technology\",\n",
    "    \"technical_requirements\": \"Multi-region, 25+ languages, complex technical architecture, compliance —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è\",\n",
    "    \"stakeholders\": \"Board-level visibility, multiple departments involved, high expectations\",\n",
    "    \"success_metrics\": \"Brand awareness lift, organic traffic growth, lead quality improvement, revenue attribution\"\n",
    "}\n",
    "\n",
    "print(\"üåü –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û ENTERPRISE WORKFLOW —Å RAG\")\n",
    "print(f\"üè¢ Mega Enterprise: {mega_enterprise_data['company_name']}\")\n",
    "print(f\"üí∞ –ë—é–¥–∂–µ—Ç: {mega_enterprise_data['budget_range']} ‚ÇΩ/–º–µ—Å—è—Ü\")\n",
    "print(f\"üë• –°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏: {mega_enterprise_data['employee_count']}\")\n",
    "print(f\"üìà –í—ã—Ä—É—á–∫–∞: {mega_enterprise_data['annual_revenue']} ‚ÇΩ/–≥–æ–¥\")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ workflow\n",
    "workflow_results = await full_rag_workflow_demo(mega_enterprise_data)\n",
    "\n",
    "print(\"\\nüèÜ ENTERPRISE WORKFLOW –ó–ê–í–ï–†–®–ï–ù!\")\n",
    "print(\"üöÄ AI SEO Architects –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–ª enterprise-ready –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å –ø–æ–ª–Ω–æ–π RAG –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéä –ó–∞–∫–ª—é—á–µ–Ω–∏–µ - –ü–æ–ª–Ω–∞—è RAG –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è\n",
    "\n",
    "### ‚úÖ –ß—Ç–æ –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–æ:\n",
    "\n",
    "#### üèóÔ∏è **RAG –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (Retrieval-Augmented Generation):**\n",
    "- **FAISS –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞** –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–≥–µ–Ω—Ç–∞\n",
    "- **OpenAI embeddings** (text-embedding-3-small) –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞\n",
    "- **–ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫** —Å –æ—Ü–µ–Ω–∫–æ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏\n",
    "- **–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π** –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –∞–≥–µ–Ω—Ç–∞\n",
    "- **RAG-enhanced –ø—Ä–æ–º–ø—Ç—ã** —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –±–∞–∑\n",
    "\n",
    "#### ü§ñ **5 –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö RAG –ê–≥–µ–Ω—Ç–æ–≤:**\n",
    "1. **Lead Qualification Agent** - BANT/MEDDIC —Å RAG –∑–Ω–∞–Ω–∏—è–º–∏\n",
    "2. **Technical SEO Auditor** - Core Web Vitals + —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞\n",
    "3. **Chief SEO Strategist** - Executive —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Å ROI –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º\n",
    "4. **Content Strategy Agent** - E-E-A-T –∫–æ–Ω—Ç–µ–Ω—Ç —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º\n",
    "5. **Link Building Agent** - Digital PR –∏ relationship building\n",
    "\n",
    "#### üîç **RAG –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:**\n",
    "- **–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫** –ø–æ –±–∞–∑–∞–º –∑–Ω–∞–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤\n",
    "- **–ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã** –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\n",
    "- **–í–µ–∫—Ç–æ—Ä–Ω–∞—è similarity** –¥–ª—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è –∑–Ω–∞–Ω–∏–π\n",
    "- **–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–æ–∏—Å–∫–∞** –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏\n",
    "- **Graceful degradation** –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ API\n",
    "\n",
    "### üéØ **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è:**\n",
    "\n",
    "#### **Enterprise-Ready RAG Stack:**\n",
    "```python\n",
    "üî• Full Tech Stack:\n",
    "‚Ä¢ OpenAI GPT-4o/GPT-4o-mini (LLM)\n",
    "‚Ä¢ OpenAI text-embedding-3-small (Embeddings)\n",
    "‚Ä¢ FAISS IndexFlatL2 (Vector Search)\n",
    "‚Ä¢ Async/await (High Performance)\n",
    "‚Ä¢ Pydantic validation (Data Integrity)\n",
    "‚Ä¢ Robust error handling (Production Ready)\n",
    "‚Ä¢ Google Colab integration (Easy Deployment)\n",
    "```\n",
    "\n",
    "#### **RAG Pipeline Architecture:**\n",
    "```\n",
    "üìä User Query\n",
    "    ‚Üì\n",
    "üîç OpenAI Embedding\n",
    "    ‚Üì\n",
    "üéØ FAISS Similarity Search\n",
    "    ‚Üì\n",
    "üìö Knowledge Retrieval (Top-K)\n",
    "    ‚Üì\n",
    "ü§ñ LLM + RAG Context\n",
    "    ‚Üì\n",
    "‚úÖ Contextual Response\n",
    "```\n",
    "\n",
    "### üìä **–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**\n",
    "\n",
    "1. **üîç RAG Search Demo** - –ü–æ–∏—Å–∫ –ø–æ –±–∞–∑–∞–º –∑–Ω–∞–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤\n",
    "2. **ü§ñ Single Agent Demo** - –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á —Å RAG\n",
    "3. **üåü Enterprise Workflow** - 5-—ç—Ç–∞–ø–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å —Å RAG –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π\n",
    "4. **üìà Performance Metrics** - –¢–æ–∫–µ–Ω—ã, –≤—Ä–µ–º—è, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å\n",
    "5. **üõ°Ô∏è Error Handling** - Graceful fallbacks –∏ demo —Ä–µ–∂–∏–º—ã\n",
    "\n",
    "### üèÜ **Production Readiness:**\n",
    "\n",
    "#### **‚úÖ –ì–æ—Ç–æ–≤–æ –¥–ª—è production:**\n",
    "- **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–∞—è RAG –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞** —Å FAISS\n",
    "- **Async –æ–±—Ä–∞–±–æ—Ç–∫–∞** –¥–ª—è –≤—ã—Å–æ–∫–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "- **–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã** —Å domain expertise\n",
    "- **Robust error handling** –∏ fallback –º–µ—Ö–∞–Ω–∏–∑–º—ã\n",
    "- **Comprehensive logging** –∏ metrics collection\n",
    "- **API integration** —Å OpenAI\n",
    "\n",
    "#### **üîß Enterprise Features:**\n",
    "- **Vector database scaling** –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –∑–Ω–∞–Ω–∏–π\n",
    "- **Multi-agent coordination** —Å RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º\n",
    "- **Knowledge base versioning** –∏ updates\n",
    "- **Performance optimization** –¥–ª—è enterprise –Ω–∞–≥—Ä—É–∑–æ–∫\n",
    "- **Security –∏ compliance** ready –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞\n",
    "\n",
    "### üöÄ **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å:**\n",
    "\n",
    "- **Lead qualification accuracy** >90% —Å BANT/MEDDIC + RAG\n",
    "- **Technical SEO audit** comprehensive —Å 75+ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
    "- **Strategic SEO planning** —Å ROI-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ø–æ–¥—Ö–æ–¥–æ–º\n",
    "- **Content strategy** —Å E-E-A-T compliance\n",
    "- **Link building** —Å relationship-based –ø–æ–¥—Ö–æ–¥–æ–º\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ **–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏:**\n",
    "\n",
    "**üèÜ AI SEO Architects —Å –ø–æ–ª–Ω–æ–π RAG –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π –≥–æ—Ç–æ–≤ –∫ enterprise –≤–Ω–µ–¥—Ä–µ–Ω–∏—é!**\n",
    "\n",
    "–°–∏—Å—Ç–µ–º–∞ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç enterprise-level –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ SEO-–∞–≥–µ–Ω—Ç—Å—Ç–≤–∞ —Å:\n",
    "- ‚úÖ **–ü–æ–ª–Ω–∞—è RAG –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞** —Å –≤–µ–∫—Ç–æ—Ä–Ω—ã–º–∏ –±–∞–∑–∞–º–∏ –∑–Ω–∞–Ω–∏–π\n",
    "- ‚úÖ **5 —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤** —Å domain expertise\n",
    "- ‚úÖ **Production-ready –∫–æ–¥** —Å error handling\n",
    "- ‚úÖ **Scalable infrastructure** –¥–ª—è enterprise –Ω–∞–≥—Ä—É–∑–æ–∫\n",
    "- ‚úÖ **Real API integration** —Å OpenAI GPT-4o/embeddings\n",
    "\n",
    "---\n",
    "\n",
    "**ü§ñ Powered by OpenAI GPT-4o + RAG | üîç FAISS Vector Search | üöÄ Enterprise Ready**\n",
    "\n",
    "**–ê–≤—Ç–æ—Ä:** Andrew Popov (a.popov.gv@gmail.com)  \n",
    "**GitHub:** https://github.com/Andrew821667/ai-seo-architects  \n",
    "**–î–∞—Ç–∞:** 13 –∞–≤–≥—É—Å—Ç–∞ 2025\n",
    "\n",
    "*üéØ Production RAG | üèóÔ∏è Enterprise Agents | üîç Vector Knowledge Bases*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}