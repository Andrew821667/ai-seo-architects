{
 "cells": [
  {
   "cell_type": "code",
   "source": "# –Ø–ß–ï–ô–ö–ê 7: üéØ –§–ò–ù–ê–õ–¨–ù–ê–Ø ENHANCED –î–ï–ú–û-–Ø–ß–ï–ô–ö–ê\n\nprint('üéØ AI SEO ARCHITECTS - ENHANCED DEMO v3.0')\nprint('=' * 80)\nprint('üöÄ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û ENHANCED –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø')\nprint('üíé Executive (GPT-4) + Management/Operational (GPT-4o-mini)')\nprint('üìä Dual Output: Business Stories + Technical Metrics')\nprint('üí∞ Token Tracking + Cost Calculation')\nprint('üö´ Telemetry Disabled + File Reports')\nprint('=' * 80)\n\n# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –¥–µ–º–æ —Ñ—É–Ω–∫—Ü–∏—é\nexec(open('final_demo_cell.py').read())\n\nprint('\\n‚ú® –í–°–ï –ì–û–¢–û–í–û! –í—ã–ø–æ–ª–Ω–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É –Ω–∏–∂–µ:')\nprint('=' * 50)\nprint('üöÄ await run_complete_ai_seo_architects_demo_enhanced()')\nprint('=' * 50)\n\nprint('\\nüí° –ß–¢–û –ü–û–õ–£–ß–ò–¢–ï:')\nprint('‚îú‚îÄ üéØ –ë–∏–∑–Ω–µ—Å-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –ª–∏–¥—É')\nprint('‚îú‚îÄ üìä –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É')\nprint('‚îú‚îÄ üí∞ –ü–æ–ª–Ω—ã–π —É—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –ø–æ —É—Ä–æ–≤–Ω—è–º –∞–≥–µ–Ω—Ç–æ–≤')\nprint('‚îú‚îÄ üìÅ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–æ–≤ –≤ —Ñ–∞–π–ª—ã')\nprint('‚îú‚îÄ üîÑ Real-time –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–∞–π–ø–ª–∞–π–Ω–æ–≤')\nprint('‚îî‚îÄ ‚ú® Executive summary –¥–ª—è –±–∏–∑–Ω–µ—Å–∞ + billing –¥–ª—è –±—É—Ö–≥–∞–ª—Ç–µ—Ä–∏–∏')\n\nprint('\\nüéä ENHANCED DEMO v3.0 –ì–û–¢–û–í –ö –ó–ê–ü–£–°–ö–£!')\n\n# –ó–∞–ø—É—Å–∫ enhanced –¥–µ–º–æ\nawait run_complete_ai_seo_architects_demo_enhanced()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# –Ø–ß–ï–ô–ö–ê 6: –ó–∞–≥—Ä—É–∑–∫–∞ —É–ª—É—á—à–µ–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\n\nprint('üîß –ó–ê–ì–†–£–ó–ö–ê ENHANCED –§–£–ù–ö–¶–ò–ô –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø')\nprint('=' * 60)\n\ntry:\n    # –ó–∞–≥—Ä—É–∂–∞–µ–º enhanced —Ñ—É–Ω–∫—Ü–∏–∏\n    exec(open('enhanced_testing_functions.py').read())\n    print('‚úÖ Enhanced testing functions –∑–∞–≥—Ä—É–∂–µ–Ω—ã')\n    \n    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Ñ—É–Ω–∫—Ü–∏–π\n    functions_to_check = [\n        'show_business_pipeline_story',\n        'show_technical_metrics', \n        'save_detailed_results',\n        'test_pipeline_scenarios_enhanced'\n    ]\n    \n    for func_name in functions_to_check:\n        if func_name in globals():\n            print(f'‚úÖ {func_name} - –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é')\n        else:\n            print(f'‚ùå {func_name} - –Ω–µ –Ω–∞–π–¥–µ–Ω–∞')\n    \n    print('\\nüéØ Enhanced —Ñ—É–Ω–∫—Ü–∏–∏ –≥–æ—Ç–æ–≤—ã!')\n    \nexcept Exception as e:\n    print(f'‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ enhanced —Ñ—É–Ω–∫—Ü–∏–π: {e}')\n    print('üí° –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Ñ–∞–π–ª enhanced_testing_functions.py –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞')\n\nprint('\\nüéØ –ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —è—á–µ–π–∫–µ –¥–µ–º–æ!')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –Ø–ß–ï–ô–ö–ê 1: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∏ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ —Ç–µ–ª–µ–º–µ—Ç—Ä–∏–∏\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "# üö´ –û–¢–ö–õ–Æ–ß–ê–ï–ú –í–°–Æ –¢–ï–õ–ï–ú–ï–¢–†–ò–Æ –ò –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–Ø\n",
    "print('üö´ –û—Ç–∫–ª—é—á–µ–Ω–∏–µ —Ç–µ–ª–µ–º–µ—Ç—Ä–∏–∏ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π...')\n",
    "os.environ['TELEMETRY_DISABLED'] = 'true'\n",
    "os.environ['ANTHROPIC_ANALYTICS_OPT_OUT'] = 'true'\n",
    "os.environ['OPENAI_LOG_LEVEL'] = 'ERROR'\n",
    "warnings.filterwarnings('ignore')\n",
    "print('‚úÖ –¢–µ–ª–µ–º–µ—Ç—Ä–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞')\n",
    "\n",
    "print('üì¶ –£–°–¢–ê–ù–û–í–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô')\n",
    "print('=' * 60)\n",
    "\n",
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –≤–µ—Ä—Å–∏—è–º–∏\n",
    "!pip install --quiet openai==1.3.5\n",
    "!pip install --quiet langchain==0.0.340\n",
    "!pip install --quiet langchain-openai==0.0.2\n",
    "!pip install --quiet chromadb==0.4.15\n",
    "!pip install --quiet python-dotenv==1.0.0\n",
    "!pip install --quiet asyncio==3.4.3\n",
    "!pip install --quiet aiofiles==23.2.1\n",
    "!pip install --quiet typing-extensions==4.8.0\n",
    "\n",
    "print('\\n‚úÖ –í—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã!')\n",
    "print('üéØ –ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ —è—á–µ–π–∫–µ 2 –¥–ª—è –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –Ø–ß–ï–ô–ö–ê 2: –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "print('üìÅ –ö–õ–û–ù–ò–†–û–í–ê–ù–ò–ï –ü–†–û–ï–ö–¢–ê AI SEO ARCHITECTS')\n",
    "print('=' * 60)\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é\n",
    "current_dir = os.getcwd()\n",
    "print(f'üìç –¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {current_dir}')\n",
    "\n",
    "# –ö–ª–æ–Ω–∏—Ä—É–µ–º –ø—Ä–æ–µ–∫—Ç –µ—Å–ª–∏ –µ–≥–æ –µ—â–µ –Ω–µ—Ç\n",
    "project_path = '/content/ai-seo-architects'\n",
    "if not os.path.exists(project_path):\n",
    "    print('üîÑ –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è...')\n",
    "    !git clone https://github.com/Andrew821667/ai-seo-architects.git /content/ai-seo-architects\n",
    "    print('‚úÖ –ü—Ä–æ–µ–∫—Ç —Å–∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω')\n",
    "else:\n",
    "    print('‚úÖ –ü—Ä–æ–µ–∫—Ç —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç')\n",
    "    # –û–±–Ω–æ–≤–ª—è–µ–º –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤–µ—Ä—Å–∏–∏\n",
    "    os.chdir(project_path)\n",
    "    !git pull origin main\n",
    "\n",
    "# –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞\n",
    "os.chdir(project_path)\n",
    "\n",
    "# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ Python PATH\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "    print('‚úÖ –ü—É—Ç—å –ø—Ä–æ–µ–∫—Ç–∞ –¥–æ–±–∞–≤–ª–µ–Ω –≤ Python PATH')\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞\n",
    "print('\\nüìÇ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞:')\n",
    "!ls -la\n",
    "\n",
    "print('\\nüéØ –ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ —è—á–µ–π–∫–µ 3 –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ OpenAI API')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –Ø–ß–ï–ô–ö–ê 3: –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ OpenAI API —á–µ—Ä–µ–∑ Colab secrets\n",
    "\n",
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "print('üîë –ù–ê–°–¢–†–û–ô–ö–ê OPENAI API')\n",
    "print('=' * 60)\n",
    "\n",
    "try:\n",
    "    # –ü–æ–ª—É—á–∞–µ–º API –∫–ª—é—á –∏–∑ —Å–µ–∫—Ä–µ—Ç–æ–≤ Google Colab\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "    \n",
    "    if OPENAI_API_KEY:\n",
    "        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "        os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "        print('‚úÖ OpenAI API –∫–ª—é—á —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ Colab secrets')\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ\n",
    "        import openai\n",
    "        client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "        \n",
    "        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ–±–æ–ª—å—à–∏–º –∑–∞–ø—Ä–æ—Å–æ–º\n",
    "        test_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "            max_tokens=5\n",
    "        )\n",
    "        print('‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ OpenAI API –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç')\n",
    "        \n",
    "    else:\n",
    "        print('‚ùå OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–µ–∫—Ä–µ—Ç–∞—Ö Colab')\n",
    "        print('üí° –î–æ–±–∞–≤—å—Ç–µ OPENAI_API_KEY –≤ —Å–µ–∫—Ä–µ—Ç—ã Google Colab')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f'‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ OpenAI API: {e}')\n",
    "    print('üí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å API –∫–ª—é—á–∞ –≤ —Å–µ–∫—Ä–µ—Ç–∞—Ö Colab')\n",
    "\n",
    "print('\\nüéØ –ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ —è—á–µ–π–∫–µ 4 –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ ChromaDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –Ø–ß–ï–ô–ö–ê 4: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ChromaDB —Å –æ—Ç–∫–ª—é—á–µ–Ω–Ω–æ–π —Ç–µ–ª–µ–º–µ—Ç—Ä–∏–µ–π\n",
    "\n",
    "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–ª–µ–º–µ—Ç—Ä–∏–∏ ChromaDB\n",
    "os.environ['ANONYMIZED_TELEMETRY'] = 'False'\n",
    "os.environ['CHROMA_SERVER_NOFILE'] = '65536'\n",
    "\n",
    "print('üóÑÔ∏è –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø CHROMADB (–ë–ï–ó –¢–ï–õ–ï–ú–ï–¢–†–ò–ò)')\n",
    "print('=' * 60)\n",
    "\n",
    "try:\n",
    "    import importlib\n",
    "    import sys\n",
    "    \n",
    "    # –û—á–∏—â–∞–µ–º –∫—ç—à –º–æ–¥—É–ª–µ–π\n",
    "    modules_to_reload = []\n",
    "    for module_name in list(sys.modules.keys()):\n",
    "        if 'knowledge' in module_name or 'faiss' in module_name.lower():\n",
    "            modules_to_reload.append(module_name)\n",
    "    \n",
    "    for module_name in modules_to_reload:\n",
    "        if module_name in sys.modules:\n",
    "            del sys.modules[module_name]\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞\n",
    "    knowledge_path = '/content/ai-seo-architects/knowledge'\n",
    "    if os.path.exists(knowledge_path):\n",
    "        print(f'‚úÖ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è knowledge –Ω–∞–π–¥–µ–Ω–∞: {knowledge_path}')\n",
    "        \n",
    "        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã –∑–Ω–∞–Ω–∏–π\n",
    "        total_knowledge_files = 0\n",
    "        for level in ['executive', 'management', 'operational']:\n",
    "            level_path = os.path.join(knowledge_path, level)\n",
    "            if os.path.exists(level_path):\n",
    "                md_files = [f for f in os.listdir(level_path) if f.endswith('.md')]\n",
    "                total_knowledge_files += len(md_files)\n",
    "                print(f'‚úÖ {level:12}: {len(md_files):2d} —Ñ–∞–π–ª–æ–≤ –∑–Ω–∞–Ω–∏–π')\n",
    "        \n",
    "        print(f'üìÑ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –∑–Ω–∞–Ω–∏–π: {total_knowledge_files}')\n",
    "    else:\n",
    "        print(f'‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è knowledge –ù–ï –Ω–∞–π–¥–µ–Ω–∞: {knowledge_path}')\n",
    "        total_knowledge_files = 0\n",
    "    \n",
    "    if total_knowledge_files > 0:\n",
    "        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º ChromaDB Knowledge Manager\n",
    "        project_path = '/content/ai-seo-architects'\n",
    "        if project_path not in sys.path:\n",
    "            sys.path.append(project_path)\n",
    "        \n",
    "        import importlib.util\n",
    "        spec = importlib.util.spec_from_file_location(\n",
    "            \"chroma_knowledge_manager\", \n",
    "            \"/content/ai-seo-architects/knowledge/chroma_knowledge_manager.py\"\n",
    "        )\n",
    "        chroma_module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(chroma_module)\n",
    "        \n",
    "        knowledge_manager = chroma_module.knowledge_manager\n",
    "        print('‚úÖ ChromaDB Knowledge Manager –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω (—Ç–µ–ª–µ–º–µ—Ç—Ä–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞)')\n",
    "        \n",
    "        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π\n",
    "        print('üöÄ –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∑–Ω–∞–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤...')\n",
    "        initialization_results = knowledge_manager.initialize_all_agents_knowledge()\n",
    "        \n",
    "        successful_agents = [agent for agent, success in initialization_results.items() if success]\n",
    "        \n",
    "        print(f'‚úÖ –ì–æ—Ç–æ–≤–æ: {len(successful_agents)}/14 –∞–≥–µ–Ω—Ç–æ–≤ –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω—ã')\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "        globals()['CHROMADB_READY'] = len(successful_agents) >= 10\n",
    "        globals()['SUCCESSFUL_AGENTS'] = successful_agents\n",
    "        globals()['KNOWLEDGE_MANAGER'] = knowledge_manager\n",
    "        \n",
    "        success_rate = len(successful_agents) / 14 * 100\n",
    "        print(f'üéØ ChromaDB –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å: {success_rate:.1f}%')\n",
    "        \n",
    "    else:\n",
    "        globals()['CHROMADB_READY'] = False\n",
    "        globals()['SUCCESSFUL_AGENTS'] = []\n",
    "\nexcept Exception as e:\n",
    "    print(f'‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ ChromaDB: {e}')\n",
    "    globals()['CHROMADB_READY'] = False\n",
    "    globals()['SUCCESSFUL_AGENTS'] = []\n",
    "\n",
    "print('\\nüéØ –ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ —è—á–µ–π–∫–µ 5 –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –Ø–ß–ï–ô–ö–ê 5: –°–æ–∑–¥–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –ø–æ —É—Ä–æ–≤–Ω—è–º + –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤\n",
    "\n",
    "print('ü§ñ –°–û–ó–î–ê–ù–ò–ï 14 –ê–ì–ï–ù–¢–û–í –° –ò–ï–†–ê–†–•–ò–ï–ô –ú–û–î–ï–õ–ï–ô')\n",
    "print('=' * 60)\n",
    "\n",
    "# üí∞ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–µ–π –∏ —Ü–µ–Ω\n",
    "MODEL_PRICING = {\n",
    "    'gpt-4': {  # –ò—Å–ø–æ–ª—å–∑—É–µ–º GPT-4 –≤–º–µ—Å—Ç–æ GPT-5 (–ø–æ–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)\n",
    "        'input': 0.01,   # $0.01 –∑–∞ 1K input —Ç–æ–∫–µ–Ω–æ–≤\n",
    "        'output': 0.03   # $0.03 –∑–∞ 1K output —Ç–æ–∫–µ–Ω–æ–≤\n",
    "    },\n",
    "    'gpt-4o-mini': {\n",
    "        'input': 0.00015,   # $0.00015 –∑–∞ 1K input —Ç–æ–∫–µ–Ω–æ–≤\n",
    "        'output': 0.0006    # $0.0006 –∑–∞ 1K output —Ç–æ–∫–µ–Ω–æ–≤\n",
    "    }\n",
    "}\n",
    "\n",
    "# üìä –ö–ª–∞—Å—Å –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤\n",
    "class TokenTracker:\n",
    "    def __init__(self):\n",
    "        self.usage_by_level = {\n",
    "            'executive': {'input': 0, 'output': 0, 'cost': 0, 'requests': 0},\n",
    "            'management': {'input': 0, 'output': 0, 'cost': 0, 'requests': 0},\n",
    "            'operational': {'input': 0, 'output': 0, 'cost': 0, 'requests': 0}\n",
    "        }\n",
    "        self.agent_details = {}\n",
    "    \n",
    "    def add_usage(self, level, agent_id, model, input_tokens, output_tokens):\n",
    "        if model not in MODEL_PRICING:\n",
    "            model = 'gpt-4o-mini'  # fallback\n",
    "            \n",
    "        pricing = MODEL_PRICING[model]\n",
    "        cost = (input_tokens * pricing['input'] / 1000) + (output_tokens * pricing['output'] / 1000)\n",
    "        \n",
    "        self.usage_by_level[level]['input'] += input_tokens\n",
    "        self.usage_by_level[level]['output'] += output_tokens\n",
    "        self.usage_by_level[level]['cost'] += cost\n",
    "        self.usage_by_level[level]['requests'] += 1\n",
    "        \n",
    "        # –î–µ—Ç–∞–ª–∏ –ø–æ –∞–≥–µ–Ω—Ç—É\n",
    "        if agent_id not in self.agent_details:\n",
    "            self.agent_details[agent_id] = {'input': 0, 'output': 0, 'cost': 0, 'requests': 0, 'model': model}\n",
    "        \n",
    "        self.agent_details[agent_id]['input'] += input_tokens\n",
    "        self.agent_details[agent_id]['output'] += output_tokens\n",
    "        self.agent_details[agent_id]['cost'] += cost\n",
    "        self.agent_details[agent_id]['requests'] += 1\n",
    "    \n",
    "    def get_total_cost(self):\n",
    "        return sum(level['cost'] for level in self.usage_by_level.values())\n",
    "    \n",
    "    def get_total_tokens(self):\n",
    "        total_input = sum(level['input'] for level in self.usage_by_level.values())\n",
    "        total_output = sum(level['output'] for level in self.usage_by_level.values())\n",
    "        return total_input + total_output\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π tracker\n",
    "token_tracker = TokenTracker()\n",
    "globals()['TOKEN_TRACKER'] = token_tracker\n",
    "\n",
    "try:\n",
    "    chromadb_ready = globals().get('CHROMADB_READY', False)\n",
    "    successful_agents = globals().get('SUCCESSFUL_AGENTS', [])\n",
    "    knowledge_manager = globals().get('KNOWLEDGE_MANAGER', None)\n",
    "    \n",
    "    if not chromadb_ready:\n",
    "        print('‚ùå ChromaDB –Ω–µ –≥–æ—Ç–æ–≤–∞. –í–µ—Ä–Ω–∏—Ç–µ—Å—å –∫ —è—á–µ–π–∫–µ 4.')\n",
    "    else:\n",
    "        # –°–æ–∑–¥–∞–µ–º data_provider\n",
    "        try:\n",
    "            from core.data_providers.static_provider import StaticDataProvider\n",
    "            provider_config = {\n",
    "                \"seo_ai_models_path\": \"./seo_ai_models/\",\n",
    "                \"mock_mode\": True,\n",
    "                \"cache_enabled\": True\n",
    "            }\n",
    "            data_provider = StaticDataProvider(provider_config)\n",
    "            print('‚úÖ StaticDataProvider —Å–æ–∑–¥–∞–Ω')\n",
    "        except:\n",
    "            class MockDataProvider:\n",
    "                async def get_client_data(self, client_id): return {\"client_id\": client_id, \"mock\": True}\n",
    "                async def get_seo_data(self, domain): return {\"domain\": domain, \"mock\": True}\n",
    "            data_provider = MockDataProvider()\n",
    "            print('‚úÖ Mock data_provider —Å–æ–∑–¥–∞–Ω')\n",
    "        \n",
    "        # üéØ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–æ–≤ —Å –∏–µ—Ä–∞—Ä—Ö–∏–µ–π –º–æ–¥–µ–ª–µ–π\n",
    "        agents_config = {\n",
    "            'executive': [\n",
    "                ('chief_seo_strategist', 'agents.executive.chief_seo_strategist', 'ChiefSEOStrategistAgent', 'gpt-4'),\n",
    "                ('business_development_director', 'agents.executive.business_development_director', 'BusinessDevelopmentDirectorAgent', 'gpt-4')\n",
    "            ],\n",
    "            'management': [\n",
    "                ('task_coordination', 'agents.management.task_coordination', 'TaskCoordinationAgent', 'gpt-4o-mini'),\n",
    "                ('sales_operations_manager', 'agents.management.sales_operations_manager', 'SalesOperationsManagerAgent', 'gpt-4o-mini'),\n",
    "                ('technical_seo_operations_manager', 'agents.management.technical_seo_operations_manager', 'TechnicalSEOOperationsManagerAgent', 'gpt-4o-mini'),\n",
    "                ('client_success_manager', 'agents.management.client_success_manager', 'ClientSuccessManagerAgent', 'gpt-4o-mini')\n",
    "            ],\n",
    "            'operational': [\n",
    "                ('lead_qualification', 'agents.operational.lead_qualification', 'LeadQualificationAgent', 'gpt-4o-mini'),\n",
    "                ('sales_conversation', 'agents.operational.sales_conversation', 'SalesConversationAgent', 'gpt-4o-mini'),\n",
    "                ('proposal_generation', 'agents.operational.proposal_generation', 'ProposalGenerationAgent', 'gpt-4o-mini'),\n",
    "                ('technical_seo_auditor', 'agents.operational.technical_seo_auditor', 'TechnicalSEOAuditorAgent', 'gpt-4o-mini'),\n",
    "                ('content_strategy', 'agents.operational.content_strategy', 'ContentStrategyAgent', 'gpt-4o-mini'),\n",
    "                ('link_building', 'agents.operational.link_building', 'LinkBuildingAgent', 'gpt-4o-mini'),\n",
    "                ('competitive_analysis', 'agents.operational.competitive_analysis', 'CompetitiveAnalysisAgent', 'gpt-4o-mini'),\n",
    "                ('reporting', 'agents.operational.reporting', 'ReportingAgent', 'gpt-4o-mini')\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–æ–≤\n",
    "        agents = {'executive': {}, 'management': {}, 'operational': {}}\n",
    "        creation_stats = {'executive': {'created': 0, 'failed': 0}, 'management': {'created': 0, 'failed': 0}, 'operational': {'created': 0, 'failed': 0}}\n",
    "        \n",
    "        for level, level_agents in agents_config.items():\n",
    "            model_icon = '‚≠ê GPT-4' if level == 'executive' else 'üí∞ GPT-4o-mini'\n",
    "            print(f'\\n{\"üëë\" if level == \"executive\" else \"‚öôÔ∏è\" if level == \"management\" else \"üîß\"} {level.upper()} –£–†–û–í–ï–ù–¨ ({model_icon}):')\n",
    "            print('‚ïê' * 55)\n",
    "            \n",
    "            for agent_id, module_path, class_name, model_name in level_agents:\n",
    "                try:\n",
    "                    rag_available = agent_id in successful_agents\n",
    "                    \n",
    "                    module = __import__(module_path, fromlist=[class_name])\n",
    "                    AgentClass = getattr(module, class_name)\n",
    "                    \n",
    "                    agent_kwargs = {\n",
    "                        'data_provider': data_provider,\n",
    "                        'rag_enabled': rag_available,\n",
    "                        'mcp_enabled': False,\n",
    "                        'retry_attempts': 3,\n",
    "                        'task_timeout': 60.0\n",
    "                    }\n",
    "                    \n",
    "                    if agent_id not in ['proposal_generation']:\n",
    "                        agent_kwargs['model_name'] = model_name\n",
    "                    \n",
    "                    agent = AgentClass(**agent_kwargs)\n",
    "                    agents[level][agent_id] = agent\n",
    "                    creation_stats[level]['created'] += 1\n",
    "                    \n",
    "                    rag_status = 'üîó RAG' if rag_available else '‚ö™ NoRAG'\n",
    "                    model_display = '‚≠ê GPT-4' if model_name == 'gpt-4' else 'üí∞ GPT-4o-mini'\n",
    "                    print(f'‚úÖ {agent_id:25} | {level:10} | {rag_status} | {model_display}')\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    creation_stats[level]['failed'] += 1\n",
    "                    print(f'‚ùå {agent_id:25} | –û—à–∏–±–∫–∞: {str(e)[:50]}...')\n",
    "        \n",
    "        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "        total_created = sum(stats['created'] for stats in creation_stats.values())\n",
    "        \n",
    "        print(f'\\nüìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–û–ó–î–ê–ù–ò–Ø:')\n",
    "        print('=' * 45)\n",
    "        \n",
    "        for level, stats in creation_stats.items():\n",
    "            model_type = 'GPT-4' if level == 'executive' else 'GPT-4o-mini'\n",
    "            print(f'{level:15}: {stats[\"created\"]:2d} –∞–≥–µ–Ω—Ç–æ–≤ | {model_type}')\n",
    "        \n",
    "        print(f'\\nüéØ –û–ë–©–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢:')\n",
    "        print(f'‚úÖ –í—Å–µ–≥–æ –∞–≥–µ–Ω—Ç–æ–≤: {total_created}/14 ({total_created/14*100:.1f}%)')\n",
    "        print(f'‚≠ê Premium –∞–≥–µ–Ω—Ç—ã (GPT-4): 2')\n",
    "        print(f'üí∞ –≠–∫–æ–Ω–æ–º–∏—á–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã (GPT-4o-mini): {total_created-2}')\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–≥–µ–Ω—Ç–æ–≤\n",
    "        globals()['AGENTS_CREATED'] = total_created >= 10\n",
    "        globals()['AI_AGENTS'] = agents\n",
    "        globals()['CREATION_STATS'] = creation_stats\n",
    "        globals()['DATA_PROVIDER'] = data_provider\n",
    "        \n",
    "        if total_created >= 12:\n",
    "            print('\\nüöÄ –°–ò–°–¢–ï–ú–ê –ì–û–¢–û–í–ê –ö –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Æ!')\n",
    "            print('üíé Executive –∞–≥–µ–Ω—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç premium GPT-4')\n",
    "            print('üí∞ Management/Operational –∏—Å–ø–æ–ª—å–∑—É—é—Ç —ç–∫–æ–Ω–æ–º–∏—á–Ω—ã–π GPT-4o-mini')\n",
    "\nexcept Exception as e:\n",
    "    print(f'‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤: {e}')\n",
    "    globals()['AGENTS_CREATED'] = False\n",
    "    globals()['AI_AGENTS'] = {'executive': {}, 'management': {}, 'operational': {}}\n",
    "\n",
    "print('\\nüéØ –ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ —è—á–µ–π–∫–∞–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}