#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ FAISS —Å OpenAI Embeddings –¥–ª—è AI SEO Architects
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –∑–Ω–∞–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤
"""

import os
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from knowledge.knowledge_manager import knowledge_manager, FAISSVectorStore
from langchain.schema import Document
from core.config import config
from datetime import datetime


def test_openai_embeddings():
    """–¢–µ—Å—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ OpenAI Embeddings"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ OpenAI Embeddings...")
    
    if knowledge_manager.embeddings is not None:
        print("‚úÖ OpenAI Embeddings —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        print(f"   –ú–æ–¥–µ–ª—å: text-embedding-ada-002")
        print(f"   API Key: {'sk-proj-' + '***' + config.OPENAI_API_KEY[-10:] if config.OPENAI_API_KEY else '–ù–µ –Ω–∞–π–¥–µ–Ω'}")
        return True
    else:
        print("‚ùå OpenAI Embeddings –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        return False


def test_faiss_vector_store():
    """–¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è –∏ —Ä–∞–±–æ—Ç—ã FAISSVectorStore"""
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ FAISSVectorStore...")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    test_documents = [
        Document(
            page_content="SEO –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤–∫–ª—é—á–∞–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ SEO, –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –∏ –ª–∏–Ω–∫–±–∏–ª–¥–∏–Ω–≥",
            metadata={"source": "test1.md", "agent": "test", "chunk_id": 0}
        ),
        Document(
            page_content="Lead qualification –∏—Å–ø–æ–ª—å–∑—É–µ—Ç BANT –∏ MEDDIC –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤",
            metadata={"source": "test2.md", "agent": "test", "chunk_id": 1}
        ),
        Document(
            page_content="Technical SEO –∞—É–¥–∏—Ç –ø—Ä–æ–≤–µ—Ä—è–µ—Ç Core Web Vitals, crawling –∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é —Å—Ç—Ä–∞–Ω–∏—Ü",
            metadata={"source": "test3.md", "agent": "test", "chunk_id": 2}
        )
    ]
    
    try:
        # –°–æ–∑–¥–∞–µ–º FAISSVectorStore —Å embeddings
        if knowledge_manager.embeddings:
            vector_store = FAISSVectorStore(test_documents, knowledge_manager.embeddings)
        else:
            vector_store = FAISSVectorStore(test_documents, None)
        
        print("‚úÖ FAISSVectorStore —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ")
        print(f"   –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(vector_store.documents)}")
        print(f"   FAISS –∏–Ω–¥–µ–∫—Å: {'–°–æ–∑–¥–∞–Ω' if vector_store.index is not None else 'Fallback'}")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
        search_results = vector_store.similarity_search("SEO –∞—É–¥–∏—Ç", k=2)
        print(f"   –ü–æ–∏—Å–∫ 'SEO –∞—É–¥–∏—Ç': –Ω–∞–π–¥–µ–Ω–æ {len(search_results)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        
        if search_results:
            print(f"   –ü–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {search_results[0].page_content[:50]}...")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è FAISSVectorStore: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_agent_knowledge_loading():
    """–¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –∑–Ω–∞–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤ —Å FAISS"""
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∑–Ω–∞–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤...")
    
    test_agents = [
        ("lead_qualification", "operational"),
        ("technical_seo_auditor", "operational"), 
        ("chief_seo_strategist", "executive")
    ]
    
    results = {}
    
    for agent_name, agent_level in test_agents:
        try:
            print(f"\nü§ñ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–Ω–∞–Ω–∏–π –¥–ª—è {agent_name}...")
            
            vector_store = knowledge_manager.load_agent_knowledge(agent_name, agent_level)
            
            if vector_store:
                results[agent_name] = {
                    'status': 'success',
                    'documents_count': len(vector_store.documents),
                    'faiss_index': vector_store.index is not None,
                    'embeddings_available': knowledge_manager.embeddings is not None
                }
                
                # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ –ø–æ –∑–Ω–∞–Ω–∏—è–º
                if vector_store.documents:
                    search_results = vector_store.similarity_search(f"{agent_name} tasks", k=1)
                    results[agent_name]['search_works'] = len(search_results) > 0
                    
                    if search_results:
                        print(f"   üìÑ –ü—Ä–∏–º–µ—Ä –∑–Ω–∞–Ω–∏–π: {search_results[0].page_content[:100]}...")
                
                print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {len(vector_store.documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
                print(f"   üîç FAISS –∏–Ω–¥–µ–∫—Å: {'–ê–∫—Ç–∏–≤–µ–Ω' if vector_store.index else 'Fallback'}")
                
            else:
                results[agent_name] = {'status': 'failed', 'reason': 'No knowledge found'}
                print(f"   ‚ùå –ó–Ω–∞–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                
        except Exception as e:
            results[agent_name] = {'status': 'error', 'error': str(e)}
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
    
    return results


def test_vector_search_quality():
    """–¢–µ—Å—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞...")
    
    if not knowledge_manager.embeddings:
        print("‚ö†Ô∏è OpenAI Embeddings –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç –∫–∞—á–µ—Å—Ç–≤–∞")
        return False
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∑–Ω–∞–Ω–∏—è –¥–ª—è technical_seo_auditor
    vector_store = knowledge_manager.load_agent_knowledge("technical_seo_auditor", "operational")
    
    if not vector_store or not vector_store.documents:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∑–Ω–∞–Ω–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        return False
    
    test_queries = [
        "Core Web Vitals",
        "crawling problems",
        "technical SEO audit",
        "page speed optimization",
        "structured data"
    ]
    
    print("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:")
    
    for query in test_queries:
        try:
            # FAISS –ø–æ–∏—Å–∫
            faiss_results = vector_store._faiss_search(query, k=3)
            
            # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            simple_results = vector_store._simple_search(query, k=3)
            
            print(f"\n   Query: '{query}'")
            print(f"   FAISS —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(faiss_results)}")
            print(f"   Simple —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(simple_results)}")
            
            if faiss_results:
                print(f"   FAISS —Ç–æ–ø-—Ä–µ–∑—É–ª—å—Ç–∞—Ç: {faiss_results[0].page_content[:80]}...")
                
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –¥–ª—è '{query}': {e}")
    
    return True


def test_index_persistence():
    """–¢–µ—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∏ FAISS –∏–Ω–¥–µ–∫—Å–æ–≤"""
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –∏–Ω–¥–µ–∫—Å–æ–≤...")
    
    if not knowledge_manager.embeddings:
        print("‚ö†Ô∏è OpenAI Embeddings –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏")
        return False
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∑–Ω–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–∞
        agent_name = "lead_qualification"
        vector_store = knowledge_manager.load_agent_knowledge(agent_name, "operational")
        
        if not vector_store:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∑–Ω–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–∞")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
        index_path = f"{config.VECTOR_STORE_PATH}/{agent_name}"
        faiss_index_file = f"{index_path}/faiss.index"
        metadata_file = f"{index_path}/metadata.pkl"
        
        index_exists = os.path.exists(faiss_index_file)
        metadata_exists = os.path.exists(metadata_file)
        
        print(f"   üì¶ –ò–Ω–¥–µ–∫—Å —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {index_exists}")
        print(f"   üìã –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç: {metadata_exists}")
        
        if index_exists and metadata_exists:
            print("   ‚úÖ –ò–Ω–¥–µ–∫—Å —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –Ω–∞ –¥–∏—Å–∫")
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∑–∫—É
            new_vector_store = FAISSVectorStore([], knowledge_manager.embeddings)
            load_success = new_vector_store.load_index(index_path)
            
            if load_success:
                print("   ‚úÖ –ò–Ω–¥–µ–∫—Å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω —Å –¥–∏—Å–∫–∞")
                print(f"   üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(new_vector_store.documents)}")
                return True
            else:
                print("   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–Ω–¥–µ–∫—Å–∞")
                return False
        else:
            print("   ‚ö†Ô∏è –ò–Ω–¥–µ–∫—Å –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω (–≤–æ–∑–º–æ–∂–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback)")
            return False
            
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏: {e}")
        return False


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è FAISS –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"""
    print("üöÄ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï FAISS + OPENAI EMBEDDINGS –ò–ù–¢–ï–ì–†–ê–¶–ò–ò")
    print("=" * 70)
    print(f"üïí –í—Ä–µ–º—è –∑–∞–ø—É—Å–∫–∞: {datetime.now().isoformat()}")
    print(f"üîß OPENAI_API_KEY: {'–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω' if config.OPENAI_API_KEY else '–ù–µ –Ω–∞–π–¥–µ–Ω'}")
    print(f"üìÅ –ü—É—Ç—å –∫ –∑–Ω–∞–Ω–∏—è–º: {config.KNOWLEDGE_BASE_PATH}")
    print(f"üíæ –ü—É—Ç—å –∫ –≤–µ–∫—Ç–æ—Ä–∞–º: {config.VECTOR_STORE_PATH}")
    
    test_results = {}
    
    # –¢–µ—Å—Ç 1: OpenAI Embeddings
    test_results['embeddings'] = test_openai_embeddings()
    
    # –¢–µ—Å—Ç 2: FAISS Vector Store
    test_results['faiss_store'] = test_faiss_vector_store()
    
    # –¢–µ—Å—Ç 3: –ó–∞–≥—Ä—É–∑–∫–∞ –∑–Ω–∞–Ω–∏–π –∞–≥–µ–Ω—Ç–æ–≤
    test_results['agent_loading'] = test_agent_knowledge_loading()
    
    # –¢–µ—Å—Ç 4: –ö–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞
    test_results['search_quality'] = test_vector_search_quality()
    
    # –¢–µ—Å—Ç 5: –ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –∏–Ω–¥–µ–∫—Å–æ–≤
    test_results['persistence'] = test_index_persistence()
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print("\n" + "=" * 70)
    print("üìä –ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
    print("=" * 70)
    
    passed_tests = 0
    total_tests = len(test_results)
    
    for test_name, result in test_results.items():
        if isinstance(result, bool):
            status = "‚úÖ PASSED" if result else "‚ùå FAILED"
            if result:
                passed_tests += 1
        elif isinstance(result, dict):
            # –î–ª—è —Ç–µ—Å—Ç–∞ agent_loading
            successful_agents = sum(1 for r in result.values() if r.get('status') == 'success')
            total_agents = len(result)
            status = f"‚úÖ PASSED ({successful_agents}/{total_agents} –∞–≥–µ–Ω—Ç–æ–≤)"
            if successful_agents > 0:
                passed_tests += 1
        else:
            status = "‚ùì UNKNOWN"
        
        print(f"   {test_name.replace('_', ' ').title()}: {status}")
    
    print(f"\nüèÜ –û–ë–©–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢: {passed_tests}/{total_tests} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ")
    
    if passed_tests == total_tests:
        print("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´! FAISS –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    elif passed_tests > 0:
        print("‚ö†Ô∏è  –ß–∞—Å—Ç–∏—á–Ω–∞—è –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –º–æ–≥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –≤ fallback —Ä–µ–∂–∏–º–µ")
    else:
        print("‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–û–ë–õ–ï–ú–´. –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    if not test_results.get('embeddings'):
        print("   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å OPENAI_API_KEY")
        print("   ‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –Ω–∞–ª–∏—á–∏–∏ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è")
    
    if not test_results.get('persistence'):
        print("   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ vector stores")
    
    print(f"\nüïí –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {datetime.now().isoformat()}")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nüëã –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()