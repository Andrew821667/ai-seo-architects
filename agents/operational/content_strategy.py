"""
Content Strategy Agent - –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è SEO
Operational Level Agent
"""

import asyncio
from datetime import datetime
from typing import Dict, Any, List, Optional
import logging

from core.base_agent import BaseAgent

logger = logging.getLogger(__name__)


class ContentStrategyAgent(BaseAgent):
    """
    Content Strategy Agent - Operational —É—Ä–æ–≤–µ–Ω—å
    
    –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: Keyword research, –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è, E-E-A-T –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è,
    TF-IDF –∞–Ω–∞–ª–∏–∑, —Ç–æ–ø–∏–∫–æ–≤–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è, content calendar –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
    """
    
    def __init__(self, data_provider, **kwargs):
        super().__init__(
            agent_id="content_strategy_agent",
            name="Content Strategy Agent",
            data_provider=data_provider,
            **kwargs
        )
        
        # Content strategy configuration
        self.content_config = {
            "keyword_research_depth": "comprehensive",  # basic, standard, comprehensive
            "content_quality_threshold": 85,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π E-E-A-T score
            "topic_cluster_size": 15,  # –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ
            "content_calendar_horizon": 90,  # –î–Ω–µ–π –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≤–ø–µ—Ä–µ–¥
            "competitor_analysis_depth": 5,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            "industry_expertise_level": "expert"  # basic, intermediate, expert
        }
        
        # Supported industries
        self.industry_specialization = [
            "fintech", "ecommerce", "saas", "healthcare", 
            "real_estate", "education", "manufacturing", "consulting"
        ]
        
        # Content types expertise
        self.content_types = [
            "blog_posts", "pillar_pages", "landing_pages", "product_pages",
            "category_pages", "guides", "whitepapers", "case_studies",
            "infographics", "videos", "podcasts", "webinars"
        ]
        
        logger.info(f"üéØ Content Strategy Agent –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω:")
        logger.info(f"üìä Keyword Research: {self.content_config['keyword_research_depth']}")
        logger.info(f"üéØ Quality Threshold: {self.content_config['content_quality_threshold']}+ E-E-A-T")
        logger.info(f"üìÖ Planning Horizon: {self.content_config['content_calendar_horizon']} –¥–Ω–µ–π")
        logger.info(f"üè≠ Industries: {len(self.industry_specialization)} –≤–µ—Ä—Ç–∏–∫–∞–ª–µ–π")
    
    async def process_task(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á Content Strategy Agent
        
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ç–∏–ø—ã –∑–∞–¥–∞—á:
        - keyword_research: –ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        - content_audit: –ê—É–¥–∏—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        - content_strategy: –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        - topic_clustering: –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–º
        - content_calendar: –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç-–∫–∞–ª–µ–Ω–¥–∞—Ä—è
        - competitor_content_analysis: –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
        - eeat_optimization: E-E-A-T –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        """
        
        start_time = datetime.now()
        
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
            input_data = task_data.get("input_data", {})
            task_type = input_data.get("task_type", "content_strategy")
            
            logger.info(f"üéØ –û–±—Ä–∞–±–æ—Ç–∫–∞ Content Strategy –∑–∞–¥–∞—á–∏: {task_type}")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ–±—Ä–∞–±–æ—Ç–∫–∏
            if task_type == "keyword_research":
                result = await self._process_keyword_research(input_data)
            elif task_type == "content_audit":
                result = await self._process_content_audit(input_data)
            elif task_type == "content_strategy":
                result = await self._process_content_strategy(input_data)
            elif task_type == "topic_clustering":
                result = await self._process_topic_clustering(input_data)
            elif task_type == "content_calendar":
                result = await self._process_content_calendar(input_data)
            elif task_type == "competitor_content_analysis":
                result = await self._process_competitor_analysis(input_data)
            elif task_type == "eeat_optimization":
                result = await self._process_eeat_optimization(input_data)
            else:
                # Default: –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
                result = await self._process_comprehensive_strategy(input_data)
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            self.metrics.record_task(True, processing_time)
            
            logger.info(f"‚úÖ Content Strategy –∑–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {processing_time:.2f}—Å")
            
            return {
                "success": True,
                "agent": self.agent_id,
                "task_type": task_type,
                "result": result,
                "processing_time": processing_time,
                "timestamp": datetime.now().isoformat(),
                "content_quality": self._assess_content_quality(result),
                "strategy_confidence": self._calculate_strategy_confidence(result)
            }
            
        except Exception as e:
            processing_time = (datetime.now() - start_time).total_seconds()
            self.metrics.record_task(False, processing_time)
            
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ Content Strategy Agent: {str(e)}")
            
            return {
                "success": False,
                "agent": self.agent_id,
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
                "processing_time": processing_time
            }
    
    async def _process_keyword_research(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤"""
        
        domain = input_data.get("domain", "example.com")
        industry = input_data.get("industry", "general")
        seed_keywords = input_data.get("seed_keywords", [])
        research_depth = input_data.get("depth", self.content_config["keyword_research_depth"])
        
        logger.info(f"üîç Keyword research –¥–ª—è {domain} –≤ {industry}")
        
        # –°–∏–º—É–ª—è—Ü–∏—è comprehensive keyword research
        if research_depth == "comprehensive":
            primary_keywords = self._generate_primary_keywords(industry, seed_keywords, 50)
            long_tail_keywords = self._generate_long_tail_keywords(primary_keywords, 200)
            question_keywords = self._generate_question_keywords(primary_keywords, 100)
            commercial_keywords = self._generate_commercial_keywords(industry, 75)
        else:
            primary_keywords = self._generate_primary_keywords(industry, seed_keywords, 25)
            long_tail_keywords = self._generate_long_tail_keywords(primary_keywords, 100)
            question_keywords = self._generate_question_keywords(primary_keywords, 50)
            commercial_keywords = self._generate_commercial_keywords(industry, 35)
        
        return {
            "keyword_research_results": {
                "primary_keywords": primary_keywords,
                "long_tail_keywords": long_tail_keywords,
                "question_keywords": question_keywords,
                "commercial_keywords": commercial_keywords,
                "total_keywords": len(primary_keywords) + len(long_tail_keywords) + len(question_keywords) + len(commercial_keywords),
                "research_depth": research_depth,
                "industry_focus": industry
            },
            "keyword_difficulty_analysis": self._analyze_keyword_difficulty(primary_keywords),
            "search_intent_mapping": self._map_search_intent(primary_keywords + long_tail_keywords),
            "content_opportunities": self._identify_content_opportunities(primary_keywords, industry)
        }
    
    async def _process_content_strategy(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""
        
        domain = input_data.get("domain", "example.com")
        industry = input_data.get("industry", "general")
        business_goals = input_data.get("business_goals", ["traffic_growth", "lead_generation"])
        target_audience = input_data.get("target_audience", {})
        content_budget = input_data.get("monthly_budget", 100000)  # —Ä—É–±–ª–µ–π
        
        logger.info(f"üìã Content strategy –¥–ª—è {domain}, –±—é–¥–∂–µ—Ç: {content_budget:,} ‚ÇΩ")
        
        # Content pillars –¥–ª—è –∏–Ω–¥—É—Å—Ç—Ä–∏–∏
        content_pillars = self._define_content_pillars(industry, business_goals)
        
        # Content types recommendation
        recommended_content_types = self._recommend_content_types(industry, content_budget, business_goals)
        
        # Publishing frequency
        publishing_schedule = self._calculate_publishing_schedule(content_budget, industry)
        
        # ROI projection
        roi_projection = self._calculate_content_roi_projection(content_budget, industry, publishing_schedule)
        
        return {
            "content_strategy": {
                "industry": industry,
                "monthly_budget": content_budget,
                "content_pillars": content_pillars,
                "recommended_content_types": recommended_content_types,
                "publishing_schedule": publishing_schedule,
                "roi_projection": roi_projection
            },
            "implementation_roadmap": self._create_implementation_roadmap(content_pillars, publishing_schedule),
            "success_metrics": self._define_success_metrics(business_goals),
            "resource_requirements": self._calculate_resource_requirements(publishing_schedule, content_budget)
        }
    
    async def _process_topic_clustering(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–º –¥–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""
        
        keywords = input_data.get("keywords", [])
        industry = input_data.get("industry", "general")
        cluster_strategy = input_data.get("cluster_strategy", "topic_based")  # topic_based, intent_based, funnel_based
        
        logger.info(f"üóÇÔ∏è Topic clustering: {len(keywords)} keywords, —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {cluster_strategy}")
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª–∞—Å—Ç–µ—Ä—ã —Ç–µ–º
        if cluster_strategy == "topic_based":
            clusters = self._create_topic_based_clusters(keywords, industry)
        elif cluster_strategy == "intent_based":
            clusters = self._create_intent_based_clusters(keywords)
        else:  # funnel_based
            clusters = self._create_funnel_based_clusters(keywords, industry)
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        prioritized_clusters = self._prioritize_clusters(clusters, industry)
        
        return {
            "topic_clusters": {
                "total_clusters": len(clusters),
                "clustering_strategy": cluster_strategy,
                "clusters": prioritized_clusters
            },
            "content_hub_recommendations": self._recommend_content_hubs(prioritized_clusters),
            "internal_linking_strategy": self._design_internal_linking_strategy(prioritized_clusters),
            "pillar_page_opportunities": self._identify_pillar_page_opportunities(prioritized_clusters)
        }
    
    async def _process_content_calendar(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç-–∫–∞–ª–µ–Ω–¥–∞—Ä—è"""
        
        content_strategy = input_data.get("content_strategy", {})
        topic_clusters = input_data.get("topic_clusters", [])
        publishing_frequency = input_data.get("publishing_frequency", "weekly")
        calendar_horizon = input_data.get("calendar_horizon", self.content_config["content_calendar_horizon"])
        
        logger.info(f"üìÖ Content calendar –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ {calendar_horizon} –¥–Ω–µ–π")
        
        # –°–æ–∑–¥–∞–µ–º –∫–∞–ª–µ–Ω–¥–∞—Ä—å –ø—É–±–ª–∏–∫–∞—Ü–∏–π
        content_calendar = self._generate_content_calendar(
            topic_clusters, publishing_frequency, calendar_horizon
        )
        
        # Seasonal content opportunities
        seasonal_content = self._identify_seasonal_opportunities(calendar_horizon)
        
        # Content distribution plan
        distribution_plan = self._create_distribution_plan(content_calendar)
        
        return {
            "content_calendar": {
                "planning_horizon_days": calendar_horizon,
                "publishing_frequency": publishing_frequency,
                "total_planned_content": len(content_calendar),
                "calendar": content_calendar
            },
            "seasonal_opportunities": seasonal_content,
            "distribution_plan": distribution_plan,
            "resource_allocation": self._calculate_calendar_resource_allocation(content_calendar)
        }
    
    async def _process_eeat_optimization(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """E-E-A-T –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        
        content_audit = input_data.get("content_audit", {})
        industry = input_data.get("industry", "general")
        expertise_level = input_data.get("target_expertise_level", "expert")
        
        logger.info(f"üéì E-E-A-T –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è {industry}, —É—Ä–æ–≤–µ–Ω—å: {expertise_level}")
        
        # E-E-A-T assessment
        current_eeat_score = self._assess_current_eeat_score(content_audit, industry)
        
        # Improvement recommendations
        eeat_improvements = self._recommend_eeat_improvements(current_eeat_score, expertise_level, industry)
        
        # Author strategy
        author_strategy = self._develop_author_strategy(industry, expertise_level)
        
        # Content credibility enhancements
        credibility_enhancements = self._recommend_credibility_enhancements(industry)
        
        return {
            "eeat_optimization": {
                "current_eeat_score": current_eeat_score,
                "target_expertise_level": expertise_level,
                "improvement_priority": eeat_improvements["priority_areas"],
                "implementation_plan": eeat_improvements["implementation_plan"]
            },
            "author_strategy": author_strategy,
            "credibility_enhancements": credibility_enhancements,
            "success_metrics": self._define_eeat_success_metrics(expertise_level)
        }
    
    async def _process_comprehensive_strategy(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è (default processing)"""
        
        domain = input_data.get("domain", "example.com")
        industry = input_data.get("industry", "general")
        
        logger.info(f"üìä Comprehensive content strategy –¥–ª—è {domain}")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        keyword_research = await self._process_keyword_research(input_data)
        content_strategy = await self._process_content_strategy(input_data)
        topic_clustering = await self._process_topic_clustering({
            "keywords": keyword_research["keyword_research_results"]["primary_keywords"],
            "industry": industry
        })
        content_calendar = await self._process_content_calendar({
            "topic_clusters": topic_clustering["topic_clusters"]["clusters"][:10],
            "publishing_frequency": "bi-weekly"
        })
        
        return {
            "comprehensive_strategy": {
                "domain": domain,
                "industry": industry,
                "strategy_scope": "comprehensive"
            },
            "keyword_research": keyword_research,
            "content_strategy": content_strategy,
            "topic_clustering": topic_clustering,
            "content_calendar": content_calendar,
            "implementation_priority": self._prioritize_implementation_steps(
                keyword_research, content_strategy, topic_clustering
            )
        }
    
    def _generate_primary_keywords(self, industry: str, seed_keywords: List[str], count: int) -> List[Dict[str, Any]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è primary keywords"""
        
        # Industry-specific keyword patterns
        industry_patterns = {
            "fintech": ["—Ñ–∏–Ω—Ç–µ—Ö", "—Ü–∏—Ñ—Ä–æ–≤–æ–π –±–∞–Ω–∫", "–º–æ–±–∏–ª—å–Ω—ã–π –±–∞–Ω–∫–∏–Ω–≥", "–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏", "–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞"],
            "ecommerce": ["–∏–Ω—Ç–µ—Ä–Ω–µ—Ç –º–∞–≥–∞–∑–∏–Ω", "–æ–Ω–ª–∞–π–Ω –ø–æ–∫—É–ø–∫–∏", "–¥–æ—Å—Ç–∞–≤–∫–∞", "—Ç–æ–≤–∞—Ä—ã", "—Å–∫–∏–¥–∫–∏"],
            "saas": ["–ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ", "–æ–±–ª–∞—á–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è", "–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è", "crm —Å–∏—Å—Ç–µ–º–∞"],
            "healthcare": ["–º–µ–¥–∏—Ü–∏–Ω–∞", "–∑–¥–æ—Ä–æ–≤—å–µ", "–ª–µ—á–µ–Ω–∏–µ", "–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞", "–∫–ª–∏–Ω–∏–∫–∞"],
            "real_estate": ["–Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å", "–∫–≤–∞—Ä—Ç–∏—Ä—ã", "–¥–æ–º–∞", "–∏–ø–æ—Ç–µ–∫–∞", "–∞—Ä–µ–Ω–¥–∞"],
            "education": ["–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ", "–æ–±—É—á–µ–Ω–∏–µ", "–∫—É—Ä—Å—ã", "—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç", "—à–∫–æ–ª–∞"],
            "general": ["—É—Å–ª—É–≥–∏", "–∫–æ–º–ø–∞–Ω–∏—è", "—Ä–µ—à–µ–Ω–∏—è", "–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏", "—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—ã"]
        }
        
        base_patterns = industry_patterns.get(industry, industry_patterns["general"])
        
        keywords = []
        for i, pattern in enumerate(base_patterns[:count]):
            keywords.append({
                "keyword": pattern,
                "search_volume": 10000 - (i * 500),
                "difficulty": 45 + (i * 3),
                "cpc": 150 + (i * 25),
                "intent": "informational" if i % 3 == 0 else "commercial",
                "priority": "high" if i < 10 else "medium"
            })
        
        return keywords
    
    def _generate_long_tail_keywords(self, primary_keywords: List[Dict[str, Any]], count: int) -> List[Dict[str, Any]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è long-tail keywords"""
        
        long_tail = []
        modifiers = ["–∫–∞–∫", "—á—Ç–æ —Ç–∞–∫–æ–µ", "–ª—É—á—à–∏–π", "—Ç–æ–ø", "—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ", "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è", "–æ—Ç–∑—ã–≤—ã", "—Ü–µ–Ω–∞"]
        
        for i, primary in enumerate(primary_keywords[:count//8]):
            for j, modifier in enumerate(modifiers):
                if len(long_tail) >= count:
                    break
                long_tail.append({
                    "keyword": f"{modifier} {primary['keyword']}",
                    "search_volume": max(100, primary["search_volume"] // 10),
                    "difficulty": max(15, primary["difficulty"] - 20),
                    "cpc": max(50, primary["cpc"] // 2),
                    "intent": "informational" if modifier in ["–∫–∞–∫", "—á—Ç–æ —Ç–∞–∫–æ–µ"] else "commercial",
                    "priority": "medium",
                    "parent_keyword": primary["keyword"]
                })
        
        return long_tail[:count]
    
    def _generate_question_keywords(self, primary_keywords: List[Dict[str, Any]], count: int) -> List[Dict[str, Any]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è question-based keywords"""
        
        question_keywords = []
        question_patterns = ["–∫–∞–∫ –≤—ã–±—Ä–∞—Ç—å", "—á—Ç–æ –ª—É—á—à–µ", "–ø–æ—á–µ–º—É", "–≥–¥–µ –Ω–∞–π—Ç–∏", "–∫–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å"]
        
        for i, primary in enumerate(primary_keywords[:count//5]):
            for pattern in question_patterns:
                if len(question_keywords) >= count:
                    break
                question_keywords.append({
                    "keyword": f"{pattern} {primary['keyword']}",
                    "search_volume": max(50, primary["search_volume"] // 20),
                    "difficulty": max(10, primary["difficulty"] - 25),
                    "cpc": max(30, primary["cpc"] // 3),
                    "intent": "informational",
                    "priority": "high",  # Question-based content —á–∞—Å—Ç–æ —Ö–æ—Ä–æ—à–æ —Ä–∞–Ω–∂–∏—Ä—É–µ—Ç—Å—è
                    "content_type": "faq_or_guide",
                    "parent_keyword": primary["keyword"]
                })
        
        return question_keywords[:count]
    
    def _generate_commercial_keywords(self, industry: str, count: int) -> List[Dict[str, Any]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è commercial intent keywords"""
        
        commercial_patterns = {
            "fintech": ["–∫—É–ø–∏—Ç—å", "—Ü–µ–Ω–∞", "—Å—Ç–æ–∏–º–æ—Å—Ç—å", "—Ç–∞—Ä–∏—Ñ", "–ø–æ–¥–∫–ª—é—á–∏—Ç—å"],
            "ecommerce": ["–∑–∞–∫–∞–∑–∞—Ç—å", "–∫—É–ø–∏—Ç—å", "–¥–æ—Å—Ç–∞–≤–∫–∞", "–æ–ø–ª–∞—Ç–∞", "–∫–∞—Ç–∞–ª–æ–≥"],
            "saas": ["–ø–æ–¥–ø–∏—Å–∫–∞", "–¥–µ–º–æ", "–ø—Ä–æ–±–Ω–∞—è –≤–µ—Ä—Å–∏—è", "—Ü–µ–Ω–∞", "—Ç–∞—Ä–∏—Ñ"],
            "general": ["–∑–∞–∫–∞–∑–∞—Ç—å", "–∫—É–ø–∏—Ç—å", "—Ü–µ–Ω–∞", "—É—Å–ª—É–≥–∏", "–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è"]
        }
        
        patterns = commercial_patterns.get(industry, commercial_patterns["general"])
        
        commercial_keywords = []
        for i, pattern in enumerate(patterns):
            for j in range(count // len(patterns)):
                commercial_keywords.append({
                    "keyword": f"{pattern} {industry}",
                    "search_volume": 2000 - (i * 100),
                    "difficulty": 55 + (i * 5),
                    "cpc": 300 + (i * 50),
                    "intent": "commercial",
                    "priority": "high",
                    "conversion_potential": "high"
                })
        
        return commercial_keywords[:count]
    
    def _analyze_keyword_difficulty(self, keywords: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤"""
        
        difficulty_distribution = {"easy": 0, "medium": 0, "hard": 0}
        total_keywords = len(keywords)
        
        for keyword in keywords:
            difficulty = keyword.get("difficulty", 50)
            if difficulty < 30:
                difficulty_distribution["easy"] += 1
            elif difficulty < 60:
                difficulty_distribution["medium"] += 1
            else:
                difficulty_distribution["hard"] += 1
        
        return {
            "difficulty_distribution": difficulty_distribution,
            "average_difficulty": sum(kw.get("difficulty", 50) for kw in keywords) / total_keywords,
            "quick_wins": [kw for kw in keywords if kw.get("difficulty", 50) < 30],
            "competitive_keywords": [kw for kw in keywords if kw.get("difficulty", 50) > 70],
            "recommendations": self._generate_difficulty_recommendations(difficulty_distribution)
        }
    
    def _generate_difficulty_recommendations(self, difficulty_distribution: Dict[str, int]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏"""
        recommendations = []
        
        total_keywords = sum(difficulty_distribution.values())
        if total_keywords == 0:
            return ["–î–æ–±–∞–≤–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"]
        
        easy_percentage = difficulty_distribution.get("easy", 0) / total_keywords
        medium_percentage = difficulty_distribution.get("medium", 0) / total_keywords  
        hard_percentage = difficulty_distribution.get("hard", 0) / total_keywords
        
        if easy_percentage > 0.6:
            recommendations.append("–î–æ–±–∞–≤–∏—Ç—å –±–æ–ª–µ–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ä–æ—Å—Ç–∞")
        elif easy_percentage < 0.2:
            recommendations.append("–î–æ–±–∞–≤–∏—Ç—å –Ω–∏–∑–∫–æ–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –ø–æ–±–µ–¥")
        
        if hard_percentage > 0.4:
            recommendations.append("–°–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏—Ç—å—Å—è —Å–Ω–∞—á–∞–ª–∞ –Ω–∞ –º–µ–Ω–µ–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö")
        
        if medium_percentage < 0.3:
            recommendations.append("–î–æ–±–∞–≤–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Å—Ä–µ–¥–Ω–µ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –±–∞–ª–∞–Ω—Å–∞")
        
        return recommendations if recommendations else ["–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏"]
    
    def _map_search_intent(self, keywords: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–ú–∞–ø–ø–∏–Ω–≥ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∏–Ω—Ç–µ–Ω—Ç–æ–≤"""
        
        intent_mapping = {
            "informational": [],
            "commercial": [],
            "navigational": [],
            "transactional": []
        }
        
        for keyword in keywords:
            intent = keyword.get("intent", "informational")
            if intent in intent_mapping:
                intent_mapping[intent].append(keyword)
            else:
                intent_mapping["informational"].append(keyword)
        
        return {
            "intent_distribution": {intent: len(kws) for intent, kws in intent_mapping.items()},
            "intent_mapping": intent_mapping,
            "content_recommendations": self._generate_intent_based_content_recommendations(intent_mapping)
        }
    
    def _generate_intent_based_content_recommendations(self, intent_mapping: Dict[str, List]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∏–Ω—Ç–µ–Ω—Ç–æ–≤"""
        recommendations = []
        
        total_keywords = sum(len(keywords) for keywords in intent_mapping.values())
        if total_keywords == 0:
            return ["–î–æ–±–∞–≤–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–Ω—Ç–µ–Ω—Ç–æ–≤"]
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏–Ω—Ç–µ–Ω—Ç–æ–≤
        informational_pct = len(intent_mapping.get("informational", [])) / total_keywords
        commercial_pct = len(intent_mapping.get("commercial", [])) / total_keywords
        transactional_pct = len(intent_mapping.get("transactional", [])) / total_keywords
        navigational_pct = len(intent_mapping.get("navigational", [])) / total_keywords
        
        if informational_pct > 0.6:
            recommendations.append("–°–æ–∑–¥–∞—Ç—å –±–æ–ª—å—à–µ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ –∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
        elif informational_pct < 0.2:
            recommendations.append("–î–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π")
        
        if commercial_pct < 0.2:
            recommendations.append("–£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")
        
        if transactional_pct < 0.15:
            recommendations.append("–°–æ–∑–¥–∞—Ç—å –±–æ–ª—å—à–µ –ø—Ä–æ–¥–∞—é—â–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –∏ –ª–µ–Ω–¥–∏–Ω–≥–æ–≤")
        
        if navigational_pct > 0.3:
            recommendations.append("–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –±—Ä–µ–Ω–¥–∏–Ω–≥ –∏ —É–∑–Ω–∞–≤–∞–µ–º–æ—Å—Ç—å")
        
        return recommendations if recommendations else ["–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–Ω—Ç–µ–Ω—Ç–æ–≤"]
    
    def _identify_content_opportunities(self, keywords: List[Dict[str, Any]], industry: str) -> List[Dict[str, Any]]:
        """–í—ã—è–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π"""
        
        opportunities = []
        
        # High-volume, low-difficulty opportunities
        for keyword in keywords:
            if keyword.get("search_volume", 0) > 5000 and keyword.get("difficulty", 100) < 40:
                opportunities.append({
                    "type": "quick_win",
                    "keyword": keyword["keyword"],
                    "opportunity_score": keyword["search_volume"] / keyword["difficulty"],
                    "recommended_content_type": "blog_post",
                    "priority": "high"
                })
        
        # Question-based content opportunities
        question_keywords = [kw for kw in keywords if any(q in kw["keyword"].lower() 
                           for q in ["–∫–∞–∫", "—á—Ç–æ", "–ø–æ—á–µ–º—É", "–≥–¥–µ", "–∫–æ–≥–¥–∞"])]
        
        for keyword in question_keywords[:10]:
            opportunities.append({
                "type": "faq_content",
                "keyword": keyword["keyword"], 
                "opportunity_score": keyword.get("search_volume", 100) * 2,  # FAQ –∫–æ–Ω—Ç–µ–Ω—Ç —á–∞—Å—Ç–æ —Ö–æ—Ä–æ—à–æ —Ä–∞–Ω–∂–∏—Ä—É–µ—Ç—Å—è
                "recommended_content_type": "faq_or_guide",
                "priority": "medium"
            })
        
        return sorted(opportunities, key=lambda x: x["opportunity_score"], reverse=True)[:20]
    
    def _define_content_pillars(self, industry: str, business_goals: List[str]) -> List[Dict[str, Any]]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö —Å—Ç–æ–ª–ø–æ–≤"""
        
        industry_pillars = {
            "fintech": [
                {"name": "–¶–∏—Ñ—Ä–æ–≤–æ–π –±–∞–Ω–∫–∏–Ω–≥", "description": "–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –±–∞–Ω–∫–æ–≤—Å–∫–∏–µ —Ä–µ—à–µ–Ω–∏—è"},
                {"name": "–ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏ –∏ —Ñ–∏–Ω–∞–Ω—Å—ã", "description": "–ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"},
                {"name": "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –≤ —Ñ–∏–Ω–∞–Ω—Å–∞—Ö", "description": "–§–∏–Ω—Ç–µ—Ö –∏–Ω–Ω–æ–≤–∞—Ü–∏–∏"},
                {"name": "–†–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ", "description": "–§–∏–Ω–∞–Ω—Å–æ–≤–æ–µ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ"}
            ],
            "ecommerce": [
                {"name": "–¢–æ–≤–∞—Ä—ã –∏ –∫–∞—Ç–∞–ª–æ–≥", "description": "–ü—Ä–æ–¥—É–∫—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç"},
                {"name": "–ü–æ–∫—É–ø–∞—Ç–µ–ª—å—Å–∫–∏–π –æ–ø—ã—Ç", "description": "UX –∏ —Å–µ—Ä–≤–∏—Å"},
                {"name": "–ú–∞—Ä–∫–µ—Ç–∏–Ω–≥ –∏ –ø—Ä–æ–¥–∞–∂–∏", "description": "–ü—Ä–æ–¥–≤–∏–∂–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤"},
                {"name": "–õ–æ–≥–∏—Å—Ç–∏–∫–∞", "description": "–î–æ—Å—Ç–∞–≤–∫–∞ –∏ fulfillment"}
            ],
            "general": [
                {"name": "–≠–∫—Å–ø–µ—Ä—Ç–∏–∑–∞", "description": "–û—Ç—Ä–∞—Å–ª–µ–≤–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞"},
                {"name": "–†–µ—à–µ–Ω–∏—è", "description": "–ü—Ä–æ–¥—É–∫—Ç—ã –∏ —É—Å–ª—É–≥–∏"},
                {"name": "–ö–µ–π—Å—ã", "description": "–ò—Å—Ç–æ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞"},
                {"name": "–¢—Ä–µ–Ω–¥—ã", "description": "–û—Ç—Ä–∞—Å–ª–µ–≤—ã–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏"}
            ]
        }
        
        pillars = industry_pillars.get(industry, industry_pillars["general"])
        
        # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –ø–æ–¥ –±–∏–∑–Ω–µ—Å-—Ü–µ–ª–∏
        for pillar in pillars:
            if "lead_generation" in business_goals:
                pillar["lead_generation_potential"] = "high"
            if "brand_awareness" in business_goals:
                pillar["brand_building_potential"] = "high"
        
        return pillars
    
    def _recommend_content_types(self, industry: str, budget: int, goals: List[str]) -> List[Dict[str, Any]]:
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è —Ç–∏–ø–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        
        # Budget-based recommendations
        if budget < 50000:  # Small budget
            recommended_types = [
                {"type": "blog_posts", "frequency": "weekly", "investment": 30000},
                {"type": "social_media", "frequency": "daily", "investment": 15000}
            ]
        elif budget < 200000:  # Medium budget
            recommended_types = [
                {"type": "blog_posts", "frequency": "bi-weekly", "investment": 60000},
                {"type": "guides", "frequency": "monthly", "investment": 40000},
                {"type": "infographics", "frequency": "bi-weekly", "investment": 30000},
                {"type": "videos", "frequency": "monthly", "investment": 50000}
            ]
        else:  # Large budget
            recommended_types = [
                {"type": "blog_posts", "frequency": "daily", "investment": 80000},
                {"type": "pillar_pages", "frequency": "weekly", "investment": 60000},
                {"type": "whitepapers", "frequency": "monthly", "investment": 40000},
                {"type": "webinars", "frequency": "bi-weekly", "investment": 50000},
                {"type": "case_studies", "frequency": "weekly", "investment": 30000}
            ]
        
        # Goal-based adjustments
        for content_type in recommended_types:
            if "lead_generation" in goals:
                content_type["lead_gen_score"] = 8 if content_type["type"] in ["whitepapers", "webinars"] else 5
            if "brand_awareness" in goals:
                content_type["brand_score"] = 9 if content_type["type"] in ["videos", "infographics"] else 6
        
        return recommended_types
    
    def _calculate_publishing_schedule(self, budget: int, industry: str) -> Dict[str, Any]:
        """–†–∞—Å—á–µ—Ç –≥—Ä–∞—Ñ–∏–∫–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–π"""
        
        # Budget-based frequency calculation
        if budget < 50000:
            weekly_posts = 1
            monthly_premium = 0
        elif budget < 100000:
            weekly_posts = 2
            monthly_premium = 1
        elif budget < 200000:
            weekly_posts = 3
            monthly_premium = 2
        else:
            weekly_posts = 5
            monthly_premium = 4
        
        return {
            "weekly_blog_posts": weekly_posts,
            "monthly_premium_content": monthly_premium,
            "quarterly_major_content": max(1, monthly_premium // 2),
            "daily_social_content": min(7, budget // 10000),
            "total_monthly_pieces": (weekly_posts * 4) + monthly_premium,
            "annual_content_pieces": ((weekly_posts * 4) + monthly_premium) * 12
        }
    
    def _calculate_content_roi_projection(self, budget: int, industry: str, schedule: Dict[str, Any]) -> Dict[str, Any]:
        """–†–∞—Å—á–µ—Ç ROI –ø—Ä–æ–µ–∫—Ü–∏–∏ –¥–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        
        # Industry multipliers
        industry_multipliers = {
            "fintech": 3.2,
            "saas": 4.1,
            "ecommerce": 2.8,
            "healthcare": 3.5,
            "general": 2.5
        }
        
        multiplier = industry_multipliers.get(industry, 2.5)
        annual_budget = budget * 12
        
        # ROI calculation based on content volume and industry
        monthly_content_pieces = schedule.get("total_monthly_pieces", 4)
        content_scaling_factor = min(2.0, 1 + (monthly_content_pieces - 4) * 0.1)
        
        projected_annual_roi = annual_budget * multiplier * content_scaling_factor
        
        return {
            "annual_investment": annual_budget,
            "projected_annual_return": projected_annual_roi,
            "roi_multiplier": projected_annual_roi / annual_budget,
            "monthly_roi_projection": projected_annual_roi / 12,
            "payback_months": max(6, 12 / (projected_annual_roi / annual_budget)),
            "confidence_level": min(85, 60 + (content_scaling_factor * 15))
        }
    
    def _assess_content_quality(self, result: Dict[str, Any]) -> str:
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        quality_score = 0
        max_score = 100
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        if "keyword_research" in result:
            quality_score += 25
        if "content_strategy" in result:
            quality_score += 25  
        if "topic_clusters" in result:
            quality_score += 20
        if "content_calendar" in result:
            quality_score += 15
        if "eeat_optimization" in result:
            quality_score += 15
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é –æ—Ü–µ–Ω–∫—É
        if quality_score >= 85:
            return "comprehensive"
        elif quality_score >= 65:
            return "good"
        elif quality_score >= 45:
            return "basic"
        else:
            return "incomplete"
    
    def _calculate_strategy_confidence(self, result: Dict[str, Any]) -> float:
        """–†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""
        
        confidence = 0.6  # –ë–∞–∑–æ–≤–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        if "keyword_research" in result:
            keyword_count = result["keyword_research"].get("keyword_research_results", {}).get("total_keywords", 0)
            confidence += min(0.2, keyword_count / 1000)
        
        if "content_strategy" in result:
            budget = result["content_strategy"].get("content_strategy", {}).get("monthly_budget", 0)
            confidence += min(0.15, budget / 1000000)  # –ë–æ–ª—å—à–µ –±—é–¥–∂–µ—Ç = –±–æ–ª—å—à–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        
        if "topic_clusters" in result:
            cluster_count = result["topic_clusters"].get("topic_clusters", {}).get("total_clusters", 0)
            confidence += min(0.1, cluster_count / 50)
        
        return min(0.95, confidence)
    
    # Helper methods –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    def _create_topic_based_clusters(self, keywords: List[Dict[str, Any]], industry: str) -> List[Dict[str, Any]]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–º"""
        # Simplified clustering logic
        clusters = []
        cluster_size = self.content_config["topic_cluster_size"]
        
        for i in range(0, len(keywords), cluster_size):
            cluster_keywords = keywords[i:i+cluster_size]
            if cluster_keywords:
                clusters.append({
                    "cluster_id": f"cluster_{len(clusters)+1}",
                    "main_topic": cluster_keywords[0]["keyword"],
                    "keywords": cluster_keywords,
                    "keyword_count": len(cluster_keywords),
                    "total_search_volume": sum(kw.get("search_volume", 0) for kw in cluster_keywords),
                    "avg_difficulty": sum(kw.get("difficulty", 50) for kw in cluster_keywords) / len(cluster_keywords),
                    "content_priority": "high" if i < cluster_size * 3 else "medium"
                })
        
        return clusters
    
    def _prioritize_clusters(self, clusters: List[Dict[str, Any]], industry: str) -> List[Dict[str, Any]]:
        """–ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"""
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π —Ü–µ–Ω–Ω–æ—Å—Ç–∏ (–æ–±—ä–µ–º –ø–æ–∏—Å–∫–∞ / —Å–ª–æ–∂–Ω–æ—Å—Ç—å)
        for cluster in clusters:
            total_volume = cluster.get("total_search_volume", 1)
            avg_difficulty = cluster.get("avg_difficulty", 50)
            cluster["priority_score"] = total_volume / max(avg_difficulty, 1)
        
        return sorted(clusters, key=lambda x: x["priority_score"], reverse=True)
    
    def _generate_content_calendar(self, clusters: List[Dict[str, Any]], frequency: str, horizon: int) -> List[Dict[str, Any]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç-–∫–∞–ª–µ–Ω–¥–∞—Ä—è"""
        
        calendar = []
        frequency_map = {"daily": 1, "weekly": 7, "bi-weekly": 14, "monthly": 30}
        interval = frequency_map.get(frequency, 7)
        
        for i, cluster in enumerate(clusters):
            if i * interval < horizon:
                calendar.append({
                    "date": f"Day {(i * interval) + 1}",
                    "content_title": f"Content for {cluster.get('main_topic', f'Topic {i+1}')}",
                    "cluster_id": cluster.get("cluster_id", f"cluster_{i+1}"),
                    "content_type": "blog_post",
                    "target_keywords": cluster.get("keywords", [])[:5],  # Top 5 keywords
                    "estimated_effort": "4-6 hours",
                    "priority": cluster.get("content_priority", "medium")
                })
        
        return calendar[:horizon//7]  # Limit to reasonable number
    
    # Additional helper methods
    def _create_implementation_roadmap(self, pillars: List[Dict], schedule: Dict) -> List[Dict[str, Any]]:
        """–°–æ–∑–¥–∞–Ω–∏–µ roadmap'–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏"""
        return [
            {"phase": "Phase 1", "duration": "Month 1-2", "focus": "Keyword research & content pillars setup"},
            {"phase": "Phase 2", "duration": "Month 3-4", "focus": "Core content creation & optimization"},
            {"phase": "Phase 3", "duration": "Month 5-6", "focus": "Content distribution & performance optimization"}
        ]
    
    def _define_success_metrics(self, goals: List[str]) -> Dict[str, Any]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ —É—Å–ø–µ—Ö–∞"""
        return {
            "traffic_growth": "25% increase in 6 months",
            "keyword_rankings": "50% of target keywords in top 10",
            "engagement_metrics": "15% increase in time on page",
            "conversion_metrics": "10% increase in organic conversions"
        }
    
    def _calculate_resource_requirements(self, schedule: Dict, budget: int) -> Dict[str, Any]:
        """–†–∞—Å—á–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ —Ä–µ—Å—É—Ä—Å–∞–º"""
        return {
            "content_writers": max(1, schedule.get("weekly_blog_posts", 1) // 2),
            "editors": 1,
            "designers": 1 if budget > 100000 else 0.5,
            "monthly_budget_allocation": {
                "writing": budget * 0.4,
                "design": budget * 0.3,
                "promotion": budget * 0.3
            }
        }