"""
üéØ Competitive Analysis Agent

Operational-level –∞–≥–µ–Ω—Ç –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤, SERP research, 
gap analysis –∏ –≤—ã—è–≤–ª–µ–Ω–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –¥–ª—è –æ–±–≥–æ–Ω–∞ —Å–æ–ø–µ—Ä–Ω–∏–∫–æ–≤ –≤ –ø–æ–∏—Å–∫–æ–≤–æ–π –≤—ã–¥–∞—á–µ.

–û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
- SERP analysis & monitoring
- Competitor gap analysis
- Share of voice tracking  
- Content gap identification
- Technical advantage mapping
"""

import logging
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
import random

from core.base_agent import BaseAgent
from core.interfaces.data_models import AgentMetrics

logger = logging.getLogger(__name__)


class CompetitiveAnalysisAgent(BaseAgent):
    """
    üéØ Competitive Analysis Agent
    
    Operational-level –∞–≥–µ–Ω—Ç –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞,
    SERP –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –≤—ã—è–≤–ª–µ–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π.
    """
    
    def __init__(self, data_provider=None, agent_level=None, **kwargs):
        # –£–±–∏—Ä–∞–µ–º agent_level –∏–∑ kwargs –µ—Å–ª–∏ –æ–Ω —Ç–∞–º –µ—Å—Ç—å
        if 'agent_level' in kwargs:
            del kwargs['agent_level']
            
        super().__init__(
            agent_id="competitive_analysis_agent",
            name="Competitive Analysis Agent",
            agent_level=agent_level or "operational",
            data_provider=data_provider,
            knowledge_base="knowledge/operational/competitive_analysis.md",
            **kwargs
        )
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Competitive Analysis
        self.max_competitors = 10  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        self.min_market_share = 5.0  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–æ–ª—è —Ä—ã–Ω–∫–∞ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤ –∞–Ω–∞–ª–∏–∑ (%)
        self.keyword_tracking_limit = 1000  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        self.serp_monitoring_depth = 20  # –ì–ª—É–±–∏–Ω–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ SERP (—Ç–æ–ø-N –ø–æ–∑–∏—Ü–∏–π)
        
        # SERP feature weights for opportunity scoring
        self.serp_feature_values = {
            "featured_snippets": {"weight": 0.35, "traffic_impact": 0.35},
            "people_also_ask": {"weight": 0.15, "traffic_impact": 0.12},
            "image_packs": {"weight": 0.10, "traffic_impact": 0.08},
            "video_results": {"weight": 0.25, "traffic_impact": 0.25},
            "local_pack": {"weight": 0.30, "traffic_impact": 0.30},
            "knowledge_panels": {"weight": 0.05, "traffic_impact": 0.05}
        }
        
        # Competitive strength factors  
        self.strength_factors = {
            "content_strategy": {"weight": 0.25},
            "technical_performance": {"weight": 0.20},
            "backlink_authority": {"weight": 0.25},
            "social_presence": {"weight": 0.15},
            "brand_authority": {"weight": 0.15}
        }
        
        logger.info(f"‚úÖ {self.name} –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω:")
        logger.info(f"   üéØ Max Competitors: {self.max_competitors}")
        logger.info(f"   üìä Min Market Share: {self.min_market_share}%")
        logger.info(f"   üîç Keyword Tracking Limit: {self.keyword_tracking_limit}")
        logger.info(f"   üìà SERP Monitoring Depth: {self.serp_monitoring_depth}")
    
    def get_system_prompt(self) -> str:
        """–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        return f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π Competitive Analysis Agent, —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –≥–ª—É–±–æ–∫–æ–º—É –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–º—É –∞–Ω–∞–ª–∏–∑—É –∏ SERP research.

–¢–í–û–Ø –≠–ö–°–ü–ï–†–¢–ò–ó–ê:
‚Ä¢ SERP Analysis & Feature Monitoring - 30%
‚Ä¢ Competitor Gap Analysis (—Å–ª–∞–±—ã–µ –º–µ—Å—Ç–∞) - 25%
‚Ä¢ Market Share & Voice Analysis - 20%
‚Ä¢ Content Gap Identification - 15%
‚Ä¢ Competitor Strategy Monitoring - 10%

–ó–ê–î–ê–ß–ê: –ü—Ä–æ–≤–µ—Å—Ç–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑, –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –æ–±–≥–æ–Ω–∞ –∏ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –¥–æ–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏—è.

–ú–ï–¢–û–î–û–õ–û–ì–ò–Ø –ê–ù–ê–õ–ò–ó–ê:
1. SERP Landscape Analysis (30 –±–∞–ª–ª–æ–≤):
   - Featured Snippets ownership –∏ opportunities (0-10)
   - SERP Features presence (PAA, Images, Video) (0-8)
   - Position distribution –ø–æ keyword set (0-7)
   - Competitive intensity assessment (0-5)

2. Competitor Gap Analysis (25 –±–∞–ª–ª–æ–≤):
   - Keyword gaps identification (0-8)
   - Content quality –∏ depth gaps (0-7)
   - Technical performance gaps (0-5)
   - Backlink profile weaknesses (0-5)

3. Market Share Analysis (20 –±–∞–ª–ª–æ–≤):
   - Visibility share calculation (0-8)
   - Traffic share estimation (0-6)
   - Market position –∏ ranking (0-6)

4. Content Gap Opportunities (15 –±–∞–ª–ª–æ–≤):
   - Topic coverage analysis (0-5)
   - Content format opportunities (0-5)
   - Expertise demonstration gaps (0-5)

5. Strategic Opportunities (10 –±–∞–ª–ª–æ–≤):
   - Overtaking possibilities identification (0-4)
   - Blue ocean opportunities (0-3)
   - Emerging trend capture (0-3)

–ö–û–ù–ö–£–†–ï–ù–¢–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´:
- –ú–∞–∫—Å–∏–º—É–º –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤: {self.max_competitors}
- –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–æ–ª—è —Ä—ã–Ω–∫–∞: {self.min_market_share}%
- SERP –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥: –¢–û–ü-{self.serp_monitoring_depth} –ø–æ–∑–∏—Ü–∏–π
- Keyword tracking: {self.keyword_tracking_limit} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤

–û–¢–†–ê–°–õ–ï–í–´–ï –ë–û–ù–£–°–´:
‚Ä¢ FinTech: +15 (regulatory compliance focus)
‚Ä¢ E-commerce: +12 (product competition analysis)
‚Ä¢ B2B Services: +10 (thought leadership opportunities)
‚Ä¢ Healthcare: +8 (expertise-based competition)
‚Ä¢ Real Estate: +6 (local market competition)

–†–ï–ó–£–õ–¨–¢–ê–¢: –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º, SERP –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π –æ–±–≥–æ–Ω–∞."""

    async def process_task(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ LLM –≤—ã–∑–æ–≤–∞–º–∏
        
        Args:
            task_data: –î–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞—Ö –∏ —Ç–∏–ø–µ –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç OpenAI
        """
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            input_data = task_data.get("input_data", {})
            task_type = task_data.get('task_type', 'comprehensive_competitive_analysis')
            
            logger.info(f"üéØ –ù–∞—á–∏–Ω–∞–µ–º –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑: {input_data.get('our_domain', 'Unknown')}, —Ç–∏–ø: {task_type}")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            user_prompt = f"""–ü—Ä–æ–≤–µ–¥–∏ –≥–ª—É–±–æ–∫–∏–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è:

–ù–ê–® –î–û–ú–ï–ù –ò –ö–û–ù–ö–£–†–ï–ù–¢–´:
Our Domain: {input_data.get('our_domain', input_data.get('domain', 'Unknown'))}
Industry: {input_data.get('industry', 'Unknown')}
Competitors: {input_data.get('competitors', 'Unknown')}
Target Keywords: {input_data.get('target_keywords', 'Unknown')}
Current Market Position: {input_data.get('current_position', 'Unknown')}
Analysis Type: {task_type}
Current DA: {input_data.get('domain_authority', 'Unknown')}
Current Organic Traffic: {input_data.get('organic_traffic', 'Unknown')}
Current Rankings: {input_data.get('current_rankings', 'Unknown')}
Market Focus: {input_data.get('market_focus', '–†–æ—Å—Å–∏—è')}

–í—ã–ø–æ–ª–Ω–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –≤—Å–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º –æ–±–ª–∞—Å—Ç—è–º. –í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ç—Ä–æ–≥–æ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
{{
    "competitive_analysis_score": <number 0-100>,
    "competitive_health": "<Excellent/Good/Needs Improvement/Poor/Critical>",
    "serp_analysis": {{
        "serp_feature_ownership": <percentage>,
        "our_avg_position": <number>,
        "featured_snippets_owned": <number>,
        "featured_snippets_opportunities": <number>,
        "serp_features_present": ["<features in SERP>"],
        "high_priority_opportunities": ["<top opportunities>"],
        "competitive_intensity": "<very_high/high/medium/low>"
    }},
    "competitor_gap_analysis": {{
        "main_competitors": ["<competitor domains>"],
        "competitor_strengths": {{
            "<competitor1>": {{"strength": <0-100>, "key_advantages": ["<advantages>"]}}
        }},
        "gap_opportunities": {{
            "keyword_gaps": <number>,
            "content_gaps": <number>,
            "technical_gaps": <number>,
            "backlink_gaps": <number>
        }},
        "overtaking_opportunities": ["<realistic opportunities to surpass competitors>"]
    }},
    "market_share_analysis": {{
        "our_visibility_share": <percentage>,
        "our_traffic_share": <percentage>,
        "market_position": <ranking position>,
        "growth_potential": "<high/medium/low>",
        "market_leaders": ["<leading domains>"],
        "market_trends": "<market direction>"
    }},
    "content_gap_opportunities": {{
        "high_value_topics": ["<topics with high opportunity>"],
        "content_format_gaps": ["<missing content formats>"],
        "expertise_gaps": ["<areas where we can dominate>"],
        "estimated_traffic_potential": <number>
    }},
    "strategic_recommendations": {{
        "immediate_priorities": ["<top 3 actions>"],
        "short_term_goals": ["<3-6 month objectives>"],
        "long_term_strategy": ["<6-12 month strategy>"],
        "resource_allocation": {{
            "content": "<percentage>",
            "technical": "<percentage>",
            "link_building": "<percentage>",
            "paid_promotion": "<percentage>"
        }}
    }},
    "competitive_threats": ["<main threats to watch>"],
    "blue_ocean_opportunities": ["<unique opportunities with low competition>"],
    "success_probability": <0.0-1.0>
}}"""

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π –º–µ—Ç–æ–¥ —Å LLM –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π
            result = await self.process_with_llm(user_prompt, input_data)
            
            if result["success"]:
                logger.info(f"‚úÖ –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —á–µ—Ä–µ–∑ OpenAI: {result.get('model_used', 'unknown')}")
                # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç–∞
                if isinstance(result.get("result"), str):
                    # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ç—Ä–æ–∫–∞, –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                    result["competitive_analysis_response"] = result["result"]
                    result["agent_type"] = "competitive_analysis"
                    result["analysis_type"] = task_type
                    result["methodology"] = ["SERP Analysis", "Gap Analysis", "Market Share Analysis"]
                
                return result
            else:
                # Fallback –∫ –±–∞–∑–æ–≤–æ–π –ª–æ–≥–∏–∫–µ –µ—Å–ª–∏ OpenAI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
                logger.warning("‚ö†Ô∏è OpenAI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
                return await self._fallback_competitive_analysis(input_data, task_type)
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ: {str(e)}")
            return {
                "success": False,
                "agent": self.agent_id,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

    async def _analyze_serp_landscape(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –ø–æ–∏—Å–∫–æ–≤–æ–π –≤—ã–¥–∞—á–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º –∑–∞–ø—Ä–æ—Å–∞–º"""
        query_data = task_data.get('query_data', {})
        target_keywords = query_data.get('keywords', ['SEO —É—Å–ª—É–≥–∏', '–ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏–µ —Å–∞–π—Ç–æ–≤'])
        our_domain = query_data.get('our_domain', 'example.com')
        
        # –ê–Ω–∞–ª–∏–∑ SERP –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞
        serp_analysis_results = []
        total_serp_features = 0
        our_serp_features = 0
        
        for keyword in target_keywords[:10]:  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–æ 10 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            # –°–∏–º—É–ª—è—Ü–∏—è SERP –¥–∞–Ω–Ω—ã—Ö
            serp_data = self._generate_serp_data(keyword, our_domain)
            
            # –ü–æ–¥—Å—á–µ—Ç SERP features
            total_serp_features += len(serp_data['serp_features'])
            our_serp_features += sum(1 for feature in serp_data['serp_features'] if feature['owned_by_us'])
            
            serp_analysis_results.append({
                "keyword": keyword,
                "search_volume": serp_data['search_volume'],
                "difficulty": serp_data['difficulty'],
                "our_position": serp_data['our_position'],
                "top_competitors": serp_data['top_competitors'],
                "serp_features": serp_data['serp_features'],
                "opportunities": serp_data['opportunities'],
                "competitive_intensity": serp_data['competitive_intensity']
            })
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ SERP
        serp_feature_ownership = (our_serp_features / total_serp_features * 100) if total_serp_features > 0 else 0
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
        high_priority_opportunities = []
        medium_priority_opportunities = []
        
        for result in serp_analysis_results:
            for opp in result['opportunities']:
                if opp['priority'] == 'high':
                    high_priority_opportunities.append({
                        'keyword': result['keyword'],
                        'opportunity': opp['type'],
                        'description': opp['description'],
                        'traffic_potential': opp['traffic_potential']
                    })
                elif opp['priority'] == 'medium':
                    medium_priority_opportunities.append({
                        'keyword': result['keyword'],
                        'opportunity': opp['type'],
                        'description': opp['description'],
                        'traffic_potential': opp['traffic_potential']
                    })
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        strategy_recommendations = self._get_serp_strategy_recommendations(
            serp_analysis_results, serp_feature_ownership
        )
        
        logger.info(f"üîç SERP Analysis:")
        logger.info(f"   üìä Keywords Analyzed: {len(target_keywords)}")
        logger.info(f"   üéØ SERP Feature Ownership: {serp_feature_ownership:.1f}%")
        logger.info(f"   üöÄ High Priority Opportunities: {len(high_priority_opportunities)}")
        logger.info(f"   üìà Medium Priority Opportunities: {len(medium_priority_opportunities)}")
        
        return {
            "success": True,
            "our_domain": our_domain,
            "keywords_analyzed": len(target_keywords),
            "serp_feature_ownership": round(serp_feature_ownership, 1),
            "serp_analysis": serp_analysis_results,
            "high_priority_opportunities": high_priority_opportunities,
            "medium_priority_opportunities": medium_priority_opportunities,
            "strategy_recommendations": strategy_recommendations,
            "competitive_landscape_summary": self._summarize_competitive_landscape(serp_analysis_results),
            "agent": self.name,
            "confidence": round(random.uniform(0.80, 0.95), 2)
        }

    async def _analyze_competitor_gaps(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """–í—ã—è–≤–ª–µ–Ω–∏–µ —Å–ª–∞–±—ã—Ö –º–µ—Å—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤"""
        competitor_data = task_data.get('competitor_data', {})
        competitors = competitor_data.get('competitors', ['competitor1.com', 'competitor2.com'])
        our_domain = competitor_data.get('our_domain', 'example.com')
        analysis_scope = competitor_data.get('scope', 'comprehensive')
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞
        competitor_gap_analysis = []
        
        for competitor in competitors[:self.max_competitors]:
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞
            competitor_profile = self._generate_competitor_profile(competitor)
            
            # –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è gaps
            keyword_gaps = self._identify_keyword_gaps(competitor_profile)
            content_gaps = self._identify_competitor_content_gaps(competitor_profile)
            technical_gaps = self._identify_technical_gaps(competitor_profile)
            backlink_gaps = self._identify_backlink_gaps(competitor_profile)
            
            # –û—Ü–µ–Ω–∫–∞ —Å–∏–ª—ã –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞
            competitor_strength = self._calculate_competitor_strength(competitor_profile)
            
            # –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –æ–±–≥–æ–Ω–∞
            overtaking_opportunities = self._identify_overtaking_opportunities(
                competitor_profile, keyword_gaps, content_gaps, technical_gaps
            )
            
            competitor_gap_analysis.append({
                "competitor_domain": competitor,
                "competitor_strength": competitor_strength,
                "keyword_gaps": keyword_gaps,
                "content_gaps": content_gaps,
                "technical_gaps": technical_gaps,
                "backlink_gaps": backlink_gaps,
                "overtaking_opportunities": overtaking_opportunities,
                "threat_level": self._assess_competitor_threat_level(competitor_strength, competitor_profile)
            })
        
        # –û–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ –ª–∞–Ω–¥—à–∞—Ñ—Ç–∞
        market_dynamics = self._analyze_market_dynamics(competitor_gap_analysis)
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        strategic_actions = self._formulate_gap_strategy(competitor_gap_analysis, market_dynamics)
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –¥–µ–π—Å—Ç–≤–∏–π
        action_priorities = self._prioritize_competitive_actions(competitor_gap_analysis)
        
        logger.info(f"üéØ Competitor Gap Analysis:")
        logger.info(f"   üè¢ Competitors Analyzed: {len(competitors)}")
        logger.info(f"   üîç Total Gaps Identified: {sum(len(c['keyword_gaps']) + len(c['content_gaps']) for c in competitor_gap_analysis)}")
        logger.info(f"   üöÄ Overtaking Opportunities: {sum(len(c['overtaking_opportunities']) for c in competitor_gap_analysis)}")
        
        return {
            "success": True,
            "our_domain": our_domain,
            "competitors_analyzed": len(competitors),
            "competitor_gap_analysis": competitor_gap_analysis,
            "market_dynamics": market_dynamics,
            "strategic_actions": strategic_actions,
            "action_priorities": action_priorities,
            "competitive_advantage_score": self._calculate_our_competitive_advantage(competitor_gap_analysis),
            "agent": self.name,
            "confidence": round(random.uniform(0.75, 0.90), 2)
        }

    async def _analyze_market_share(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –¥–æ–ª–∏ –≥–æ–ª–æ—Å–∞ –≤ –Ω–∏—à–µ"""
        market_data = task_data.get('market_data', {})
        our_domain = market_data.get('our_domain', 'example.com')
        industry = market_data.get('industry', 'seo_services')
        competitors = market_data.get('competitors', ['competitor1.com', 'competitor2.com'])
        
        # –°–∏–º—É–ª—è—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –æ —Ä—ã–Ω–∫–µ
        total_market_keywords = random.randint(5000, 20000)
        total_market_traffic = random.randint(500000, 5000000)
        
        # –ê–Ω–∞–ª–∏–∑ –¥–æ–ª–∏ –∫–∞–∂–¥–æ–≥–æ –∏–≥—Ä–æ–∫–∞
        market_players = []
        remaining_share = 100.0
        
        # –ù–∞—à –¥–æ–º–µ–Ω
        our_visibility = random.uniform(8.0, 25.0)
        our_traffic_share = random.uniform(6.0, 20.0)
        remaining_share -= our_visibility
        
        market_players.append({
            "domain": our_domain,
            "is_our_domain": True,
            "visibility_share": our_visibility,
            "traffic_share": our_traffic_share,
            "ranking_keywords": int(total_market_keywords * (our_visibility / 100)),
            "estimated_traffic": int(total_market_traffic * (our_traffic_share / 100)),
            "avg_position": random.uniform(8.5, 15.2),
            "serp_features_owned": random.randint(15, 45)
        })
        
        # –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã
        for i, competitor in enumerate(competitors[:8]):
            comp_visibility = random.uniform(3.0, min(remaining_share * 0.4, 18.0))
            comp_traffic = random.uniform(2.0, comp_visibility * 1.2)
            remaining_share -= comp_visibility
            
            market_players.append({
                "domain": competitor,
                "is_our_domain": False,
                "visibility_share": comp_visibility,
                "traffic_share": comp_traffic,
                "ranking_keywords": int(total_market_keywords * (comp_visibility / 100)),
                "estimated_traffic": int(total_market_traffic * (comp_traffic / 100)),
                "avg_position": random.uniform(6.0, 20.0),
                "serp_features_owned": random.randint(5, 60)
            })
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ visibility share
        market_players = sorted(market_players, key=lambda x: x['visibility_share'], reverse=True)
        
        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤
        market_trends = self._analyze_market_trends(market_players, our_domain)
        
        # –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ä–æ—Å—Ç–∞
        growth_opportunities = self._identify_market_growth_opportunities(
            market_players, our_domain, total_market_keywords
        )
        
        # –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è
        competitive_position = self._assess_competitive_position(market_players, our_domain)
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        market_strategy = self._develop_market_strategy(
            competitive_position, growth_opportunities, market_trends
        )
        
        logger.info(f"üìä Market Share Analysis for {industry}:")
        logger.info(f"   üéØ Our Visibility Share: {our_visibility:.1f}%")
        logger.info(f"   üìà Market Position: #{next(i+1 for i, p in enumerate(market_players) if p['is_our_domain'])}")
        logger.info(f"   üöÄ Growth Opportunities: {len(growth_opportunities)}")
        
        return {
            "success": True,
            "our_domain": our_domain,
            "industry": industry,
            "total_market_keywords": total_market_keywords,
            "total_market_traffic": total_market_traffic,
            "our_visibility_share": round(our_visibility, 1),
            "our_traffic_share": round(our_traffic_share, 1),
            "market_position": next(i+1 for i, p in enumerate(market_players) if p['is_our_domain']),
            "market_players": market_players,
            "market_trends": market_trends,
            "competitive_position": competitive_position,
            "growth_opportunities": growth_opportunities,
            "market_strategy": market_strategy,
            "agent": self.name,
            "confidence": round(random.uniform(0.80, 0.92), 2)
        }

    async def _identify_content_gaps(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π"""
        content_data = task_data.get('content_data', {})
        our_domain = content_data.get('our_domain', 'example.com')
        competitors = content_data.get('competitors', ['competitor1.com', 'competitor2.com'])
        target_topics = content_data.get('topics', ['SEO', '–∫–æ–Ω—Ç–µ–Ω—Ç-–º–∞—Ä–∫–µ—Ç–∏–Ω–≥', '–≤–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞'])
        
        # –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ª–∞–Ω–¥—à–∞—Ñ—Ç–∞
        content_landscape = []
        all_content_gaps = []
        
        for topic in target_topics:
            # –°–∏–º—É–ª—è—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ —Ç–µ–º–µ
            topic_analysis = self._analyze_topic_content_landscape(topic, competitors, our_domain)
            content_landscape.append(topic_analysis)
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ gaps –¥–ª—è —ç—Ç–æ–π —Ç–µ–º—ã
            for gap in topic_analysis['content_gaps']:
                all_content_gaps.append({
                    'topic': topic,
                    'gap_type': gap['type'],
                    'opportunity': gap['opportunity'],
                    'competitor_advantage': gap['competitor_performance'],
                    'our_potential': gap['our_potential'],
                    'priority': gap['priority'],
                    'estimated_traffic': gap['traffic_potential'],
                    'production_cost': gap['production_cost'],
                    'timeline': gap['timeline']
                })
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
        high_priority_gaps = [gap for gap in all_content_gaps if gap['priority'] == 'high']
        medium_priority_gaps = [gap for gap in all_content_gaps if gap['priority'] == 'medium']
        
        # –ö–æ–Ω—Ç–µ–Ω—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
        content_strategy = self._develop_content_gap_strategy(
            all_content_gaps, content_landscape
        )
        
        # ROI –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
        content_roi_analysis = self._analyze_content_gaps_roi(all_content_gaps)
        
        # –†–µ—Å—É—Ä—Å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
        resource_requirements = self._calculate_content_gap_resources(all_content_gaps)
        
        logger.info(f"üìù Content Gap Analysis:")
        logger.info(f"   üìä Topics Analyzed: {len(target_topics)}")
        logger.info(f"   üîç Total Content Gaps: {len(all_content_gaps)}")
        logger.info(f"   üöÄ High Priority Gaps: {len(high_priority_gaps)}")
        logger.info(f"   üìà Estimated Traffic Potential: {sum(gap['estimated_traffic'] for gap in all_content_gaps):,}")
        
        return {
            "success": True,
            "our_domain": our_domain,
            "topics_analyzed": len(target_topics),
            "total_content_gaps": len(all_content_gaps),
            "content_landscape": content_landscape,
            "high_priority_gaps": high_priority_gaps,
            "medium_priority_gaps": medium_priority_gaps,
            "content_strategy": content_strategy,
            "roi_analysis": content_roi_analysis,
            "resource_requirements": resource_requirements,
            "estimated_total_traffic_potential": sum(gap['estimated_traffic'] for gap in all_content_gaps),
            "agent": self.name,
            "confidence": round(random.uniform(0.75, 0.88), 2)
        }

    async def _monitor_competitor_changes(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏–∑–º–µ–Ω–µ–Ω–∏–π —É –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤"""
        monitoring_data = task_data.get('monitoring_data', {})
        competitors = monitoring_data.get('competitors', ['competitor1.com', 'competitor2.com'])
        monitoring_period = monitoring_data.get('period_days', 30)
        our_domain = monitoring_data.get('our_domain', 'example.com')
        
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏–∑–º–µ–Ω–µ–Ω–∏–π —É –∫–∞–∂–¥–æ–≥–æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞
        competitor_changes = []
        significant_changes = []
        
        for competitor in competitors[:self.max_competitors]:
            # –°–∏–º—É–ª—è—Ü–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –∑–∞ –ø–µ—Ä–∏–æ–¥
            changes = self._generate_competitor_changes(competitor, monitoring_period)
            
            # –û—Ü–µ–Ω–∫–∞ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π
            change_significance = self._assess_change_significance(changes)
            
            competitor_changes.append({
                "competitor": competitor,
                "monitoring_period_days": monitoring_period,
                "ranking_changes": changes['ranking_changes'],
                "content_changes": changes['content_changes'],
                "technical_changes": changes['technical_changes'],
                "backlink_changes": changes['backlink_changes'],
                "serp_feature_changes": changes['serp_feature_changes'],
                "change_significance": change_significance,
                "threat_assessment": self._assess_competitor_threat(changes, change_significance)
            })
            
            # –°–±–æ—Ä –∑–Ω–∞—á–∏–º—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
            if change_significance['overall_significance'] >= 7.0:
                significant_changes.append({
                    "competitor": competitor,
                    "change_type": change_significance['primary_change_type'],
                    "impact_level": change_significance['impact_level'],
                    "description": change_significance['description'],
                    "our_response_needed": change_significance['response_required']
                })
        
        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤
        market_trend_analysis = self._analyze_competitive_trends(competitor_changes)
        
        # –ê–ª–µ—Ä—Ç—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        competitive_alerts = self._generate_competitive_alerts(significant_changes)
        response_recommendations = self._generate_response_recommendations(significant_changes, market_trend_analysis)
        
        # –ü—Ä–æ–≥–Ω–æ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        trend_predictions = self._predict_competitive_trends(competitor_changes)
        
        logger.info(f"üìä Competitor Monitoring ({monitoring_period} days):")
        logger.info(f"   üè¢ Competitors Monitored: {len(competitors)}")
        logger.info(f"   üö® Significant Changes: {len(significant_changes)}")
        logger.info(f"   üìà Active Alerts: {len(competitive_alerts)}")
        
        return {
            "success": True,
            "our_domain": our_domain,
            "monitoring_period_days": monitoring_period,
            "competitors_monitored": len(competitors),
            "competitor_changes": competitor_changes,
            "significant_changes": significant_changes,
            "market_trend_analysis": market_trend_analysis,
            "competitive_alerts": competitive_alerts,
            "response_recommendations": response_recommendations,
            "trend_predictions": trend_predictions,
            "monitoring_summary": self._create_monitoring_summary(competitor_changes, significant_changes),
            "agent": self.name,
            "confidence": round(random.uniform(0.82, 0.94), 2)
        }

    async def _comprehensive_competitive_analysis(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)"""
        analysis_data = task_data.get('input_data', task_data.get('analysis_data', {}))
        our_domain = analysis_data.get('our_domain', analysis_data.get('domain', 'example.com'))
        industry = analysis_data.get('industry', 'general')
        
        # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ (—Å–∏–º—É–ª—è—Ü–∏—è)
        discovered_competitors = [f"competitor{i}.{random.choice(['com', 'ru', 'org'])}" for i in range(1, 6)]
        
        # –ó–∞–ø—É—Å–∫ –∫–ª—é—á–µ–≤—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤
        serp_analysis = await self._analyze_serp_landscape({
            'query_data': {
                'keywords': [f'{industry} —É—Å–ª—É–≥–∏', f'{industry} –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏', 'SEO –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è'],
                'our_domain': our_domain
            }
        })
        
        gap_analysis = await self._analyze_competitor_gaps({
            'competitor_data': {
                'competitors': discovered_competitors,
                'our_domain': our_domain
            }
        })
        
        market_share = await self._analyze_market_share({
            'market_data': {
                'our_domain': our_domain,
                'industry': industry,
                'competitors': discovered_competitors
            }
        })
        
        # –û–±—â–∞—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        competitive_score = self._calculate_overall_competitive_score(
            serp_analysis, gap_analysis, market_share
        )
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã
        strategic_priorities = self._determine_competitive_priorities(
            competitive_score, serp_analysis, gap_analysis, market_share
        )
        
        # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
        action_roadmap = self._create_competitive_action_roadmap(
            strategic_priorities, serp_analysis, gap_analysis
        )
        
        logger.info(f"üéØ Comprehensive Competitive Analysis –¥–ª—è {our_domain}:")
        logger.info(f"   üìä Competitive Score: {competitive_score}/100")
        logger.info(f"   üìà Market Position: #{market_share['market_position']}")
        logger.info(f"   üöÄ Strategic Priorities: {len(strategic_priorities)}")
        
    async def _fallback_competitive_analysis(self, input_data: Dict[str, Any], task_type: str) -> Dict[str, Any]:
        """Fallback –ª–æ–≥–∏–∫–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –±–µ–∑ LLM"""
        try:
            our_domain = input_data.get('our_domain', input_data.get('domain', 'unknown-domain.com'))
            industry = input_data.get('industry', 'general')
            competitors = input_data.get('competitors', ['competitor1.com', 'competitor2.com'])
            
            # –ë–∞–∑–æ–≤—ã–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–π —Å–∫–æ—Ä
            base_score = 55  # –°—Ä–µ–¥–Ω–∏–π —Å–∫–æ—Ä
            
            # –ü—Ä–æ—Å—Ç—ã–µ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö
            current_da = input_data.get('domain_authority', 0)
            if current_da > 60:
                base_score += 20
            elif current_da > 40:
                base_score += 10
            elif current_da > 20:
                base_score += 5
            
            organic_traffic = input_data.get('organic_traffic', 0)
            if organic_traffic > 100000:
                base_score += 15
            elif organic_traffic > 50000:
                base_score += 10
            elif organic_traffic > 10000:
                base_score += 5
            
            # –û—Ç—Ä–∞—Å–ª–µ–≤—ã–µ –±–æ–Ω—É—Å—ã
            industry_bonuses = {
                'fintech': 8,
                'ecommerce': 6,
                'b2b_services': 5,
                'healthcare': 4
            }
            base_score += industry_bonuses.get(industry.lower(), 0)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–µ –∑–¥–æ—Ä–æ–≤—å–µ
            if base_score >= 80:
                health = "Excellent"
                market_position = random.randint(1, 3)
                visibility = random.uniform(15, 30)
            elif base_score >= 65:
                health = "Good"
                market_position = random.randint(2, 5)
                visibility = random.uniform(10, 20)
            elif base_score >= 50:
                health = "Needs Improvement"
                market_position = random.randint(4, 8)
                visibility = random.uniform(5, 15)
            elif base_score >= 35:
                health = "Poor"
                market_position = random.randint(6, 12)
                visibility = random.uniform(2, 8)
            else:
                health = "Critical"
                market_position = random.randint(10, 20)
                visibility = random.uniform(1, 5)
            
            # –ë–∞–∑–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            recommendations = [
                "–ü—Ä–æ–≤–µ—Å—Ç–∏ SERP –∞–Ω–∞–ª–∏–∑ –ø–æ –∫–ª—é—á–µ–≤—ã–º –∑–∞–ø—Ä–æ—Å–∞–º",
                "–ê–Ω–∞–ª–∏–∑ —Å–ª–∞–±—ã—Ö –º–µ—Å—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤",
                "–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏–∑–º–µ–Ω–µ–Ω–∏–π —É –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤"
            ]
            
            if base_score < 50:
                recommendations.insert(0, "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)")
            
            # –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
            opportunities = [
                f"–ê–Ω–∞–ª–∏–∑ {len(competitors)} –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–ª–∞–±—ã—Ö –º–µ—Å—Ç",
                "–ó–∞—Ö–≤–∞—Ç featured snippets –Ω–∞ –Ω–∏–∑–∫–æ–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö",
                "–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤ –Ω–µ–¥–æ–æ—Å–≤–µ—â–µ–Ω–Ω—ã—Ö –Ω–∏—à–∞—Ö"
            ]
            
            return {
                "success": True,
                "agent": self.agent_id,
                "result": {
                    "competitive_analysis_score": base_score,
                    "competitive_health": health,
                    "our_domain": our_domain,
                    "industry": industry,
                    "market_position": market_position,
                    "visibility_share": round(visibility, 1),
                    "competitors_analyzed": len(competitors),
                    "main_competitors": competitors[:3],
                    "strategic_recommendations": recommendations,
                    "opportunities": opportunities,
                    "note": "–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª—É—á–µ–Ω –±–µ–∑ OpenAI (fallback —Ä–µ–∂–∏–º)",
                    "analysis_scope": {
                        "serp_monitoring": f"–¢–û–ü-{self.serp_monitoring_depth} –ø–æ–∑–∏—Ü–∏–π",
                        "max_competitors": self.max_competitors,
                        "keyword_tracking": self.keyword_tracking_limit
                    }
                },
                "fallback_mode": True,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "success": False,
                "agent": self.agent_id,
                "error": f"Fallback competitive analysis failed: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }

        return {
            "success": True,
            "our_domain": our_domain,
            "industry": industry,
            "competitive_score": competitive_score,
            "market_position": market_share["market_position"],
            "visibility_share": market_share["our_visibility_share"],
            "serp_analysis_summary": {
                "keywords_analyzed": serp_analysis["keywords_analyzed"],
                "serp_feature_ownership": serp_analysis["serp_feature_ownership"],
                "high_priority_opportunities": len(serp_analysis["high_priority_opportunities"])
            },
            "gap_analysis_summary": {
                "competitors_analyzed": gap_analysis["competitors_analyzed"],
                "competitive_advantage_score": gap_analysis["competitive_advantage_score"]
            },
            "strategic_priorities": strategic_priorities,
            "action_roadmap": action_roadmap,
            "competitive_health": self._assess_competitive_health(competitive_score),
            "agent": self.name,
            "confidence": round(random.uniform(0.80, 0.93), 2)
        }

    # Helper methods

    def _generate_serp_data(self, keyword: str, our_domain: str) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è SERP –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞"""
        search_volume = random.randint(1000, 50000)
        difficulty = random.randint(30, 95)
        our_position = random.randint(1, 50) if random.random() > 0.3 else None
        
        # –¢–æ–ø –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã
        top_competitors = []
        for i in range(10):
            top_competitors.append({
                "domain": f"competitor-{i+1}.{random.choice(['com', 'ru', 'org'])}",
                "position": i + 1,
                "title": f"–ü—Ä–∏–º–µ—Ä –∑–∞–≥–æ–ª–æ–≤–∫–∞ –¥–ª—è {keyword}",
                "url": f"https://competitor-{i+1}.com/page-{i+1}",
                "snippet": f"–û–ø–∏—Å–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è {keyword}..."
            })
        
        # SERP features
        serp_features = []
        possible_features = list(self.serp_feature_values.keys())
        num_features = random.randint(1, 4)
        
        for feature in random.sample(possible_features, num_features):
            owned_by_us = our_position and our_position <= 5 and random.random() < 0.3
            serp_features.append({
                "type": feature,
                "owned_by_us": owned_by_us,
                "current_owner": our_domain if owned_by_us else f"competitor-{random.randint(1, 5)}.com",
                "opportunity_score": random.randint(60, 95) if not owned_by_us else 0
            })
        
        # –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
        opportunities = []
        for feature in serp_features:
            if not feature["owned_by_us"] and feature["opportunity_score"] > 70:
                opportunities.append({
                    "type": feature["type"],
                    "description": f"–ó–∞—Ö–≤–∞—Ç {feature['type']} –¥–ª—è '{keyword}'",
                    "priority": "high" if feature["opportunity_score"] > 85 else "medium",
                    "traffic_potential": int(search_volume * self.serp_feature_values[feature["type"]]["traffic_impact"])
                })
        
        return {
            "search_volume": search_volume,
            "difficulty": difficulty,
            "our_position": our_position,
            "top_competitors": top_competitors,
            "serp_features": serp_features,
            "opportunities": opportunities,
            "competitive_intensity": self._calculate_competitive_intensity(top_competitors, difficulty)
        }

    def _calculate_competitive_intensity(self, competitors: List[Dict], difficulty: int) -> str:
        """–†–∞—Å—á–µ—Ç –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏–∏"""
        # –ê–Ω–∞–ª–∏–∑ –¥–æ–º–µ–Ω–æ–≤ –≤ —Ç–æ–ø–µ
        high_authority_domains = sum(1 for c in competitors[:5] if 'gov' in c['domain'] or 'edu' in c['domain'])
        
        if difficulty > 80 or high_authority_domains >= 2:
            return "very_high"
        elif difficulty > 60 or high_authority_domains >= 1:
            return "high"
        elif difficulty > 40:
            return "medium"
        else:
            return "low"

    def _get_serp_strategy_recommendations(self, serp_results: List[Dict], feature_ownership: float) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ SERP —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""
        recommendations = []
        
        if feature_ownership < 20:
            recommendations.append("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–æ–µ –≤–ª–∞–¥–µ–Ω–∏–µ SERP features - —Ç—Ä–µ–±—É–µ—Ç—Å—è –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è")
        
        high_volume_opportunities = [
            r for r in serp_results 
            if r['search_volume'] > 10000 and any(o['priority'] == 'high' for o in r['opportunities'])
        ]
        
        if high_volume_opportunities:
            recommendations.append(f"–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞ {len(high_volume_opportunities)} –≤—ã—Å–æ–∫–æ–æ–±—ä–µ–º–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π")
        
        featured_snippet_opps = sum(
            1 for r in serp_results 
            for o in r['opportunities'] 
            if o['type'] == 'featured_snippets'
        )
        
        if featured_snippet_opps >= 3:
            recommendations.append("–°–∏–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ featured snippets")
        
        return recommendations

    def _summarize_competitive_landscape(self, serp_results: List[Dict]) -> Dict[str, Any]:
        """–°—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ –ª–∞–Ω–¥—à–∞—Ñ—Ç–∞"""
        total_keywords = len(serp_results)
        our_rankings = sum(1 for r in serp_results if r['our_position'] and r['our_position'] <= 10)
        avg_difficulty = sum(r['difficulty'] for r in serp_results) / total_keywords
        
        return {
            "total_keywords_analyzed": total_keywords,
            "our_top10_rankings": our_rankings,
            "ranking_percentage": round((our_rankings / total_keywords) * 100, 1),
            "average_keyword_difficulty": round(avg_difficulty, 1),
            "high_competition_keywords": sum(1 for r in serp_results if r['competitive_intensity'] in ['high', 'very_high']),
            "opportunity_keywords": sum(len(r['opportunities']) for r in serp_results)
        }

    def _generate_competitor_profile(self, competitor_domain: str) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ—Ñ–∏–ª—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞"""
        return {
            "domain": competitor_domain,
            "domain_authority": random.randint(35, 80),
            "organic_keywords": random.randint(5000, 50000),
            "organic_traffic": random.randint(50000, 500000),
            "backlinks": random.randint(10000, 200000),
            "referring_domains": random.randint(500, 5000),
            "content_volume": random.randint(500, 5000),
            "technical_score": random.randint(60, 95),
            "site_speed": random.uniform(1.5, 4.0),
            "mobile_score": random.randint(70, 100),
            "social_presence": random.randint(1000, 100000),
            "brand_strength": random.randint(40, 90)
        }

    def _identify_keyword_gaps(self, competitor_profile: Dict[str, Any]) -> List[Dict]:
        """–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è keyword gaps"""
        gaps = []
        
        # –°–∏–º—É–ª—è—Ü–∏—è keyword gaps
        for i in range(random.randint(10, 30)):
            gaps.append({
                "keyword": f"keyword-gap-{i+1}",
                "search_volume": random.randint(500, 20000),
                "difficulty": random.randint(20, 70),
                "competitor_position": random.randint(1, 10),
                "our_opportunity": random.choice(["high", "medium", "low"]),
                "estimated_traffic": random.randint(100, 5000)
            })
        
        return sorted(gaps, key=lambda x: x['estimated_traffic'], reverse=True)

    def _identify_competitor_content_gaps(self, competitor_profile: Dict[str, Any]) -> List[Dict]:
        """–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö gaps —É –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞"""
        return [
            {
                "gap_type": "topic_depth",
                "description": "–ü–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–Ω–æ–µ –æ—Å–≤–µ—â–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã—Ö —Ç–µ–º",
                "opportunity": "–°–æ–∑–¥–∞—Ç—å –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–∏–π —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç",
                "priority": "high"
            },
            {
                "gap_type": "content_format",
                "description": "–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤",
                "opportunity": "–î–æ–±–∞–≤–∏—Ç—å –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä—ã –∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã",
                "priority": "medium"
            },
            {
                "gap_type": "update_frequency",
                "description": "–†–µ–¥–∫–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞",
                "opportunity": "–†–µ–≥—É–ª—è—Ä–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
                "priority": "medium"
            }
        ]

    def _identify_technical_gaps(self, competitor_profile: Dict[str, Any]) -> List[Dict]:
        """–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö gaps"""
        gaps = []
        
        if competitor_profile["site_speed"] > 3.0:
            gaps.append({
                "gap_type": "site_speed",
                "current_performance": f"{competitor_profile['site_speed']:.1f}s",
                "opportunity": "–ü—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ –≤ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∑–∫–∏",
                "priority": "high"
            })
        
        if competitor_profile["mobile_score"] < 90:
            gaps.append({
                "gap_type": "mobile_optimization",
                "current_performance": f"{competitor_profile['mobile_score']}/100",
                "opportunity": "–õ—É—á—à–∏–π mobile experience",
                "priority": "medium"
            })
        
        return gaps

    def _identify_backlink_gaps(self, competitor_profile: Dict[str, Any]) -> List[Dict]:
        """–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è backlink gaps"""
        return [
            {
                "gap_type": "industry_publications",
                "description": "–°–ª–∞–±–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤ –æ—Ç—Ä–∞—Å–ª–µ–≤—ã—Ö –∏–∑–¥–∞–Ω–∏—è—Ö",
                "opportunity": "PR –∏ guest posting –≤ –Ω–∏—à–µ–≤—ã—Ö –º–µ–¥–∏–∞",
                "priority": "high"
            },
            {
                "gap_type": "local_citations",
                "description": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ–∫ –ª–æ–∫–∞–ª—å–Ω—ã—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π",
                "opportunity": "–õ–æ–∫–∞–ª—å–Ω—ã–π link building",
                "priority": "medium"
            }
        ]

    def _calculate_competitor_strength(self, competitor_profile: Dict[str, Any]) -> Dict[str, Any]:
        """–†–∞—Å—á–µ—Ç —Å–∏–ª—ã –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞"""
        # –í–µ—Å–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤
        weights = {
            "organic_performance": 0.30,
            "technical_performance": 0.25,
            "authority_signals": 0.25,
            "brand_strength": 0.20
        }
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ (0-100)
        organic_score = min(100, (competitor_profile["organic_traffic"] / 10000))
        technical_score = competitor_profile["technical_score"]
        authority_score = min(100, (competitor_profile["domain_authority"] / 80) * 100)
        brand_score = competitor_profile["brand_strength"]
        
        # –û–±—â–∏–π –±–∞–ª–ª
        overall_strength = (
            organic_score * weights["organic_performance"] +
            technical_score * weights["technical_performance"] + 
            authority_score * weights["authority_signals"] +
            brand_score * weights["brand_strength"]
        )
        
        return {
            "overall_strength": round(overall_strength, 1),
            "organic_performance": round(organic_score, 1),
            "technical_performance": round(technical_score, 1),
            "authority_signals": round(authority_score, 1),
            "brand_strength": round(brand_score, 1),
            "strength_tier": self._categorize_strength(overall_strength)
        }

    def _categorize_strength(self, strength_score: float) -> str:
        """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è —Å–∏–ª—ã –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞"""
        if strength_score >= 80:
            return "dominant"
        elif strength_score >= 65:
            return "strong"
        elif strength_score >= 50:
            return "moderate"
        else:
            return "weak"

    def _identify_overtaking_opportunities(self, competitor_profile: Dict, keyword_gaps: List, content_gaps: List, technical_gaps: List) -> List[Dict]:
        """–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –¥–ª—è –æ–±–≥–æ–Ω–∞"""
        opportunities = []
        
        # –ù–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö gaps
        for gap in technical_gaps:
            if gap["priority"] == "high":
                opportunities.append({
                    "type": "technical_advantage",
                    "description": f"–û–±–≥–æ–Ω —á–µ—Ä–µ–∑ {gap['gap_type']}",
                    "timeline": "2-4 months",
                    "investment_required": "medium",
                    "success_probability": 0.75
                })
        
        # –ù–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö gaps
        high_content_gaps = [g for g in content_gaps if g["priority"] == "high"]
        if high_content_gaps:
            opportunities.append({
                "type": "content_superiority",
                "description": "–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—â–µ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞",
                "timeline": "3-6 months",
                "investment_required": "high",
                "success_probability": 0.65
            })
        
        return opportunities

    def _assess_competitor_threat_level(self, strength: Dict, profile: Dict) -> str:
        """–û—Ü–µ–Ω–∫–∞ —É—Ä–æ–≤–Ω—è —É–≥—Ä–æ–∑—ã –æ—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞"""
        if strength["overall_strength"] >= 80 and profile["organic_traffic"] > 200000:
            return "critical"
        elif strength["overall_strength"] >= 65:
            return "high"
        elif strength["overall_strength"] >= 50:
            return "medium"
        else:
            return "low"

    # Additional helper methods for other analyses...
    # (–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ helper methods –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π)

    def _analyze_market_dynamics(self, competitor_analysis: List[Dict]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏ —Ä—ã–Ω–∫–∞"""
        return {
            "market_concentration": "fragmented",  # –∏–ª–∏ "concentrated"
            "dominant_players": sum(1 for c in competitor_analysis if c["competitor_strength"]["strength_tier"] == "dominant"),
            "emerging_threats": sum(1 for c in competitor_analysis if c["threat_level"] in ["high", "critical"]),
            "market_opportunity": "–ï—Å—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —Ä–æ—Å—Ç–∞ –¥–æ–ª–∏ —Ä—ã–Ω–∫–∞"
        }

    def _formulate_gap_strategy(self, competitor_analysis: List, market_dynamics: Dict) -> List[str]:
        """–§–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ gaps"""
        return [
            "–°—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞—Ö",
            "–†–∞–∑–≤–∏–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–æ–µ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ",
            "–£—Å–∏–ª–∏—Ç—å link building —Å—Ç—Ä–∞—Ç–µ–≥–∏—é",
            "–ò–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ brand building"
        ]

    def _prioritize_competitive_actions(self, competitor_analysis: List) -> List[Dict]:
        """–ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π"""
        actions = []
        
        for analysis in competitor_analysis:
            for opp in analysis["overtaking_opportunities"]:
                actions.append({
                    "competitor": analysis["competitor_domain"],
                    "action": opp["description"],
                    "priority": "high" if opp["success_probability"] > 0.7 else "medium",
                    "timeline": opp["timeline"],
                    "investment": opp["investment_required"]
                })
        
        return sorted(actions, key=lambda x: (x["priority"] == "high", x.get("success_probability", 0)), reverse=True)

    def _calculate_our_competitive_advantage(self, competitor_analysis: List) -> int:
        """–†–∞—Å—á–µ—Ç –Ω–∞—à–µ–≥–æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞"""
        # –°–∏–º—É–ª—è—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
        avg_competitor_strength = sum(
            c["competitor_strength"]["overall_strength"] 
            for c in competitor_analysis
        ) / len(competitor_analysis)
        
        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –Ω–∞—à —É—Ä–æ–≤–µ–Ω—å
        our_estimated_strength = random.uniform(50, 75)
        
        if our_estimated_strength > avg_competitor_strength:
            return int(60 + (our_estimated_strength - avg_competitor_strength))
        else:
            return int(40 - (avg_competitor_strength - our_estimated_strength))

    def _analyze_topic_content_landscape(self, topic: str, competitors: List[str], our_domain: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ª–∞–Ω–¥—à–∞—Ñ—Ç–∞ –ø–æ —Ç–µ–º–µ"""
        return {
            "topic": topic,
            "competitor_content_volume": random.randint(50, 300),
            "avg_content_quality": random.randint(60, 85),
            "content_gaps": [
                {
                    "type": "depth_analysis",
                    "opportunity": f"–ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ {topic}",
                    "competitor_performance": random.randint(60, 80),
                    "our_potential": random.randint(80, 95),
                    "priority": "high",
                    "traffic_potential": random.randint(5000, 25000),
                    "production_cost": random.randint(50000, 200000),
                    "timeline": "2-4 weeks"
                },
                {
                    "type": "interactive_content",
                    "opportunity": f"–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è {topic}",
                    "competitor_performance": random.randint(20, 50),
                    "our_potential": random.randint(70, 90),
                    "priority": "medium",
                    "traffic_potential": random.randint(3000, 15000),
                    "production_cost": random.randint(100000, 400000),
                    "timeline": "4-8 weeks"
                }
            ],
            "market_saturation": random.choice(["low", "medium", "high"])
        }

    def _develop_content_gap_strategy(self, content_gaps: List[Dict], landscape: List[Dict]) -> Dict[str, Any]:
        """–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö gaps"""
        return {
            "primary_focus": "–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—â–µ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞",
            "content_types_priority": ["interactive_tools", "expert_analysis", "comprehensive_guides"],
            "investment_allocation": {
                "high_priority": "60%",
                "medium_priority": "30%", 
                "experimental": "10%"
            },
            "timeline": "6 months –¥–ª—è –ø–æ–ª–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏",
            "success_metrics": ["organic_traffic", "engagement_rate", "backlinks_earned"]
        }

    def _analyze_content_gaps_roi(self, content_gaps: List[Dict]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ ROI –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π"""
        total_investment = sum(gap['production_cost'] for gap in content_gaps)
        total_traffic_potential = sum(gap['estimated_traffic'] for gap in content_gaps)
        
        return {
            "total_investment_required": total_investment,
            "total_traffic_potential": total_traffic_potential,
            "estimated_conversion_value": total_traffic_potential * 50,  # 50‚ÇΩ –∑–∞ –≤–∏–∑–∏—Ç
            "roi_percentage": ((total_traffic_potential * 50 * 12 - total_investment) / total_investment) * 100,
            "payback_period_months": total_investment / (total_traffic_potential * 50),
            "risk_assessment": "medium"
        }

    def _calculate_content_gap_resources(self, content_gaps: List[Dict]) -> Dict[str, Any]:
        """–†–∞—Å—á–µ—Ç —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö gaps"""
        return {
            "content_creators_needed": max(1, len(content_gaps) // 10),
            "designers_needed": max(1, len([g for g in content_gaps if 'interactive' in g['gap_type']]) // 5),
            "developers_needed": len([g for g in content_gaps if 'tool' in g.get('gap_type', '')]),
            "total_man_hours": sum(40 if 'interactive' in g.get('gap_type', '') else 20 for g in content_gaps),
            "external_expertise_required": len([g for g in content_gaps if g.get('priority') == 'high'])
        }

    def _generate_competitor_changes(self, competitor: str, period_days: int) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥"""
        return {
            "ranking_changes": {
                "keywords_gained": random.randint(0, 50),
                "keywords_lost": random.randint(0, 30),
                "avg_position_change": random.uniform(-2.5, 3.0),
                "top10_changes": random.randint(-5, 10)
            },
            "content_changes": {
                "new_pages_published": random.randint(0, 20),
                "pages_updated": random.randint(5, 50),
                "content_quality_change": random.uniform(-0.5, 1.5)
            },
            "technical_changes": {
                "site_speed_change": random.uniform(-0.5, 0.8),
                "mobile_score_change": random.randint(-5, 10),
                "core_web_vitals_change": random.uniform(-0.2, 0.5)
            },
            "backlink_changes": {
                "new_backlinks": random.randint(10, 200),
                "lost_backlinks": random.randint(5, 50),
                "da_change": random.randint(-2, 3),
                "referring_domains_change": random.randint(-5, 25)
            },
            "serp_feature_changes": {
                "features_gained": random.randint(0, 5),
                "features_lost": random.randint(0, 3),
                "featured_snippets_change": random.randint(-2, 3)
            }
        }

    def _assess_change_significance(self, changes: Dict[str, Any]) -> Dict[str, Any]:
        """–û—Ü–µ–Ω–∫–∞ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
        significance_score = 0
        primary_change = "none"
        
        # –û—Ü–µ–Ω–∫–∞ ranking changes
        if changes["ranking_changes"]["keywords_gained"] > 30:
            significance_score += 3
            primary_change = "ranking_improvement"
        
        # –û—Ü–µ–Ω–∫–∞ content changes
        if changes["content_changes"]["new_pages_published"] > 15:
            significance_score += 2
            if primary_change == "none":
                primary_change = "content_expansion"
        
        # –û—Ü–µ–Ω–∫–∞ backlink changes
        if changes["backlink_changes"]["new_backlinks"] > 100:
            significance_score += 3
            if primary_change == "none":
                primary_change = "link_building_campaign"
        
        overall_significance = min(10, significance_score)
        
        return {
            "overall_significance": overall_significance,
            "primary_change_type": primary_change,
            "impact_level": "high" if overall_significance >= 7 else "medium" if overall_significance >= 4 else "low",
            "description": f"Competitor showing {primary_change} with significance {overall_significance}/10",
            "response_required": overall_significance >= 6
        }

    def _assess_competitor_threat(self, changes: Dict, significance: Dict) -> str:
        """–û—Ü–µ–Ω–∫–∞ —É–≥—Ä–æ–∑—ã –æ—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞"""
        if significance["overall_significance"] >= 8:
            return "immediate_threat"
        elif significance["overall_significance"] >= 6:
            return "monitoring_required"
        elif significance["overall_significance"] >= 4:
            return "watch_closely"
        else:
            return "low_concern"

    def _analyze_competitive_trends(self, competitor_changes: List[Dict]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤"""
        return {
            "market_activity_level": "high" if len([c for c in competitor_changes if c["change_significance"]["overall_significance"] >= 6]) > 2 else "moderate",
            "dominant_strategy": "content_marketing",  # –ù–∞–∏–±–æ–ª–µ–µ –ø–æ–ø—É–ª—è—Ä–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
            "emerging_tactics": ["interactive_content", "video_marketing", "ai_tools"],
            "market_consolidation": False,
            "innovation_rate": "accelerating"
        }

    def _generate_competitive_alerts(self, significant_changes: List[Dict]) -> List[Dict]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã—Ö –∞–ª–µ—Ä—Ç–æ–≤"""
        alerts = []
        for change in significant_changes:
            if change["impact_level"] == "high":
                alerts.append({
                    "alert_type": "competitor_threat",
                    "competitor": change["competitor"],
                    "severity": "high",
                    "description": change["description"],
                    "action_required": "immediate_response",
                    "deadline": "7 days"
                })
        return alerts

    def _generate_response_recommendations(self, significant_changes: List, trends: Dict) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —Ä–µ–∞–≥–∏—Ä–æ–≤–∞–Ω–∏—é"""
        recommendations = []
        
        if trends["market_activity_level"] == "high":
            recommendations.append("–£–≤–µ–ª–∏—á–∏—Ç—å —á–∞—Å—Ç–æ—Ç—É –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤")
        
        for change in significant_changes:
            if change["our_response_needed"]:
                recommendations.append(f"–û—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –¥–µ–π—Å—Ç–≤–∏—è {change['competitor']}: {change['change_type']}")
        
        return recommendations

    def _predict_competitive_trends(self, competitor_changes: List) -> Dict[str, Any]:
        """–ü—Ä–æ–≥–Ω–æ–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤"""
        return {
            "next_30_days": "–û–∂–∏–¥–∞–µ—Ç—Å—è —É—Å–∏–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–æ–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏–∏",
            "next_90_days": "–í–æ–∑–º–æ–∂–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ link building –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏",
            "key_risks": ["–ù–æ–≤—ã–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã", "–ò–∑–º–µ–Ω–µ–Ω–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤", "–†–æ—Å—Ç —Ä–µ–∫–ª–∞–º–Ω—ã—Ö —Ä–∞—Å—Ö–æ–¥–æ–≤"],
            "opportunities": ["Gaps –≤ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏", "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞", "–ù–∏—à–µ–≤—ã–µ keywords"]
        }

    def _create_monitoring_summary(self, competitor_changes: List, significant_changes: List) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–∫–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
        return {
            "total_competitors_monitored": len(competitor_changes),
            "significant_changes_detected": len(significant_changes),
            "immediate_threats": len([c for c in significant_changes if c["impact_level"] == "high"]),
            "monitoring_health": "active",
            "data_freshness": "real_time"
        }

    def _calculate_overall_competitive_score(self, serp: Dict, gaps: Dict, market: Dict) -> int:
        """–†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ —Å–∫–æ—Ä–∞"""
        # –í–µ—Å–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        serp_weight = 0.4
        gaps_weight = 0.35
        market_weight = 0.25
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–∫–æ—Ä–æ–≤
        serp_score = min(100, serp["serp_feature_ownership"] * 2 + len(serp["high_priority_opportunities"]) * 5)
        gaps_score = gaps["competitive_advantage_score"]
        market_score = (market["our_visibility_share"] / 30) * 100  # Normalize to 30% max
        
        overall = serp_score * serp_weight + gaps_score * gaps_weight + market_score * market_weight
        
        return min(100, int(overall))

    def _determine_competitive_priorities(self, score: int, serp: Dict, gaps: Dict, market: Dict) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤"""
        priorities = []
        
        if score < 50:
            priorities.append("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏")
        
        if serp["serp_feature_ownership"] < 20:
            priorities.append("–ó–∞—Ö–≤–∞—Ç SERP features")
        
        if market["market_position"] > 5:
            priorities.append("–†–æ—Å—Ç –¥–æ–ª–∏ —Ä—ã–Ω–∫–∞")
        
        if len(serp["high_priority_opportunities"]) > 5:
            priorities.append("–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –≤—ã—Å–æ–∫–æ–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π")
        
        return priorities

    def _create_competitive_action_roadmap(self, priorities: List[str], serp: Dict, gaps: Dict) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–æ—Ä–æ–∂–Ω–æ–π –∫–∞—Ä—Ç—ã –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π"""
        return {
            "immediate_actions": priorities[:2],
            "short_term_goals": ["–£–ª—É—á—à–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π", "–ö–æ–Ω—Ç–µ–Ω—Ç–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è"],
            "long_term_strategy": ["–î–æ–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –Ω–∏—à–µ", "–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ market share"],
            "resource_allocation": {
                "content": "40%",
                "technical": "30%",
                "link_building": "20%",
                "monitoring": "10%"
            },
            "timeline": "12 months –¥–ª—è –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–∑–∏—Ü–∏–π"
        }

    def _assess_competitive_health(self, competitive_score: int) -> str:
        """–û—Ü–µ–Ω–∫–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ –∑–¥–æ—Ä–æ–≤—å—è"""
        if competitive_score >= 80:
            return "excellent"
        elif competitive_score >= 60:
            return "good"
        elif competitive_score >= 40:
            return "needs_improvement"
        else:
            return "critical"

    def get_agent_metrics(self) -> AgentMetrics:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞"""
        return AgentMetrics(
            agent_name=self.name,
            agent_type="operational",
            version="1.0.0", 
            status="active",
            total_tasks_processed=getattr(self, '_tasks_processed', 0),
            success_rate=getattr(self, '_success_rate', 0.0),
            average_response_time=getattr(self, '_avg_response_time', 0.0),
            specialized_metrics={
                "max_competitors": self.max_competitors,
                "min_market_share": self.min_market_share,
                "keyword_tracking_limit": self.keyword_tracking_limit,
                "serp_monitoring_depth": self.serp_monitoring_depth
            }
        )