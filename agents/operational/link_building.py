"""
üîó Link Building Agent

Operational-level –∞–≥–µ–Ω—Ç –¥–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –Ω–∞—Ä–∞—â–∏–≤–∞–Ω–∏—è —Å—Å—ã–ª–æ—á–Ω–æ–π –º–∞—Å—Å—ã, outreach automation 
–∏ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å—Å—ã–ª–æ–∫ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–∑–∏—Ü–∏–π –≤ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö.

–û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
- Link prospect identification & scoring
- Outreach automation & templates
- Link quality assessment
- Toxic link detection & disavow
- Competitor backlink analysis
"""

import logging
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
import random

from core.base_agent import BaseAgent
from core.interfaces.data_models import AgentMetrics

logger = logging.getLogger(__name__)


class LinkBuildingAgent(BaseAgent):
    """
    üîó Link Building Agent
    
    Operational-level –∞–≥–µ–Ω—Ç –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å—Å—ã–ª–æ—á–Ω—ã–º –ø—Ä–æ—Ñ–∏–ª–µ–º,
    –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ outreach –∫–∞–º–ø–∞–Ω–∏–π –∏ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å—Å—ã–ª–æ–∫.
    """
    
    def __init__(self, data_provider=None, **kwargs):
        super().__init__(
            agent_id="link_building_agent", 
            name="Link Building Agent",
            data_provider=data_provider,
            **kwargs
        )
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Link Building
        self.min_da_threshold = 30  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π Domain Authority
        self.max_spam_score = 15    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π spam score
        self.min_relevance_score = 70  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å %
        self.target_monthly_links = 25  # –¶–µ–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Å—ã–ª–æ–∫ –≤ –º–µ—Å—è—Ü
        
        # Quality scoring weights
        self.quality_factors = {
            "domain_authority": {"weight": 0.25, "min_threshold": 30},
            "page_authority": {"weight": 0.20, "min_threshold": 25},
            "traffic_volume": {"weight": 0.15, "min_threshold": 5000},
            "content_relevance": {"weight": 0.15, "min_threshold": 70},
            "spam_score": {"weight": 0.10, "max_threshold": 15},
            "trust_flow": {"weight": 0.10, "min_threshold": 20},
            "citation_flow": {"weight": 0.05, "min_threshold": 15}
        }
        
        # Outreach strategies
        self.outreach_strategies = {
            "guest_posting": {"success_rate": 0.20, "avg_da": 50, "cost": 25000},
            "resource_page": {"success_rate": 0.25, "avg_da": 45, "cost": 14000},
            "broken_link_building": {"success_rate": 0.125, "avg_da": 55, "cost": 20000},
            "skyscraper_technique": {"success_rate": 0.10, "avg_da": 60, "cost": 42500},
            "haro_pr": {"success_rate": 0.075, "avg_da": 70, "cost": 7500},
            "digital_pr": {"success_rate": 0.15, "avg_da": 65, "cost": 50000}
        }
        
        logger.info(f"‚úÖ {self.name} –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω:")
        logger.info(f"   üéØ Min DA Threshold: {self.min_da_threshold}")
        logger.info(f"   üö´ Max Spam Score: {self.max_spam_score}")
        logger.info(f"   üìä Min Relevance: {self.min_relevance_score}%")
        logger.info(f"   üîó Monthly Target: {self.target_monthly_links} links")

    async def process_task(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á Link Building Agent
        
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ç–∏–ø—ã –∑–∞–¥–∞—á:
        - link_prospect_analysis: –ê–Ω–∞–ª–∏–∑ –∏ —Å–∫–æ—Ä–∏–Ω–≥ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –¥–æ–Ω–æ—Ä–æ–≤
        - outreach_campaign_planning: –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ outreach –∫–∞–º–ø–∞–Ω–∏–∏
        - link_quality_audit: –ê—É–¥–∏—Ç –∫–∞—á–µ—Å—Ç–≤–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å—Å—ã–ª–æ–∫
        - toxic_link_detection: –í—ã—è–≤–ª–µ–Ω–∏–µ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö —Å—Å—ã–ª–æ–∫
        - competitor_backlink_analysis: –ê–Ω–∞–ª–∏–∑ —Å—Å—ã–ª–æ—á–Ω–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
        """
        task_type = task_data.get('task_type', 'link_prospect_analysis')
        
        try:
            if task_type == 'link_prospect_analysis':
                return await self._analyze_link_prospects(task_data)
            elif task_type == 'outreach_campaign_planning':
                return await self._plan_outreach_campaign(task_data)
            elif task_type == 'link_quality_audit':
                return await self._audit_link_quality(task_data)
            elif task_type == 'toxic_link_detection':
                return await self._detect_toxic_links(task_data)
            elif task_type == 'competitor_backlink_analysis':
                return await self._analyze_competitor_backlinks(task_data)
            else:
                # Default: –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Å—ã–ª–æ—á–Ω–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è
                return await self._comprehensive_link_analysis(task_data)
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ Link Building Agent: {e}")
            return {
                "success": False,
                "error": str(e),
                "agent": self.name
            }

    async def _analyze_link_prospects(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∏ —Å–∫–æ—Ä–∏–Ω–≥ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –¥–æ–Ω–æ—Ä–æ–≤ —Å—Å—ã–ª–æ–∫"""
        domain_data = task_data.get('domain_data', {})
        domain = domain_data.get('domain', 'example.com')
        industry = domain_data.get('industry', 'general')
        
        # –°–∏–º—É–ª—è—Ü–∏—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö prospects
        num_prospects = random.randint(50, 200)
        prospects = []
        
        for i in range(min(num_prospects, 20)):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-20
            prospect = self._generate_prospect_data(industry)
            quality_score = self._calculate_prospect_quality_score(prospect)
            
            prospects.append({
                "domain": f"prospect-{i+1}.{random.choice(['com', 'ru', 'org', 'net'])}",
                "da": prospect["da"],
                "pa": prospect["pa"],
                "spam_score": prospect["spam_score"],
                "traffic": prospect["traffic"],
                "relevance": prospect["relevance"],
                "trust_flow": prospect["trust_flow"],
                "quality_score": quality_score,
                "outreach_strategy": self._recommend_outreach_strategy(prospect),
                "estimated_cost": self._estimate_link_cost(quality_score),
                "success_probability": self._calculate_success_probability(prospect)
            })
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ quality score
        prospects = sorted(prospects, key=lambda x: x['quality_score'], reverse=True)
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è prospects
        premium_prospects = [p for p in prospects if p['quality_score'] >= 80]
        high_quality = [p for p in prospects if 60 <= p['quality_score'] < 80]
        medium_quality = [p for p in prospects if 40 <= p['quality_score'] < 60]
        low_quality = [p for p in prospects if p['quality_score'] < 40]
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        strategy_recommendations = self._get_prospect_strategy_recommendations(
            len(premium_prospects), len(high_quality), len(medium_quality)
        )
        
        logger.info(f"üîç Link Prospect Analysis –¥–ª—è {domain}:")
        logger.info(f"   üìä Total Prospects: {num_prospects}")
        logger.info(f"   üíé Premium Quality: {len(premium_prospects)}")
        logger.info(f"   üéØ High Quality: {len(high_quality)}")
        logger.info(f"   üìà Medium Quality: {len(medium_quality)}")
        
        return {
            "success": True,
            "domain": domain,
            "total_prospects_found": num_prospects,
            "prospects_analyzed": len(prospects),
            "quality_distribution": {
                "premium": len(premium_prospects),
                "high": len(high_quality),
                "medium": len(medium_quality),
                "low": len(low_quality)
            },
            "top_prospects": prospects[:10],
            "strategy_recommendations": strategy_recommendations,
            "estimated_monthly_capacity": self._calculate_monthly_capacity(prospects),
            "agent": self.name,
            "confidence": round(random.uniform(0.75, 0.90), 2)
        }

    async def _plan_outreach_campaign(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ outreach –∫–∞–º–ø–∞–Ω–∏–∏"""
        campaign_data = task_data.get('campaign_data', {})
        budget = campaign_data.get('monthly_budget', random.randint(200000, 1000000))
        target_links = campaign_data.get('target_links', self.target_monthly_links)
        industry = campaign_data.get('industry', 'general')
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –±—é–¥–∂–µ—Ç–∞ –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º
        budget_allocation = self._allocate_outreach_budget(budget)
        
        # –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–º–ø–∞–Ω–∏–π –ø–æ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        campaign_strategies = []
        total_expected_links = 0
        total_outreach_volume = 0
        
        for strategy, allocation in budget_allocation.items():
            strategy_config = self.outreach_strategies[strategy]
            strategy_budget = budget * allocation
            
            expected_links = strategy_budget / strategy_config["cost"]
            outreach_needed = expected_links / strategy_config["success_rate"]
            
            campaign_strategies.append({
                "strategy": strategy,
                "budget_allocation": allocation,
                "budget_amount": int(strategy_budget),
                "expected_links": int(expected_links),
                "outreach_volume": int(outreach_needed),
                "avg_da": strategy_config["avg_da"],
                "success_rate": strategy_config["success_rate"],
                "timeline": self._get_strategy_timeline(strategy)
            })
            
            total_expected_links += expected_links
            total_outreach_volume += outreach_needed
        
        # Timeline planning
        campaign_timeline = self._create_campaign_timeline(campaign_strategies)
        
        # Resource requirements
        resource_requirements = self._calculate_resource_requirements(
            total_outreach_volume, total_expected_links
        )
        
        # Risk assessment
        risk_factors = self._assess_campaign_risks(campaign_strategies, budget)
        
        logger.info(f"üìã Outreach Campaign Planning:")
        logger.info(f"   üí∞ Budget: {budget:,} ‚ÇΩ/–º–µ—Å")
        logger.info(f"   üéØ Target Links: {target_links}")
        logger.info(f"   üìä Expected Links: {int(total_expected_links)}")
        logger.info(f"   üìß Outreach Volume: {int(total_outreach_volume)}")
        
        return {
            "success": True,
            "campaign_budget": budget,
            "target_links": target_links,
            "expected_links": int(total_expected_links),
            "total_outreach_volume": int(total_outreach_volume),
            "budget_allocation": budget_allocation,
            "campaign_strategies": campaign_strategies,
            "timeline": campaign_timeline,
            "resource_requirements": resource_requirements,
            "risk_factors": risk_factors,
            "success_probability": self._calculate_campaign_success_probability(campaign_strategies),
            "agent": self.name,
            "confidence": round(random.uniform(0.70, 0.85), 2)
        }

    async def _audit_link_quality(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ê—É–¥–∏—Ç –∫–∞—á–µ—Å—Ç–≤–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å—Å—ã–ª–æ–∫"""
        domain_data = task_data.get('domain_data', {})
        domain = domain_data.get('domain', 'example.com')
        
        # –°–∏–º—É–ª—è—Ü–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Å—Å—ã–ª–æ—á–Ω–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è
        total_backlinks = random.randint(500, 5000)
        referring_domains = random.randint(100, 800)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Å—ã–ª–æ–∫
        link_analysis = []
        quality_distribution = {"premium": 0, "high": 0, "medium": 0, "low": 0, "toxic": 0}
        
        for i in range(min(referring_domains, 50)):  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ø-50 –¥–æ–º–µ–Ω–æ–≤
            link_data = self._generate_existing_link_data()
            quality_score = self._calculate_link_quality_score(link_data)
            
            if quality_score >= 80:
                quality_tier = "premium"
            elif quality_score >= 60:
                quality_tier = "high"
            elif quality_score >= 40:
                quality_tier = "medium"
            elif quality_score >= 20:
                quality_tier = "low"
            else:
                quality_tier = "toxic"
            
            quality_distribution[quality_tier] += 1
            
            link_analysis.append({
                "referring_domain": f"backlink-{i+1}.{random.choice(['com', 'ru', 'org', 'net'])}",
                "da": link_data["da"],
                "pa": link_data["pa"],
                "spam_score": link_data["spam_score"],
                "trust_flow": link_data["trust_flow"],
                "quality_score": quality_score,
                "quality_tier": quality_tier,
                "link_count": random.randint(1, 5),
                "anchor_text_quality": random.choice(["good", "over-optimized", "natural"]),
                "link_placement": random.choice(["editorial", "footer", "sidebar", "author_bio"]),
                "nofollow": random.choice([True, False])
            })
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ quality score
        link_analysis = sorted(link_analysis, key=lambda x: x['quality_score'], reverse=True)
        
        # –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ—Ñ–∏–ª—è
        avg_da = sum(link['da'] for link in link_analysis) / len(link_analysis)
        avg_quality_score = sum(link['quality_score'] for link in link_analysis) / len(link_analysis)
        
        # Toxic links –¥–ª—è disavow
        toxic_links = [link for link in link_analysis if link['quality_tier'] == 'toxic']
        
        # Health assessment
        link_profile_health = self._assess_link_profile_health(quality_distribution, avg_quality_score)
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
        improvement_recommendations = self._get_link_profile_recommendations(
            quality_distribution, toxic_links, avg_quality_score
        )
        
        logger.info(f"üîó Link Quality Audit –¥–ª—è {domain}:")
        logger.info(f"   üìä Total Backlinks: {total_backlinks:,}")
        logger.info(f"   üåê Referring Domains: {referring_domains}")
        logger.info(f"   üìà Avg DA: {avg_da:.1f}")
        logger.info(f"   üíé Avg Quality Score: {avg_quality_score:.1f}")
        logger.info(f"   üö® Toxic Links: {len(toxic_links)}")
        
        return {
            "success": True,
            "domain": domain,
            "total_backlinks": total_backlinks,
            "referring_domains": referring_domains,
            "avg_da": round(avg_da, 1),
            "avg_quality_score": round(avg_quality_score, 1),
            "quality_distribution": quality_distribution,
            "link_profile_health": link_profile_health,
            "top_quality_links": link_analysis[:10],
            "toxic_links_count": len(toxic_links),
            "toxic_links": toxic_links[:5] if toxic_links else [],
            "improvement_recommendations": improvement_recommendations,
            "disavow_required": len(toxic_links) > 0,
            "agent": self.name,
            "confidence": round(random.uniform(0.80, 0.95), 2)
        }

    async def _detect_toxic_links(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """–í—ã—è–≤–ª–µ–Ω–∏–µ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ –¥–ª—è disavow"""
        domain_data = task_data.get('domain_data', {})
        domain = domain_data.get('domain', 'example.com')
        
        # –°–∏–º—É–ª—è—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö —Å—Å—ã–ª–æ–∫
        total_links_analyzed = random.randint(1000, 8000)
        
        # –†–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã —Ç–æ–∫—Å–∏—á–Ω—ã—Ö —Å—Å—ã–ª–æ–∫
        toxic_categories = {
            "spam_domains": {"count": random.randint(5, 25), "severity": "high"},
            "pbn_networks": {"count": random.randint(2, 15), "severity": "critical"},
            "adult_content": {"count": random.randint(0, 8), "severity": "high"},
            "malware_sites": {"count": random.randint(0, 5), "severity": "critical"},
            "link_farms": {"count": random.randint(3, 20), "severity": "high"},
            "irrelevant_links": {"count": random.randint(10, 50), "severity": "medium"},
            "over_optimization": {"count": random.randint(5, 30), "severity": "medium"}
        }
        
        # –ü–æ–¥—Ä–æ–±–Ω—ã–µ —Ç–æ–∫—Å–∏—á–Ω—ã–µ —Å—Å—ã–ª–∫–∏
        toxic_links = []
        total_toxic = 0
        
        for category, data in toxic_categories.items():
            total_toxic += data["count"]
            for i in range(min(data["count"], 3)):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ 3 –ø—Ä–∏–º–µ—Ä–∞
                toxic_links.append({
                    "referring_domain": f"toxic-{category}-{i+1}.{random.choice(['com', 'ru', 'biz'])}",
                    "category": category,
                    "severity": data["severity"],
                    "spam_score": random.randint(60, 95),
                    "da": random.randint(1, 20),
                    "toxic_signals": self._get_toxic_signals(category),
                    "link_count": random.randint(1, 10),
                    "discovery_date": datetime.now() - timedelta(days=random.randint(1, 180)),
                    "disavow_priority": "immediate" if data["severity"] == "critical" else "next_cycle"
                })
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        priority_order = {"critical": 0, "high": 1, "medium": 2}
        toxic_links = sorted(toxic_links, key=lambda x: priority_order[x['severity']])
        
        # –°–æ–∑–¥–∞–Ω–∏–µ disavow —Ñ–∞–π–ª–∞
        disavow_file_content = self._generate_disavow_file(toxic_links)
        
        # Risk assessment
        penalty_risk = self._assess_penalty_risk(toxic_categories, total_toxic)
        
        # Action plan
        cleanup_action_plan = self._create_cleanup_action_plan(toxic_categories, penalty_risk)
        
        logger.info(f"üö® Toxic Link Detection –¥–ª—è {domain}:")
        logger.info(f"   üìä Links Analyzed: {total_links_analyzed:,}")
        logger.info(f"   ‚ò†Ô∏è Toxic Links Found: {total_toxic}")
        logger.info(f"   üî• Critical Issues: {sum(1 for cat in toxic_categories.values() if cat['severity'] == 'critical')}")
        logger.info(f"   üìà Penalty Risk: {penalty_risk}")
        
        return {
            "success": True,
            "domain": domain,
            "total_links_analyzed": total_links_analyzed,
            "total_toxic_links": total_toxic,
            "toxic_categories": toxic_categories,
            "toxic_links_sample": toxic_links[:15],
            "penalty_risk": penalty_risk,
            "disavow_file_content": disavow_file_content,
            "cleanup_action_plan": cleanup_action_plan,
            "immediate_action_required": penalty_risk in ["high", "critical"],
            "estimated_cleanup_time": f"{random.randint(2, 8)} weeks",
            "agent": self.name,
            "confidence": round(random.uniform(0.85, 0.95), 2)
        }

    async def _analyze_competitor_backlinks(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Å—Å—ã–ª–æ—á–Ω–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤"""
        competitor_data = task_data.get('competitor_data', {})
        competitors = competitor_data.get('competitors', ['competitor1.com', 'competitor2.com'])
        our_domain = competitor_data.get('our_domain', 'example.com')
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞
        competitor_analysis = []
        all_competitor_links = []
        
        for competitor in competitors[:3]:  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–æ 3 –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
            comp_links = random.randint(800, 4000)
            comp_domains = random.randint(150, 900)
            comp_avg_da = random.randint(35, 70)
            
            # –¢–æ–ø —Å—Å—ã–ª–∫–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞
            top_links = []
            for i in range(10):
                link = {
                    "referring_domain": f"comp-{competitor.replace('.', '-')}-link-{i+1}.com",
                    "da": random.randint(40, 85),
                    "pa": random.randint(35, 75),
                    "trust_flow": random.randint(25, 65),
                    "spam_score": random.randint(1, 25),
                    "traffic": random.randint(10000, 500000),
                    "obtainability": random.choice(["easy", "medium", "hard", "impossible"]),
                    "relevance": random.randint(60, 95)
                }
                top_links.append(link)
                all_competitor_links.append(link)
            
            competitor_analysis.append({
                "domain": competitor,
                "total_backlinks": comp_links,
                "referring_domains": comp_domains,
                "avg_da": comp_avg_da,
                "domain_authority": random.randint(45, 80),
                "top_referring_domains": top_links,
                "link_building_velocity": random.randint(20, 100),  # links per month
                "content_strategy": random.choice(["guest_posts", "pr_heavy", "resource_focused", "skyscraper"])
            })
        
        # Gap analysis - —Å—Å—ã–ª–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å —É –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤, –Ω–æ –Ω–µ—Ç —É –Ω–∞—Å
        link_gap_opportunities = self._identify_link_gaps(all_competitor_links, our_domain)
        
        # Content gaps - –∫–æ–Ω—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–∏–≤–ª–µ–∫–∞–µ—Ç —Å—Å—ã–ª–∫–∏ —É –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
        content_gaps = self._identify_content_gaps(competitors)
        
        # Strategy insights
        strategy_insights = self._extract_strategy_insights(competitor_analysis)
        
        # Actionable recommendations
        action_recommendations = self._create_competitor_action_plan(
            link_gap_opportunities, content_gaps, strategy_insights
        )
        
        logger.info(f"üéØ Competitor Backlink Analysis:")
        logger.info(f"   üè¢ Competitors Analyzed: {len(competitors)}")
        logger.info(f"   üîó Gap Opportunities: {len(link_gap_opportunities)}")
        logger.info(f"   üìÑ Content Gaps: {len(content_gaps)}")
        logger.info(f"   üí° Strategy Insights: {len(strategy_insights)}")
        
        return {
            "success": True,
            "our_domain": our_domain,
            "competitors_analyzed": len(competitors),
            "competitor_analysis": competitor_analysis,
            "link_gap_opportunities": link_gap_opportunities[:20],
            "content_gaps": content_gaps,
            "strategy_insights": strategy_insights,
            "action_recommendations": action_recommendations,
            "competitive_advantage_score": self._calculate_competitive_advantage(competitor_analysis),
            "priority_targets": [opp for opp in link_gap_opportunities if opp["priority"] == "high"][:10],
            "agent": self.name,
            "confidence": round(random.uniform(0.75, 0.90), 2)
        }

    async def _comprehensive_link_analysis(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Å—ã–ª–æ—á–Ω–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)"""
        domain_data = task_data.get('input_data', task_data.get('domain_data', {}))
        domain = domain_data.get('domain', 'example.com')
        industry = domain_data.get('industry', 'general')
        
        # –ó–∞–ø—É—Å–∫ –∫–ª—é—á–µ–≤—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤
        prospect_analysis = await self._analyze_link_prospects({'domain_data': domain_data})
        quality_audit = await self._audit_link_quality({'domain_data': domain_data})
        toxic_detection = await self._detect_toxic_links({'domain_data': domain_data})
        
        # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ —Å—Å—ã–ª–æ—á–Ω–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è
        link_profile_score = self._calculate_overall_link_score(
            quality_audit, toxic_detection, prospect_analysis
        )
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        strategic_priorities = self._get_link_building_priorities(
            link_profile_score, quality_audit, toxic_detection, prospect_analysis
        )
        
        # Budget recommendations
        recommended_budget = self._recommend_link_building_budget(
            link_profile_score, prospect_analysis['total_prospects_found']
        )
        
        logger.info(f"üîó Comprehensive Link Analysis –¥–ª—è {domain}:")
        logger.info(f"   üìä Link Profile Score: {link_profile_score}/100")
        logger.info(f"   üéØ Prospects Available: {prospect_analysis['total_prospects_found']}")
        logger.info(f"   üí∞ Recommended Budget: {recommended_budget:,} ‚ÇΩ/–º–µ—Å")
        
        return {
            "success": True,
            "domain": domain,
            "link_profile_score": link_profile_score,
            "current_link_health": quality_audit["link_profile_health"],
            "prospect_opportunities": {
                "total_prospects": prospect_analysis["total_prospects_found"],
                "quality_distribution": prospect_analysis["quality_distribution"]
            },
            "toxic_link_issues": {
                "total_toxic": toxic_detection["total_toxic_links"],
                "penalty_risk": toxic_detection["penalty_risk"],
                "cleanup_required": toxic_detection["immediate_action_required"]
            },
            "strategic_priorities": strategic_priorities,
            "recommended_monthly_budget": recommended_budget,
            "expected_monthly_links": self._calculate_expected_links(recommended_budget),
            "timeline_to_improvement": f"{random.randint(3, 8)} months",
            "agent": self.name,
            "confidence": round(random.uniform(0.80, 0.92), 2)
        }

    # Helper methods

    def _generate_prospect_data(self, industry: str) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö prospect'–∞"""
        return {
            "da": random.randint(25, 85),
            "pa": random.randint(20, 75),
            "spam_score": random.randint(1, 30),
            "traffic": random.randint(3000, 200000),
            "relevance": random.randint(50, 95),
            "trust_flow": random.randint(15, 70),
            "citation_flow": random.randint(10, 65)
        }

    def _calculate_prospect_quality_score(self, prospect: Dict[str, Any]) -> int:
        """–†–∞—Å—á–µ—Ç quality score –¥–ª—è prospect'–∞"""
        score = 0
        
        # Domain Authority (25%)
        da_score = min(100, (prospect["da"] / 80) * 100)
        score += da_score * 0.25
        
        # Page Authority (20%)
        pa_score = min(100, (prospect["pa"] / 70) * 100)
        score += pa_score * 0.20
        
        # Traffic Volume (15%)
        traffic_score = min(100, (prospect["traffic"] / 100000) * 100)
        score += traffic_score * 0.15
        
        # Content Relevance (15%)
        score += prospect["relevance"] * 0.15
        
        # Spam Score (10% - –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)
        spam_penalty = max(0, (30 - prospect["spam_score"]) / 30 * 100)
        score += spam_penalty * 0.10
        
        # Trust Flow (10%)
        tf_score = min(100, (prospect["trust_flow"] / 60) * 100)
        score += tf_score * 0.10
        
        # Citation Flow (5%)
        cf_score = min(100, (prospect["citation_flow"] / 55) * 100)
        score += cf_score * 0.05
        
        return min(100, int(score))

    def _recommend_outreach_strategy(self, prospect: Dict[str, Any]) -> str:
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ outreach –¥–ª—è prospect'–∞"""
        if prospect["da"] >= 70 and prospect["traffic"] >= 50000:
            return "digital_pr"
        elif prospect["da"] >= 50 and prospect["relevance"] >= 80:
            return "guest_posting"
        elif prospect["da"] >= 40:
            return "resource_page"
        elif prospect["relevance"] >= 85:
            return "broken_link_building"
        else:
            return "skyscraper_technique"

    def _estimate_link_cost(self, quality_score: int) -> int:
        """–û—Ü–µ–Ω–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Å—ã–ª–∫–∏"""
        if quality_score >= 80:
            return random.randint(40000, 100000)
        elif quality_score >= 60:
            return random.randint(20000, 40000)
        elif quality_score >= 40:
            return random.randint(8000, 20000)
        else:
            return random.randint(3000, 8000)

    def _calculate_success_probability(self, prospect: Dict[str, Any]) -> float:
        """–†–∞—Å—á–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —É—Å–ø–µ—Ö–∞ outreach"""
        base_rate = 0.15  # 15% –±–∞–∑–æ–≤–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
        
        # –ë–æ–Ω—É—Å—ã
        if prospect["relevance"] >= 85:
            base_rate += 0.10
        if prospect["da"] < 50:
            base_rate += 0.05  # –ú–µ–Ω–µ–µ –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —Å–∞–π—Ç—ã –±–æ–ª–µ–µ –¥–æ—Å—Ç—É–ø–Ω—ã
        if prospect["spam_score"] < 10:
            base_rate += 0.05
        
        # –®—Ç—Ä–∞—Ñ—ã
        if prospect["da"] >= 70:
            base_rate -= 0.05  # –í—ã—Å–æ–∫–æ–∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ —Å–∞–π—Ç—ã –º–µ–Ω–µ–µ –¥–æ—Å—Ç—É–ø–Ω—ã
        if prospect["spam_score"] > 20:
            base_rate -= 0.10
        
        return round(max(0.05, min(0.35, base_rate)), 2)

    def _get_prospect_strategy_recommendations(self, premium: int, high: int, medium: int) -> List[str]:
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞ prospects"""
        recommendations = []
        
        if premium >= 5:
            recommendations.append("Focus on premium prospects with digital PR approach")
        if high >= 10:
            recommendations.append("Strong guest posting opportunities available")
        if medium >= 15:
            recommendations.append("Scale with resource page and broken link building")
        if premium + high < 8:
            recommendations.append("Consider content creation to attract higher-quality prospects")
        
        return recommendations

    def _calculate_monthly_capacity(self, prospects: List[Dict]) -> Dict[str, int]:
        """–†–∞—Å—á–µ—Ç –º–µ—Å—è—á–Ω–æ–π capacity –ø–æ –∫–∞—á–µ—Å—Ç–≤—É prospects"""
        premium = len([p for p in prospects if p['quality_score'] >= 80])
        high = len([p for p in prospects if 60 <= p['quality_score'] < 80])
        medium = len([p for p in prospects if 40 <= p['quality_score'] < 60])
        
        return {
            "premium_links": min(premium, 5),    # –ú–∞–∫—Å–∏–º—É–º 5 –ø—Ä–µ–º–∏—É–º —Å—Å—ã–ª–æ–∫ –≤ –º–µ—Å—è—Ü
            "high_quality_links": min(high, 15), # –ú–∞–∫—Å–∏–º—É–º 15 –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö
            "medium_quality_links": min(medium, 30), # –ú–∞–∫—Å–∏–º—É–º 30 —Å—Ä–µ–¥–Ω–∏—Ö
            "total_realistic_capacity": min(premium, 5) + min(high, 15) + min(medium, 30)
        }

    def _allocate_outreach_budget(self, budget: int) -> Dict[str, float]:
        """–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –±—é–¥–∂–µ—Ç–∞ –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º outreach"""
        if budget >= 800000:  # –ë–æ–ª—å—à–æ–π –±—é–¥–∂–µ—Ç
            return {
                "digital_pr": 0.35,
                "guest_posting": 0.30,
                "skyscraper_technique": 0.20,
                "resource_page": 0.10,
                "haro_pr": 0.05
            }
        elif budget >= 400000:  # –°—Ä–µ–¥–Ω–∏–π –±—é–¥–∂–µ—Ç
            return {
                "guest_posting": 0.40,
                "resource_page": 0.25,
                "digital_pr": 0.20,
                "broken_link_building": 0.15
            }
        else:  # –ù–µ–±–æ–ª—å—à–æ–π –±—é–¥–∂–µ—Ç
            return {
                "resource_page": 0.40,
                "guest_posting": 0.30,
                "broken_link_building": 0.20,
                "haro_pr": 0.10
            }

    def _get_strategy_timeline(self, strategy: str) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ timeline –¥–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""
        timelines = {
            "guest_posting": "4-8 weeks",
            "resource_page": "2-4 weeks", 
            "broken_link_building": "3-6 weeks",
            "skyscraper_technique": "8-12 weeks",
            "haro_pr": "2-8 weeks",
            "digital_pr": "4-10 weeks"
        }
        return timelines.get(strategy, "4-6 weeks")

    def _create_campaign_timeline(self, strategies: List[Dict]) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ timeline –∫–∞–º–ø–∞–Ω–∏–∏"""
        return {
            "week_1_2": "Prospect research and qualification",
            "week_3_4": "Outreach template creation and initial campaigns",
            "week_5_8": "Full outreach execution and follow-ups",
            "week_9_12": "Link placement and monitoring",
            "ongoing": "Relationship nurturing and maintenance"
        }

    def _calculate_resource_requirements(self, outreach_volume: float, expected_links: float) -> Dict[str, Any]:
        """–†–∞—Å—á–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ —Ä–µ—Å—É—Ä—Å–∞–º"""
        return {
            "outreach_specialist_hours": int(outreach_volume * 0.5),  # 30 –º–∏–Ω –Ω–∞ –ø–∏—Å—å–º–æ
            "content_creation_hours": int(expected_links * 4),        # 4 —á–∞—Å–∞ –Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç
            "relationship_management_hours": int(expected_links * 2), # 2 —á–∞—Å–∞ –Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏–µ
            "tools_required": ["Ahrefs", "Pitchbox", "Hunter.io", "BuzzStream"],
            "team_size_recommended": max(1, int(outreach_volume / 200))  # 1 —á–µ–ª–æ–≤–µ–∫ –Ω–∞ 200 –ø–∏—Å–µ–º
        }

    def _assess_campaign_risks(self, strategies: List[Dict], budget: int) -> List[str]:
        """–û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–æ–≤ –∫–∞–º–ø–∞–Ω–∏–∏"""
        risks = []
        
        if budget < 300000:
            risks.append("Limited budget may restrict high-quality opportunities")
        
        total_outreach = sum(s["outreach_volume"] for s in strategies)
        if total_outreach > 500:
            risks.append("High outreach volume may impact personalization quality")
        
        if any(s["success_rate"] < 0.10 for s in strategies):
            risks.append("Some strategies have low success rates")
        
        return risks

    def _calculate_campaign_success_probability(self, strategies: List[Dict]) -> float:
        """–†–∞—Å—á–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —É—Å–ø–µ—Ö–∞ –∫–∞–º–ø–∞–Ω–∏–∏"""
        weighted_success = sum(
            s["success_rate"] * s["budget_allocation"] 
            for s in strategies
        )
        return round(weighted_success, 2)

    # Additional helper methods for other functions would continue here...
    # (–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –¥–ª—è audit_link_quality, detect_toxic_links, etc.)

    def _generate_existing_link_data(self) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å—Å—ã–ª–∫–∏"""
        return {
            "da": random.randint(15, 80),
            "pa": random.randint(10, 70),
            "spam_score": random.randint(1, 50),
            "trust_flow": random.randint(5, 65),
            "citation_flow": random.randint(5, 60)
        }

    def _calculate_link_quality_score(self, link_data: Dict[str, Any]) -> int:
        """–†–∞—Å—á–µ—Ç quality score –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å—Å—ã–ª–∫–∏"""
        return self._calculate_prospect_quality_score(link_data)

    def _assess_link_profile_health(self, quality_dist: Dict, avg_score: float) -> str:
        """–û—Ü–µ–Ω–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å—Å—ã–ª–æ—á–Ω–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è"""
        if avg_score >= 70 and quality_dist.get("toxic", 0) == 0:
            return "excellent"
        elif avg_score >= 50 and quality_dist.get("toxic", 0) <= 5:
            return "good"
        elif avg_score >= 35:
            return "needs_improvement"
        else:
            return "poor"

    def _get_link_profile_recommendations(self, quality_dist: Dict, toxic_links: List, avg_score: float) -> List[str]:
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é —Å—Å—ã–ª–æ—á–Ω–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è"""
        recommendations = []
        
        if toxic_links:
            recommendations.append(f"Immediate disavow of {len(toxic_links)} toxic links required")
        
        if quality_dist.get("premium", 0) < 10:
            recommendations.append("Focus on acquiring high-authority premium links")
        
        if avg_score < 50:
            recommendations.append("Overall link quality improvement needed")
        
        return recommendations

    def _get_toxic_signals(self, category: str) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        signals_map = {
            "spam_domains": ["High spam score", "Low DA", "Excessive outbound links"],
            "pbn_networks": ["PBN footprints", "Similar IP ranges", "Thin content"],
            "adult_content": ["Adult keywords", "Inappropriate content"],
            "malware_sites": ["Security warnings", "Malicious code detected"],
            "link_farms": ["Link exchange schemes", "Reciprocal linking"],
            "irrelevant_links": ["Topic mismatch", "Geographic irrelevance"],
            "over_optimization": ["Exact match anchors", "Keyword stuffing"]
        }
        return signals_map.get(category, ["Suspicious patterns detected"])

    def _generate_disavow_file(self, toxic_links: List[Dict]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ disavow —Ñ–∞–π–ª–∞"""
        content = "# Disavow file generated by AI SEO Architects\n"
        content += f"# Generated on: {datetime.now().strftime('%Y-%m-%d')}\n\n"
        
        for link in toxic_links:
            content += f"domain:{link['referring_domain']}\n"
        
        return content

    def _assess_penalty_risk(self, toxic_categories: Dict, total_toxic: int) -> str:
        """–û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–µ–Ω–∞–ª—å—Ç–∏"""
        critical_count = sum(
            data["count"] for data in toxic_categories.values() 
            if data["severity"] == "critical"
        )
        
        if critical_count > 10 or total_toxic > 100:
            return "critical"
        elif critical_count > 5 or total_toxic > 50:
            return "high"
        elif total_toxic > 20:
            return "medium"
        else:
            return "low"

    def _create_cleanup_action_plan(self, toxic_categories: Dict, penalty_risk: str) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–ª–∞–Ω–∞ –æ—á–∏—Å—Ç–∫–∏ —Å—Å—ã–ª–æ—á–Ω–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è"""
        if penalty_risk == "critical":
            return {
                "timeline": "Immediate (1-2 weeks)",
                "actions": ["Emergency disavow submission", "Manual link removal requests", "Google reconsideration"],
                "priority": "critical",
                "estimated_cost": "100,000-300,000 ‚ÇΩ"
            }
        elif penalty_risk == "high":
            return {
                "timeline": "Urgent (2-4 weeks)",
                "actions": ["Comprehensive disavow file", "Outreach for link removal", "Profile monitoring"],
                "priority": "high", 
                "estimated_cost": "50,000-150,000 ‚ÇΩ"
            }
        else:
            return {
                "timeline": "Standard (4-8 weeks)",
                "actions": ["Regular disavow update", "Gradual cleanup", "Quality improvement focus"],
                "priority": "medium",
                "estimated_cost": "20,000-75,000 ‚ÇΩ"
            }

    def _identify_link_gaps(self, competitor_links: List[Dict], our_domain: str) -> List[Dict]:
        """–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è gap opportunities –≤ —Å—Å—ã–ª–∫–∞—Ö"""
        gaps = []
        for link in competitor_links:
            if link["obtainability"] in ["easy", "medium"]:
                gaps.append({
                    "domain": link["referring_domain"],
                    "da": link["da"],
                    "relevance": link["relevance"],
                    "obtainability": link["obtainability"],
                    "priority": "high" if link["da"] > 60 and link["obtainability"] == "easy" else "medium",
                    "estimated_cost": self._estimate_link_cost(link["da"]),
                    "strategy": self._recommend_outreach_strategy(link)
                })
        return sorted(gaps, key=lambda x: x["da"], reverse=True)

    def _identify_content_gaps(self, competitors: List[str]) -> List[Dict]:
        """–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã—Ö gap'–æ–≤"""
        return [
            {
                "content_type": "Industry Report 2025",
                "competitor_links": random.randint(50, 200),
                "our_opportunity": "Create comprehensive industry analysis",
                "estimated_links": random.randint(80, 300),
                "production_cost": random.randint(300000, 800000)
            },
            {
                "content_type": "Interactive Calculator",
                "competitor_links": random.randint(30, 150),
                "our_opportunity": "Develop specialized tool for industry",
                "estimated_links": random.randint(60, 250),
                "production_cost": random.randint(500000, 1200000)
            }
        ]

    def _extract_strategy_insights(self, competitor_analysis: List[Dict]) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏—Ö –∏–Ω—Å–∞–π—Ç–æ–≤"""
        return [
            "Competitors focus heavily on guest posting strategy",
            "High-authority news sites are common targets",
            "Resource pages in industry are underutilized",
            "Digital PR campaigns show strong results"
        ]

    def _create_competitor_action_plan(self, gaps: List, content_gaps: List, insights: List) -> List[str]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–ª–∞–Ω–∞ –¥–µ–π—Å—Ç–≤–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        return [
            f"Target {len([g for g in gaps if g['priority'] == 'high'])} high-priority gap opportunities",
            f"Develop {len(content_gaps)} linkable content assets",
            "Implement competitor monitoring system",
            "Execute strategic outreach to identified prospects"
        ]

    def _calculate_competitive_advantage(self, competitor_analysis: List[Dict]) -> int:
        """–†–∞—Å—á–µ—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞"""
        our_estimated_da = random.randint(35, 65)
        avg_competitor_da = sum(c["domain_authority"] for c in competitor_analysis) / len(competitor_analysis)
        
        if our_estimated_da > avg_competitor_da:
            return random.randint(60, 85)
        else:
            return random.randint(25, 55)

    def _calculate_overall_link_score(self, quality_audit: Dict, toxic_detection: Dict, prospect_analysis: Dict) -> int:
        """–†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ —Å–∫–æ—Ä–∞ —Å—Å—ã–ª–æ—á–Ω–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è"""
        quality_score = quality_audit["avg_quality_score"]
        toxic_penalty = min(30, toxic_detection["total_toxic_links"] * 0.5)
        prospect_bonus = min(20, prospect_analysis["quality_distribution"]["premium"] * 2)
        
        return max(0, min(100, int(quality_score - toxic_penalty + prospect_bonus)))

    def _get_link_building_priorities(self, profile_score: int, quality_audit: Dict, toxic_detection: Dict, prospect_analysis: Dict) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤ link building"""
        priorities = []
        
        if toxic_detection["immediate_action_required"]:
            priorities.append("Priority 1: Immediate toxic link cleanup")
        
        if profile_score < 50:
            priorities.append("Priority 2: Quality improvement focus")
        
        if prospect_analysis["quality_distribution"]["premium"] > 10:
            priorities.append("Priority 3: Premium prospect targeting")
        
        return priorities

    def _recommend_link_building_budget(self, profile_score: int, total_prospects: int) -> int:
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –±—é–¥–∂–µ—Ç–∞ –Ω–∞ link building"""
        base_budget = 200000  # –ë–∞–∑–æ–≤—ã–π –±—é–¥–∂–µ—Ç
        
        if profile_score < 40:
            base_budget *= 2  # –£–¥–≤–æ–µ–Ω–∏–µ –¥–ª—è –Ω–∏–∑–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        elif profile_score > 70:
            base_budget *= 1.5  # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ prospects
        if total_prospects > 100:
            base_budget *= 1.3
        
        return int(base_budget)

    def _calculate_expected_links(self, budget: int) -> int:
        """–†–∞—Å—á–µ—Ç –æ–∂–∏–¥–∞–µ–º–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Å—ã–ª–æ–∫"""
        avg_cost_per_link = 25000  # –°—Ä–µ–¥–Ω—è—è —Å—Ç–æ–∏–º–æ—Å—Ç—å —Å—Å—ã–ª–∫–∏
        return int(budget / avg_cost_per_link)

    def get_agent_metrics(self) -> AgentMetrics:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞"""
        return AgentMetrics(
            agent_name=self.name,
            agent_type="operational", 
            version="1.0.0",
            status="active",
            total_tasks_processed=getattr(self, '_tasks_processed', 0),
            success_rate=getattr(self, '_success_rate', 0.0),
            average_response_time=getattr(self, '_avg_response_time', 0.0),
            specialized_metrics={
                "min_da_threshold": self.min_da_threshold,
                "max_spam_score": self.max_spam_score,
                "min_relevance_score": self.min_relevance_score,
                "target_monthly_links": self.target_monthly_links
            }
        )