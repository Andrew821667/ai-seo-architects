"""
üìä Reporting Agent

Operational-level –∞–≥–µ–Ω—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–æ–≤, KPI tracking, 
client dashboards –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ SEO –∫–∞–º–ø–∞–Ω–∏–π.

–û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
- Automated reporting & scheduling
- KPI tracking & monitoring
- Client dashboard creation
- Performance analytics & insights
- ROI measurement & attribution
"""

import logging
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
import random

from core.base_agent import BaseAgent
from core.interfaces.data_models import AgentMetrics

logger = logging.getLogger(__name__)


class ReportingAgent(BaseAgent):
    """
    üìä Reporting Agent
    
    Operational-level –∞–≥–µ–Ω—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–æ–≤,
    –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è KPI.
    """
    
    def __init__(self, data_provider=None, agent_level=None, **kwargs):
        # –£–±–∏—Ä–∞–µ–º agent_level –∏–∑ kwargs –µ—Å–ª–∏ –æ–Ω —Ç–∞–º –µ—Å—Ç—å
        if 'agent_level' in kwargs:
            del kwargs['agent_level']
            
        super().__init__(
            agent_id="reporting_agent",
            name="Reporting Agent",
            agent_level=agent_level or "operational",
            data_provider=data_provider,
            knowledge_base="knowledge/operational/reporting.md",
            **kwargs
        )
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Reporting
        self.supported_report_types = [
            "executive_summary", "detailed_performance", "technical_audit", 
            "competitive_intelligence", "roi_analysis"
        ]
        self.kpi_categories = [
            "visibility_metrics", "traffic_metrics", "conversion_metrics", 
            "revenue_metrics", "technical_metrics"
        ]
        self.alert_severity_levels = ["low", "medium", "high", "critical"]
        
        # Report generation settings
        self.max_report_data_points = 1000  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ data points –≤ –æ—Ç—á–µ—Ç–µ
        self.default_time_period = 30  # –î–Ω–µ–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.confidence_threshold = 0.85  # –ü–æ—Ä–æ–≥ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
        
        # Data source weights
        self.data_source_reliability = {
            "google_analytics": 0.95,
            "search_console": 0.90,
            "third_party_tools": 0.80,
            "estimated_data": 0.60
        }
        
        logger.info(f"‚úÖ {self.name} –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω:")
        logger.info(f"   üìä Supported Report Types: {len(self.supported_report_types)}")
        logger.info(f"   üìà KPI Categories: {len(self.kpi_categories)}")
        logger.info(f"   üéØ Confidence Threshold: {self.confidence_threshold}")
        logger.info(f"   üìÖ Default Period: {self.default_time_period} days")
    
    def get_system_prompt(self) -> str:
        """–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è reporting"""
        return f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π Reporting Agent, —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã—Ö SEO –æ—Ç—á—ë—Ç–æ–≤ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.

–¢–í–û–Ø –≠–ö–°–ü–ï–†–¢–ò–ó–ê:
‚Ä¢ SEO Performance Reporting - 30%
‚Ä¢ KPI Analysis & Tracking - 25%
‚Ä¢ ROI & Attribution Modeling - 20%
‚Ä¢ Dashboard Data Preparation - 15%
‚Ä¢ Insights & Recommendations Generation - 10%

–ó–ê–î–ê–ß–ê: –°–æ–∑–¥–∞—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–π, –∏–Ω—Å–∞–π—Ç–Ω—ã–π SEO –æ—Ç—á—ë—Ç —Å –∫–ª—é—á–µ–≤—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏, —Ç—Ä–µ–Ω–¥–∞–º–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏.

–ú–ï–¢–û–î–û–õ–û–ì–ò–Ø –û–¢–ß–Å–¢–û–í:
1. Performance Analysis (30 –±–∞–ª–ª–æ–≤):
   - –û—Ä–≥–∞–Ω–∏—á–µ—Å–∫–∏–π —Ç—Ä–∞—Ñ–∏–∫ dynamics (0-10)
   - –ü–æ–∑–∏—Ü–∏–∏ –∏ visibility trends (0-8)
   - Click-through rates –∞–Ω–∞–ª–∏–∑ (0-6)
   - Impressions –∏ reach metrics (0-6)

2. KPI Tracking (25 –±–∞–ª–ª–æ–≤):
   - Conversion tracking –∏ attribution (0-8)
   - Goal completions analysis (0-7)
   - Revenue –∏ business impact (0-5)
   - User engagement metrics (0-5)

3. ROI & Attribution (20 –±–∞–ª–ª–æ–≤):
   - Cost per acquisition calculations (0-7)
   - Revenue attribution modeling (0-7)
   - ROI –ø–æ –∫–∞–Ω–∞–ª–∞–º –∏ –∫–∞–º–ø–∞–Ω–∏—è–º (0-6)

4. Technical Metrics (15 –±–∞–ª–ª–æ–≤):
   - Site speed –∏ Core Web Vitals (0-5)
   - Crawling –∏ indexing status (0-5)
   - Mobile –∏ accessibility scores (0-5)

5. Insights & Forecasting (10 –±–∞–ª–ª–æ–≤):
   - –¢—Ä–µ–Ω–¥ identification –∏ analysis (0-4)
   - Performance forecasting (0-3)
   - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ prioritization (0-3)

–û–¢–ß–Å–¢–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´:
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ç–∏–ø—ã: {', '.join(self.supported_report_types)}
- KPI –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {', '.join(self.kpi_categories)}
- –ü–µ—Ä–∏–æ–¥ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {self.default_time_period} –¥–Ω–µ–π
- –ü–æ—Ä–æ–≥ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏: {self.confidence_threshold}
- –ú–∞–∫—Å data points: {self.max_report_data_points}

–û–¢–†–ê–°–õ–ï–í–´–ï –ë–û–ù–£–°–´:
‚Ä¢ E-commerce: +15 (conversion & revenue focus)
‚Ä¢ B2B Services: +12 (lead quality & attribution)
‚Ä¢ FinTech: +10 (compliance & security metrics)
‚Ä¢ Healthcare: +8 (trust & authority metrics)
‚Ä¢ Local Business: +6 (local visibility metrics)

–†–ï–ó–£–õ–¨–¢–ê–¢: –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON —Å –ø–æ–ª–Ω—ã–º SEO performance –æ—Ç—á—ë—Ç–æ–º, –∫–ª—é—á–µ–≤—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏, —Ç—Ä–µ–Ω–¥–∞–º–∏ –∏ actionable —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏."""

    async def process_task(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è SEO –æ—Ç—á—ë—Ç–æ–≤ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ LLM –≤—ã–∑–æ–≤–∞–º–∏
        
        Args:
            task_data: –î–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –æ—Ç—á—ë—Ç–∞
            
        Returns:
            Dict —Å –ø–æ–ª–Ω—ã–º SEO performance –æ—Ç—á—ë—Ç–æ–º –æ—Ç OpenAI
        """
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            input_data = task_data.get("input_data", {})
            task_type = task_data.get('task_type', 'comprehensive_performance_report')
            
            logger.info(f"üìä –ù–∞—á–∏–Ω–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç—á—ë—Ç–∞: {input_data.get('domain', 'Unknown')}, —Ç–∏–ø: {task_type}")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è reporting
            user_prompt = f"""–°–æ–∑–¥–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π SEO performance –æ—Ç—á—ë—Ç —Å –≥–ª—É–±–æ–∫–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π:

–î–ê–ù–ù–´–ï –ü–†–û–ï–ö–¢–ê:
Domain: {input_data.get('domain', 'Unknown')}
Industry: {input_data.get('industry', 'Unknown')}
Report Type: {task_type}
Period: {input_data.get('period_days', self.default_time_period)} –¥–Ω–µ–π
Client Type: {input_data.get('client_type', 'General')}

–¢–ï–ö–£–©–ò–ï –ú–ï–¢–†–ò–ö–ò:
Organic Traffic: {input_data.get('organic_traffic', 'N/A')}
Organic Keywords: {input_data.get('organic_keywords', 'N/A')}
Average Position: {input_data.get('avg_position', 'N/A')}
Click-Through Rate: {input_data.get('ctr', 'N/A')}%
Conversions: {input_data.get('conversions', 'N/A')}
Revenue Attribution: {input_data.get('revenue', 'N/A')} ‚ÇΩ
Site Speed (CWV): {input_data.get('site_speed', 'N/A')}
Mobile Score: {input_data.get('mobile_score', 'N/A')}
Backlinks: {input_data.get('backlinks', 'N/A')}
Referring Domains: {input_data.get('referring_domains', 'N/A')}

–ü–†–ï–î–´–î–£–©–ò–ï –ü–û–ö–ê–ó–ê–¢–ï–õ–ò (–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è):
Previous Traffic: {input_data.get('previous_traffic', 'N/A')}
Previous Keywords: {input_data.get('previous_keywords', 'N/A')}
Previous Conversions: {input_data.get('previous_conversions', 'N/A')}
Previous Revenue: {input_data.get('previous_revenue', 'N/A')} ‚ÇΩ

–¶–ï–õ–ò –ò KPI:
Target Goals: {input_data.get('target_goals', 'Unknown')}
KPI Focus: {input_data.get('kpi_focus', 'Traffic & Conversions')}
Budget/Investment: {input_data.get('budget', 'N/A')} ‚ÇΩ

–°–æ–∑–¥–∞–π –ø–æ–ª–Ω—ã–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π SEO –æ—Ç—á—ë—Ç —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π. –í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ç—Ä–æ–≥–æ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
{{
    "report_performance_score": <number 0-100>,
    "report_summary": "<executive summary –æ—Ç—á—ë—Ç–∞>",
    "performance_analysis": {{
        "organic_traffic": {{
            "current_value": <number>,
            "previous_value": <number>,
            "change_percentage": <number>,
            "trend": "<—Ä–æ—Å—Ç/—Å–ø–∞–¥/—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å>",
            "trend_analysis": "<–∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞>"
        }},
        "keyword_performance": {{
            "total_keywords": <number>,
            "top_10_keywords": <number>,
            "avg_position_change": <number>,
            "visibility_score": <number>,
            "keyword_trends": "<–æ—Ü–µ–Ω–∫–∞ —Ç—Ä–µ–Ω–¥–æ–≤>"
        }},
        "user_engagement": {{
            "ctr_performance": <percentage>,
            "bounce_rate_estimate": <percentage>,
            "avg_session_duration": "<estimate>",
            "engagement_quality": "<high/medium/low>"
        }}
    }},
    "conversion_analysis": {{
        "conversion_rate": <percentage>,
        "conversion_change": <percentage>,
        "goal_completions": <number>,
        "revenue_attribution": <number>,
        "cost_per_conversion": <number>,
        "conversion_trends": "<–∞–Ω–∞–ª–∏–∑>"
    }},
    "roi_analysis": {{
        "seo_roi_percentage": <number>,
        "revenue_generated": <number>,
        "investment_vs_return": "<—Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ>",
        "payback_period": "<–æ—Ü–µ–Ω–∫–∞>",
        "ltv_impact": "<–≤–ª–∏—è–Ω–∏–µ –Ω–∞ LTV>"
    }},
    "technical_performance": {{
        "site_speed_score": <0-100>,
        "mobile_optimization": <0-100>,
        "core_web_vitals": "<pass/fail>",
        "indexing_health": "<–æ—Ü–µ–Ω–∫–∞>",
        "technical_issues": ["<—Å–ø–∏—Å–æ–∫ –ø—Ä–æ–±–ª–µ–º>"]
    }},
    "competitive_position": {{
        "market_share_estimate": <percentage>,
        "visibility_vs_competitors": "<—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ>",
        "competitive_advantages": ["<–ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞>"],
        "competitive_threats": ["<—É–≥—Ä–æ–∑—ã>"]
    }},
    "key_insights": ["<—Ç–æ–ø-5 –∫–ª—é—á–µ–≤—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤>"],
    "strategic_recommendations": {{
        "high_priority": ["<–≤—ã—Å–æ–∫–æ–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è>"],
        "medium_priority": ["<—Å—Ä–µ–¥–Ω–µ–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è>"],
        "long_term_strategy": ["<–¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è>"]
    }},
    "forecasting": {{
        "30_day_projection": "<–ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 30 –¥–Ω–µ–π>",
        "90_day_projection": "<–ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 90 –¥–Ω–µ–π>",
        "growth_trajectory": "<—Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è —Ä–æ—Å—Ç–∞>",
        "confidence_level": <0.0-1.0>
    }},
    "next_actions": ["<–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏>"]
}}"""

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π –º–µ—Ç–æ–¥ —Å LLM –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π
            result = await self.process_with_llm(user_prompt, input_data)
            
            if result["success"]:
                logger.info(f"‚úÖ SEO –æ—Ç—á—ë—Ç —Å–æ–∑–¥–∞–Ω —á–µ—Ä–µ–∑ OpenAI: {result.get('model_used', 'unknown')}")
                # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç–∞
                if isinstance(result.get("result"), str):
                    # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ç—Ä–æ–∫–∞, –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                    result["reporting_response"] = result["result"]
                    result["agent_type"] = "reporting"
                    result["report_type"] = task_type
                    result["methodology"] = ["Performance Analysis", "KPI Tracking", "ROI Calculation"]
                
                return result
            else:
                # Fallback –∫ –±–∞–∑–æ–≤–æ–π –ª–æ–≥–∏–∫–µ –µ—Å–ª–∏ OpenAI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
                logger.warning("‚ö†Ô∏è OpenAI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback reporting")
                return await self._fallback_reporting(input_data, task_type)
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ reporting: {str(e)}")
            return {
                "success": False,
                "agent": self.agent_id,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def _fallback_reporting(self, input_data: Dict[str, Any], task_type: str) -> Dict[str, Any]:
        """Fallback –ª–æ–≥–∏–∫–∞ reporting –±–µ–∑ LLM"""
        try:
            domain = input_data.get('domain', 'unknown-domain.com')
            period_days = input_data.get('period_days', self.default_time_period)
            
            # –ë–∞–∑–æ–≤—ã–π performance —Å–∫–æ—Ä
            base_score = 65  # –°—Ä–µ–¥–Ω–∏–π —Å–∫–æ—Ä
            
            # –ü—Ä–æ—Å—Ç—ã–µ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö
            current_traffic = input_data.get('organic_traffic', 0)
            previous_traffic = input_data.get('previous_traffic', 0)
            
            if current_traffic > previous_traffic and previous_traffic > 0:
                traffic_growth = ((current_traffic - previous_traffic) / previous_traffic) * 100
                base_score += min(15, traffic_growth * 0.3)
            
            conversions = input_data.get('conversions', 0)
            if conversions > 0:
                base_score += 10
                
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            if base_score >= 80:
                performance = "Excellent"
                trend = "—Å–∏–ª—å–Ω—ã–π —Ä–æ—Å—Ç"
            elif base_score >= 65:
                performance = "Good"
                trend = "—É–º–µ—Ä–µ–Ω–Ω—ã–π —Ä–æ—Å—Ç"
            elif base_score >= 50:
                performance = "Average"
                trend = "—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å"
            else:
                performance = "Needs Improvement"
                trend = "—Å–Ω–∏–∂–µ–Ω–∏–µ"
            
            # –ë–∞–∑–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            recommendations = [
                "–ü—Ä–æ–≤–µ—Å—Ç–∏ –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤",
                "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è CTR",
                "–£–ª—É—á—à–∏—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ —Å–∞–π—Ç–∞"
            ]
            
            if base_score < 60:
                recommendations.insert(0, "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ SEO —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)")
            
            return {
                "success": True,
                "agent": self.agent_id,
                "result": {
                    "report_performance_score": base_score,
                    "performance_summary": performance,
                    "domain": domain,
                    "reporting_period": f"{period_days} –¥–Ω–µ–π",
                    "traffic_trend": trend,
                    "current_metrics": {
                        "organic_traffic": current_traffic,
                        "conversions": conversions,
                        "avg_position": input_data.get('avg_position', 'N/A')
                    },
                    "key_recommendations": recommendations,
                    "note": "–û—Ç—á—ë—Ç —Å–æ–∑–¥–∞–Ω –±–µ–∑ OpenAI (fallback —Ä–µ–∂–∏–º)",
                    "report_config": {
                        "supported_types": self.supported_report_types,
                        "kpi_categories": self.kpi_categories,
                        "confidence_threshold": self.confidence_threshold
                    }
                },
                "fallback_mode": True,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                "success": False,
                "agent": self.agent_id,
                "error": f"Fallback reporting failed: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }

    async def _generate_report(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞"""
        report_config = task_data.get('report_config', {})
        report_type = report_config.get('type', 'detailed_performance')
        domain = report_config.get('domain', 'example.com')
        period_days = report_config.get('period_days', self.default_time_period)
        client_type = report_config.get('client_type', 'general')
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –æ—Ç—á–µ—Ç–∞
        report_data = await self._collect_report_data(domain, period_days, report_type)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞
        if report_type == 'executive_summary':
            report_content = await self._create_executive_summary(report_data, client_type)
        elif report_type == 'detailed_performance':
            report_content = await self._create_detailed_performance_report(report_data)
        elif report_type == 'technical_audit':
            report_content = await self._create_technical_audit_report(report_data)
        elif report_type == 'competitive_intelligence':
            report_content = await self._create_competitive_report(report_data)
        elif report_type == 'roi_analysis':
            report_content = await self._create_roi_analysis_report(report_data)
        else:
            report_content = await self._create_detailed_performance_report(report_data)
        
        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ—Ç—á–µ—Ç–∞
        report_metadata = {
            "report_id": f"rpt_{int(datetime.now().timestamp())}",
            "generated_at": datetime.now().isoformat(),
            "domain": domain,
            "report_type": report_type,
            "period_days": period_days,
            "client_type": client_type,
            "data_sources": list(report_data.keys()),
            "confidence_score": self._calculate_report_confidence(report_data)
        }
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç—á–µ—Ç–∞
        recommendations = self._generate_report_recommendations(report_content, report_type)
        
        logger.info(f"üìä Report Generated:")
        logger.info(f"   üìà Type: {report_type}")
        logger.info(f"   üåê Domain: {domain}")
        logger.info(f"   üìÖ Period: {period_days} days")
        logger.info(f"   üéØ Confidence: {report_metadata['confidence_score']:.1%}")
        
        return {
            "success": True,
            "report_metadata": report_metadata,
            "report_content": report_content,
            "recommendations": recommendations,
            "export_formats": ["pdf", "excel", "powerpoint", "json"],
            "sharing_options": ["email", "dashboard", "api", "download"],
            "agent": self.name,
            "confidence": report_metadata['confidence_score']
        }

    async def _analyze_kpis(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ KPI –∏ —Ç—Ä–µ–Ω–¥–æ–≤"""
        kpi_config = task_data.get('kpi_config', {})
        domain = kpi_config.get('domain', 'example.com')
        kpi_categories = kpi_config.get('categories', self.kpi_categories)
        period_days = kpi_config.get('period_days', 30)
        comparison_period = kpi_config.get('comparison', 'previous_period')
        
        # –°–±–æ—Ä KPI –¥–∞–Ω–Ω—ã—Ö
        current_kpis = self._collect_kpi_data(domain, period_days)
        comparison_kpis = self._collect_comparison_kpi_data(domain, period_days, comparison_period)
        
        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤
        kpi_analysis = {}
        
        for category in kpi_categories:
            if category in current_kpis:
                category_analysis = self._analyze_kpi_category(
                    current_kpis[category], 
                    comparison_kpis.get(category, {}),
                    category
                )
                kpi_analysis[category] = category_analysis
        
        # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        overall_performance = self._calculate_overall_performance(kpi_analysis)
        
        # –í—ã—è–≤–ª–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π
        anomalies = self._detect_kpi_anomalies(current_kpis, comparison_kpis)
        
        # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤
        trend_forecasts = self._forecast_kpi_trends(current_kpis, period_days)
        
        # –ê–ª–µ—Ä—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Ä–æ–≥–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        alerts = self._generate_kpi_alerts(current_kpis, comparison_kpis)
        
        logger.info(f"üìà KPI Analysis:")
        logger.info(f"   üìä Categories Analyzed: {len(kpi_categories)}")
        logger.info(f"   üéØ Overall Performance: {overall_performance['score']}/100")
        logger.info(f"   üö® Alerts Generated: {len(alerts)}")
        logger.info(f"   ‚ö†Ô∏è Anomalies Detected: {len(anomalies)}")
        
        return {
            "success": True,
            "domain": domain,
            "analysis_period": period_days,
            "comparison_period": comparison_period,
            "kpi_analysis": kpi_analysis,
            "overall_performance": overall_performance,
            "anomalies": anomalies,
            "trend_forecasts": trend_forecasts,
            "alerts": alerts,
            "data_quality_score": self._assess_data_quality(current_kpis),
            "agent": self.name,
            "confidence": round(random.uniform(0.82, 0.95), 2)
        }

    async def _prepare_dashboard_data(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è dashboard"""
        dashboard_config = task_data.get('dashboard_config', {})
        domain = dashboard_config.get('domain', 'example.com')
        dashboard_type = dashboard_config.get('type', 'performance_overview')
        refresh_interval = dashboard_config.get('refresh_minutes', 60)
        user_role = dashboard_config.get('user_role', 'marketing_manager')
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–∏–¥–∂–µ—Ç–æ–≤ –¥–ª—è dashboard
        dashboard_widgets = self._get_dashboard_widgets(dashboard_type, user_role)
        
        # –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–∏–¥–∂–µ—Ç–∞
        widget_data = {}
        for widget_id, widget_config in dashboard_widgets.items():
            widget_data[widget_id] = await self._collect_widget_data(
                domain, widget_config, dashboard_type
            )
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        dashboard_filters = self._configure_dashboard_filters(dashboard_type, user_role)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–ª–µ—Ä—Ç–æ–≤ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
        real_time_alerts = self._setup_realtime_alerts(domain, dashboard_type)
        
        # –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        personalization = self._apply_dashboard_personalization(user_role, dashboard_type)
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ dashboard
        performance_metrics = {
            "data_freshness": self._calculate_data_freshness(widget_data),
            "load_time_estimate": f"{random.randint(800, 2000)}ms",
            "data_points_count": sum(len(str(data)) for data in widget_data.values()),
            "update_frequency": f"Every {refresh_interval} minutes"
        }
        
        logger.info(f"üìä Dashboard Data Prepared:")
        logger.info(f"   üéõÔ∏è Type: {dashboard_type}")
        logger.info(f"   üë§ User Role: {user_role}")
        logger.info(f"   üìà Widgets: {len(dashboard_widgets)}")
        logger.info(f"   üîÑ Refresh: {refresh_interval} min")
        
        return {
            "success": True,
            "dashboard_config": {
                "domain": domain,
                "type": dashboard_type,
                "user_role": user_role,
                "refresh_interval": refresh_interval
            },
            "widgets": dashboard_widgets,
            "widget_data": widget_data,
            "filters": dashboard_filters,
            "real_time_alerts": real_time_alerts,
            "personalization": personalization,
            "performance_metrics": performance_metrics,
            "export_options": ["pdf_snapshot", "excel_data", "scheduled_email"],
            "agent": self.name,
            "confidence": round(random.uniform(0.88, 0.96), 2)
        }

    async def _generate_performance_insights(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        insight_config = task_data.get('insight_config', {})
        domain = insight_config.get('domain', 'example.com')
        analysis_depth = insight_config.get('depth', 'comprehensive')
        focus_areas = insight_config.get('focus_areas', ['traffic', 'conversions', 'technical'])
        business_context = insight_config.get('business_context', {})
        
        # –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        performance_data = await self._collect_performance_data(domain, analysis_depth)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∏–Ω—Å–∞–π—Ç–æ–≤
        insights = {}
        
        # Trend insights
        if 'trends' in focus_areas or analysis_depth == 'comprehensive':
            insights['trend_insights'] = self._generate_trend_insights(performance_data)
        
        # Anomaly insights  
        if 'anomalies' in focus_areas or analysis_depth == 'comprehensive':
            insights['anomaly_insights'] = self._generate_anomaly_insights(performance_data)
        
        # Opportunity insights
        if 'opportunities' in focus_areas or analysis_depth == 'comprehensive':
            insights['opportunity_insights'] = self._generate_opportunity_insights(performance_data)
        
        # Performance attribution
        if 'attribution' in focus_areas or analysis_depth == 'comprehensive':
            insights['attribution_insights'] = self._generate_attribution_insights(performance_data)
        
        # Competitive insights
        if 'competitive' in focus_areas or analysis_depth == 'comprehensive':
            insights['competitive_insights'] = self._generate_competitive_insights(performance_data)
        
        # Predictive insights
        if 'forecasting' in focus_areas or analysis_depth == 'comprehensive':
            insights['predictive_insights'] = self._generate_predictive_insights(performance_data)
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤
        prioritized_insights = self._prioritize_insights(insights, business_context)
        
        # Actionable recommendations
        actionable_recommendations = self._create_actionable_recommendations(
            prioritized_insights, business_context
        )
        
        # Confidence scoring
        insight_confidence = self._calculate_insight_confidence(insights, performance_data)
        
        logger.info(f"üîç Performance Insights Generated:")
        logger.info(f"   üìä Analysis Depth: {analysis_depth}")
        logger.info(f"   üéØ Focus Areas: {len(focus_areas)}")
        logger.info(f"   üí° Total Insights: {sum(len(category) for category in insights.values())}")
        logger.info(f"   üöÄ High Priority: {len([i for i in prioritized_insights if i['priority'] == 'high'])}")
        
        return {
            "success": True,
            "domain": domain,
            "analysis_depth": analysis_depth,
            "focus_areas": focus_areas,
            "insights": insights,
            "prioritized_insights": prioritized_insights,
            "actionable_recommendations": actionable_recommendations,
            "insight_confidence": insight_confidence,
            "business_impact_estimate": self._estimate_business_impact(prioritized_insights),
            "implementation_timeline": self._create_implementation_timeline(actionable_recommendations),
            "agent": self.name,
            "confidence": insight_confidence['overall_confidence']
        }

    async def _calculate_roi_attribution(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """–†–∞—Å—á–µ—Ç ROI –∏ –∞—Ç—Ä–∏–±—É—Ü–∏–∏"""
        roi_config = task_data.get('roi_config', {})
        domain = roi_config.get('domain', 'example.com')
        attribution_model = roi_config.get('attribution_model', 'data_driven')
        time_period = roi_config.get('period_days', 90)
        investment_data = roi_config.get('investment_data', {})
        
        # –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –æ –¥–æ—Ö–æ–¥–∞—Ö –∏ –∫–æ–Ω–≤–µ—Ä—Å–∏—è—Ö
        revenue_data = self._collect_revenue_data(domain, time_period)
        conversion_data = self._collect_conversion_data(domain, time_period)
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∞—Ç—Ä–∏–±—É—Ü–∏–∏
        attributed_results = self._apply_attribution_model(
            revenue_data, conversion_data, attribution_model
        )
        
        # –†–∞—Å—á–µ—Ç ROI –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –º–µ—Ç—Ä–∏–∫–∞–º
        roi_calculations = {
            "direct_roi": self._calculate_direct_roi(attributed_results, investment_data),
            "assisted_roi": self._calculate_assisted_roi(attributed_results, investment_data),
            "lifetime_value_roi": self._calculate_ltv_roi(attributed_results, investment_data),
            "blended_roi": self._calculate_blended_roi(attributed_results, investment_data)
        }
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–∞–Ω–∞–ª–∞–º
        channel_attribution = self._analyze_channel_attribution(attributed_results)
        
        # –í—Ä–µ–º–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏–∑ ROI
        roi_trends = self._analyze_roi_trends(revenue_data, investment_data, time_period)
        
        # –ü—Ä–æ–≥–Ω–æ–∑ ROI
        roi_forecast = self._forecast_roi_performance(roi_trends, investment_data)
        
        # –ë–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥
        industry_benchmarks = self._get_industry_roi_benchmarks(domain)
        benchmark_comparison = self._compare_to_benchmarks(roi_calculations, industry_benchmarks)
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ ROI
        optimization_recommendations = self._generate_roi_optimization_recommendations(
            roi_calculations, channel_attribution, benchmark_comparison
        )
        
        logger.info(f"üí∞ ROI Attribution Analysis:")
        logger.info(f"   üìä Attribution Model: {attribution_model}")
        logger.info(f"   üìÖ Time Period: {time_period} days")
        logger.info(f"   üíé Direct ROI: {roi_calculations['direct_roi']['roi_percentage']:.1%}")
        logger.info(f"   üîÑ Blended ROI: {roi_calculations['blended_roi']['roi_percentage']:.1%}")
        
        return {
            "success": True,
            "domain": domain,
            "attribution_model": attribution_model,
            "analysis_period": time_period,
            "roi_calculations": roi_calculations,
            "attributed_results": attributed_results,
            "channel_attribution": channel_attribution,
            "roi_trends": roi_trends,
            "roi_forecast": roi_forecast,
            "benchmark_comparison": benchmark_comparison,
            "optimization_recommendations": optimization_recommendations,
            "data_reliability": self._assess_attribution_reliability(attributed_results),
            "agent": self.name,
            "confidence": round(random.uniform(0.75, 0.88), 2)
        }

    async def _comprehensive_performance_report(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –æ—Ç—á–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)"""
        report_data = task_data.get('input_data', task_data.get('report_data', {}))
        domain = report_data.get('domain', 'example.com')
        client_type = report_data.get('client_type', 'general')
        
        # –ó–∞–ø—É—Å–∫ –∫–ª—é—á–µ–≤—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤
        kpi_analysis = await self._analyze_kpis({
            'kpi_config': {'domain': domain, 'period_days': 30}
        })
        
        performance_insights = await self._generate_performance_insights({
            'insight_config': {'domain': domain, 'depth': 'comprehensive'}
        })
        
        roi_analysis = await self._calculate_roi_attribution({
            'roi_config': {'domain': domain, 'period_days': 90}
        })
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        comprehensive_report = {
            "executive_summary": {
                "overall_performance_score": kpi_analysis["overall_performance"]["score"],
                "key_achievements": self._extract_key_achievements(kpi_analysis, performance_insights),
                "primary_challenges": self._extract_primary_challenges(kpi_analysis, performance_insights),
                "roi_summary": {
                    "direct_roi": roi_analysis["roi_calculations"]["direct_roi"]["roi_percentage"],
                    "total_attributed_revenue": roi_analysis["attributed_results"]["total_revenue"],
                    "investment_efficiency": roi_analysis["benchmark_comparison"]["performance_vs_benchmark"]
                }
            },
            "detailed_performance": {
                "kpi_analysis": kpi_analysis["kpi_analysis"],
                "trend_analysis": performance_insights["insights"].get("trend_insights", []),
                "anomaly_detection": performance_insights["insights"].get("anomaly_insights", [])
            },
            "strategic_insights": {
                "high_priority_opportunities": performance_insights["prioritized_insights"][:5],
                "actionable_recommendations": performance_insights["actionable_recommendations"],
                "competitive_position": performance_insights["insights"].get("competitive_insights", {})
            },
            "financial_analysis": {
                "roi_breakdown": roi_analysis["roi_calculations"],
                "channel_performance": roi_analysis["channel_attribution"],
                "forecast": roi_analysis["roi_forecast"]
            }
        }
        
        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ—Ç—á–µ—Ç–∞
        report_metadata = {
            "report_type": "comprehensive_performance",
            "generated_at": datetime.now().isoformat(),
            "domain": domain,
            "client_type": client_type,
            "data_period": "Last 30-90 days",
            "confidence_score": (
                kpi_analysis["confidence"] + 
                performance_insights["confidence"] + 
                roi_analysis["confidence"]
            ) / 3
        }
        
        logger.info(f"üìä Comprehensive Performance Report:")
        logger.info(f"   üéØ Overall Score: {comprehensive_report['executive_summary']['overall_performance_score']}/100")
        logger.info(f"   üí∞ Direct ROI: {comprehensive_report['executive_summary']['roi_summary']['direct_roi']:.1%}")
        logger.info(f"   üöÄ High Priority Opportunities: {len(comprehensive_report['strategic_insights']['high_priority_opportunities'])}")
        
        return {
            "success": True,
            "report_metadata": report_metadata,
            "comprehensive_report": comprehensive_report,
            "component_analyses": {
                "kpi_analysis": kpi_analysis,
                "performance_insights": performance_insights,
                "roi_analysis": roi_analysis
            },
            "next_steps": self._create_next_steps_plan(comprehensive_report),
            "agent": self.name,
            "confidence": report_metadata["confidence_score"]
        }

    # Helper methods

    async def _collect_report_data(self, domain: str, period_days: int, report_type: str) -> Dict[str, Any]:
        """–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç—á–µ—Ç–∞"""
        # –°–∏–º—É–ª—è—Ü–∏—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        return {
            "google_analytics": {
                "sessions": random.randint(10000, 100000),
                "users": random.randint(8000, 80000),
                "pageviews": random.randint(25000, 250000),
                "bounce_rate": random.uniform(0.35, 0.65),
                "avg_session_duration": random.uniform(120, 300),
                "conversion_rate": random.uniform(0.02, 0.08)
            },
            "search_console": {
                "total_clicks": random.randint(5000, 50000),
                "total_impressions": random.randint(100000, 1000000),
                "avg_ctr": random.uniform(0.03, 0.12),
                "avg_position": random.uniform(8.5, 25.0),
                "indexed_pages": random.randint(500, 5000)
            },
            "third_party_tools": {
                "domain_authority": random.randint(35, 75),
                "backlinks": random.randint(1000, 25000),
                "referring_domains": random.randint(100, 2000),
                "organic_keywords": random.randint(2000, 20000)
            }
        }

    async def _create_executive_summary(self, report_data: Dict, client_type: str) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ executive summary"""
        return {
            "period_overview": f"Performance summary for last {self.default_time_period} days",
            "key_metrics": {
                "traffic_growth": f"+{random.randint(5, 25)}%",
                "conversion_improvement": f"+{random.randint(8, 35)}%",
                "roi_achievement": f"{random.randint(150, 400)}%",
                "market_share_gain": f"+{random.uniform(0.5, 3.2):.1f}%"
            },
            "strategic_highlights": [
                "Organic traffic grew significantly in target segments",
                "Conversion rate optimization yielded strong results",  
                "Technical SEO improvements boosted site performance",
                "Competitive positioning strengthened in key markets"
            ],
            "priority_actions": [
                "Scale successful content marketing initiatives",
                "Expand technical optimization to remaining pages",
                "Increase investment in high-performing channels"
            ]
        }

    async def _create_detailed_performance_report(self, report_data: Dict) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        return {
            "traffic_analysis": {
                "organic_sessions": report_data["google_analytics"]["sessions"],
                "session_growth": f"+{random.randint(10, 30)}%",
                "user_behavior": {
                    "bounce_rate": report_data["google_analytics"]["bounce_rate"],
                    "pages_per_session": random.uniform(2.1, 4.5),
                    "avg_session_duration": report_data["google_analytics"]["avg_session_duration"]
                }
            },
            "search_performance": {
                "keyword_rankings": {
                    "total_keywords": report_data["third_party_tools"]["organic_keywords"],
                    "top_10_keywords": random.randint(150, 800),
                    "featured_snippets": random.randint(5, 25),
                    "avg_position_change": random.uniform(-1.5, 2.2)
                },
                "serp_visibility": {
                    "total_impressions": report_data["search_console"]["total_impressions"],
                    "click_through_rate": report_data["search_console"]["avg_ctr"],
                    "impression_share": random.uniform(0.15, 0.45)
                }
            },
            "conversion_analysis": {
                "conversion_rate": report_data["google_analytics"]["conversion_rate"],
                "goal_completions": random.randint(500, 5000),
                "revenue_attribution": random.randint(500000, 5000000),
                "cost_per_acquisition": random.randint(500, 2500)
            }
        }

    def _collect_kpi_data(self, domain: str, period_days: int) -> Dict[str, Any]:
        """–°–±–æ—Ä KPI –¥–∞–Ω–Ω—ã—Ö"""
        return {
            "visibility_metrics": {
                "organic_impressions": random.randint(100000, 1000000),
                "average_position": random.uniform(8.0, 20.0),
                "serp_features": random.randint(10, 50),
                "voice_share": random.uniform(0.05, 0.25)
            },
            "traffic_metrics": {
                "organic_sessions": random.randint(20000, 200000),
                "organic_users": random.randint(15000, 150000),
                "pages_per_session": random.uniform(2.0, 5.0),
                "session_duration": random.uniform(120, 400)
            },
            "conversion_metrics": {
                "goal_completions": random.randint(500, 8000),
                "micro_conversions": random.randint(2000, 20000),
                "conversion_rate": random.uniform(0.02, 0.12),
                "assisted_conversions": random.randint(200, 3000)
            },
            "revenue_metrics": {
                "revenue_attributed": random.randint(1000000, 10000000),
                "revenue_assisted": random.randint(500000, 5000000),
                "cost_per_acquisition": random.randint(500, 3000),
                "lifetime_value": random.randint(5000, 25000)
            },
            "technical_metrics": {
                "core_web_vitals": random.uniform(0.6, 0.95),
                "crawl_efficiency": random.uniform(0.8, 0.98),
                "site_errors": random.randint(0, 50),
                "security_score": random.uniform(0.85, 1.0)
            }
        }

    def _collect_comparison_kpi_data(self, domain: str, period_days: int, comparison: str) -> Dict[str, Any]:
        """–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è KPI"""
        # –°–∏–º—É–ª—è—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –ø–µ—Ä–∏–æ–¥–∞ (–æ–±—ã—á–Ω–æ –Ω–µ–º–Ω–æ–≥–æ –Ω–∏–∂–µ)
        base_data = self._collect_kpi_data(domain, period_days)
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–ª—è —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
        comparison_data = {}
        for category, metrics in base_data.items():
            comparison_data[category] = {}
            for metric, value in metrics.items():
                if isinstance(value, (int, float)):
                    # –°–ª—É—á–∞–π–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –æ—Ç -20% –¥–æ +10% –¥–ª—è –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
                    change_factor = random.uniform(0.8, 1.1)
                    comparison_data[category][metric] = value * change_factor
                else:
                    comparison_data[category][metric] = value
        
        return comparison_data

    def _analyze_kpi_category(self, current_data: Dict, comparison_data: Dict, category: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ KPI"""
        analysis = {
            "category": category,
            "metrics": {},
            "overall_trend": "stable",
            "significant_changes": []
        }
        
        total_improvement = 0
        metric_count = 0
        
        for metric, current_value in current_data.items():
            if isinstance(current_value, (int, float)) and metric in comparison_data:
                previous_value = comparison_data[metric]
                change_percent = ((current_value - previous_value) / previous_value) * 100
                
                analysis["metrics"][metric] = {
                    "current_value": current_value,
                    "previous_value": previous_value,
                    "change_percent": round(change_percent, 1),
                    "trend": "up" if change_percent > 5 else "down" if change_percent < -5 else "stable"
                }
                
                if abs(change_percent) > 15:
                    analysis["significant_changes"].append({
                        "metric": metric,
                        "change": change_percent,
                        "significance": "high" if abs(change_percent) > 25 else "medium"
                    })
                
                total_improvement += change_percent
                metric_count += 1
        
        if metric_count > 0:
            avg_improvement = total_improvement / metric_count
            if avg_improvement > 5:
                analysis["overall_trend"] = "improving"
            elif avg_improvement < -5:
                analysis["overall_trend"] = "declining"
        
        return analysis

    def _calculate_overall_performance(self, kpi_analysis: Dict) -> Dict[str, Any]:
        """–†–∞—Å—á–µ—Ç –æ–±—â–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        category_scores = []
        
        for category, analysis in kpi_analysis.items():
            improving_metrics = sum(1 for m in analysis["metrics"].values() if m["trend"] == "up")
            stable_metrics = sum(1 for m in analysis["metrics"].values() if m["trend"] == "stable")
            declining_metrics = sum(1 for m in analysis["metrics"].values() if m["trend"] == "down")
            total_metrics = len(analysis["metrics"])
            
            if total_metrics > 0:
                category_score = ((improving_metrics * 2 + stable_metrics) / (total_metrics * 2)) * 100
                category_scores.append(category_score)
        
        overall_score = sum(category_scores) / len(category_scores) if category_scores else 50
        
        return {
            "score": round(overall_score, 1),
            "grade": "excellent" if overall_score >= 80 else "good" if overall_score >= 60 else "needs_improvement" if overall_score >= 40 else "critical",
            "category_scores": dict(zip(kpi_analysis.keys(), category_scores))
        }

    def _detect_kpi_anomalies(self, current_kpis: Dict, comparison_kpis: Dict) -> List[Dict]:
        """–í—ã—è–≤–ª–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –≤ KPI"""
        anomalies = []
        
        for category, metrics in current_kpis.items():
            if category in comparison_kpis:
                for metric, current_value in metrics.items():
                    if isinstance(current_value, (int, float)) and metric in comparison_kpis[category]:
                        previous_value = comparison_kpis[category][metric]
                        change_percent = abs(((current_value - previous_value) / previous_value) * 100)
                        
                        if change_percent > 50:  # –ë–æ–ª–µ–µ 50% –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å—á–∏—Ç–∞–µ—Ç—Å—è –∞–Ω–æ–º–∞–ª–∏–µ–π
                            anomalies.append({
                                "category": category,
                                "metric": metric,
                                "current_value": current_value,
                                "previous_value": previous_value,
                                "change_percent": round(change_percent, 1),
                                "severity": "critical" if change_percent > 75 else "high",
                                "direction": "spike" if current_value > previous_value else "drop"
                            })
        
        return sorted(anomalies, key=lambda x: x["change_percent"], reverse=True)

    def _forecast_kpi_trends(self, current_kpis: Dict, period_days: int) -> Dict[str, Any]:
        """–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤ KPI"""
        forecasts = {}
        
        for category, metrics in current_kpis.items():
            forecasts[category] = {}
            for metric, current_value in metrics.items():
                if isinstance(current_value, (int, float)):
                    # –ü—Ä–æ—Å—Ç–æ–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞
                    trend_factor = random.uniform(0.95, 1.15)  # -5% –¥–æ +15% —Ä–æ—Å—Ç–∞
                    forecast_30d = current_value * trend_factor
                    forecast_90d = current_value * (trend_factor ** 3)
                    
                    forecasts[category][metric] = {
                        "current_value": current_value,
                        "forecast_30d": round(forecast_30d, 2),
                        "forecast_90d": round(forecast_90d, 2),
                        "confidence": random.uniform(0.7, 0.9),
                        "trend_direction": "up" if trend_factor > 1.05 else "down" if trend_factor < 0.95 else "stable"
                    }
        
        return forecasts

    def _generate_kpi_alerts(self, current_kpis: Dict, comparison_kpis: Dict) -> List[Dict]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–ª–µ—Ä—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ KPI"""
        alerts = []
        
        # –ê–ª–µ—Ä—Ç—ã –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
        for category, metrics in current_kpis.items():
            if category in comparison_kpis:
                for metric, current_value in metrics.items():
                    if isinstance(current_value, (int, float)) and metric in comparison_kpis[category]:
                        previous_value = comparison_kpis[category][metric]
                        change_percent = ((current_value - previous_value) / previous_value) * 100
                        
                        # –ê–ª–µ—Ä—Ç –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è —Ç—Ä–∞—Ñ–∏–∫–∞
                        if metric in ["organic_sessions", "organic_users"] and change_percent < -20:
                            alerts.append({
                                "type": "traffic_drop",
                                "severity": "high",
                                "metric": metric,
                                "change_percent": round(change_percent, 1),
                                "message": f"{metric} decreased by {abs(change_percent):.1f}%",
                                "action_required": True
                            })
                        
                        # –ê–ª–µ—Ä—Ç –¥–ª—è –ø–∞–¥–µ–Ω–∏—è –∫–æ–Ω–≤–µ—Ä—Å–∏–π
                        elif metric == "conversion_rate" and change_percent < -15:
                            alerts.append({
                                "type": "conversion_drop",
                                "severity": "critical",
                                "metric": metric,
                                "change_percent": round(change_percent, 1),
                                "message": f"Conversion rate dropped by {abs(change_percent):.1f}%",
                                "action_required": True
                            })
        
        return sorted(alerts, key=lambda x: {"critical": 3, "high": 2, "medium": 1, "low": 0}[x["severity"]], reverse=True)

    def _assess_data_quality(self, kpis: Dict) -> float:
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö"""
        quality_factors = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö
        total_expected_metrics = sum(len(category) for category in kpis.values())
        actual_metrics = sum(sum(1 for v in category.values() if v is not None) for category in kpis.values())
        completeness = actual_metrics / total_expected_metrics if total_expected_metrics > 0 else 0
        quality_factors.append(completeness)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑—É–º–Ω–æ—Å—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏–π
        reasonable_values = 0
        total_numeric_values = 0
        for category in kpis.values():
            for metric, value in category.items():
                if isinstance(value, (int, float)):
                    total_numeric_values += 1
                    if value >= 0 and not (value == 0 and metric not in ["site_errors"]):  # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –Ω–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å 0
                        reasonable_values += 1
        
        reasonableness = reasonable_values / total_numeric_values if total_numeric_values > 0 else 0
        quality_factors.append(reasonableness)
        
        return sum(quality_factors) / len(quality_factors)

    def _get_dashboard_widgets(self, dashboard_type: str, user_role: str) -> Dict[str, Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤–∏–¥–∂–µ—Ç–æ–≤ –¥–ª—è dashboard"""
        base_widgets = {
            "performance_scorecard": {
                "type": "scorecard",
                "metrics": ["traffic", "conversions", "rankings", "roi"],
                "size": "large"
            },
            "traffic_chart": {
                "type": "time_series",
                "metrics": ["organic_sessions", "organic_users"],
                "size": "medium"
            },
            "keyword_table": {
                "type": "data_table",
                "metrics": ["keyword", "position", "volume", "clicks"],
                "size": "medium"
            }
        }
        
        if user_role == "executive":
            base_widgets["roi_summary"] = {
                "type": "financial_summary",
                "metrics": ["roi", "revenue", "cost"],
                "size": "large"
            }
        elif user_role == "technical":
            base_widgets["technical_health"] = {
                "type": "health_monitor",
                "metrics": ["core_web_vitals", "errors", "crawl_rate"],
                "size": "medium"
            }
        
        return base_widgets

    async def _collect_widget_data(self, domain: str, widget_config: Dict, dashboard_type: str) -> Dict[str, Any]:
        """–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∏–¥–∂–µ—Ç–∞"""
        widget_data = {}
        
        for metric in widget_config["metrics"]:
            if metric == "traffic":
                widget_data[metric] = random.randint(10000, 100000)
            elif metric == "conversions":
                widget_data[metric] = random.randint(500, 5000)
            elif metric == "rankings":
                widget_data[metric] = random.uniform(8.0, 15.0)
            elif metric == "roi":
                widget_data[metric] = random.uniform(1.5, 4.5)
            else:
                widget_data[metric] = random.randint(100, 10000)
        
        return widget_data

    def _configure_dashboard_filters(self, dashboard_type: str, user_role: str) -> Dict[str, Any]:
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤ dashboard"""
        return {
            "time_range": ["last_7_days", "last_30_days", "last_90_days", "custom"],
            "device": ["desktop", "mobile", "tablet"],
            "geography": ["all", "russia", "moscow", "spb"],
            "traffic_source": ["organic", "direct", "referral", "social", "paid"]
        }

    def _setup_realtime_alerts(self, domain: str, dashboard_type: str) -> List[Dict]:
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–ª–µ—Ä—Ç–æ–≤ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏"""
        return [
            {
                "alert_type": "traffic_anomaly",
                "threshold": "20% deviation from normal",
                "enabled": True
            },
            {
                "alert_type": "conversion_drop",
                "threshold": "15% decrease",
                "enabled": True
            },
            {
                "alert_type": "ranking_loss",
                "threshold": "5+ position drop for target keywords",
                "enabled": True
            }
        ]

    def _apply_dashboard_personalization(self, user_role: str, dashboard_type: str) -> Dict[str, Any]:
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ dashboard"""
        return {
            "preferred_metrics": {
                "executive": ["roi", "revenue", "market_share"],
                "marketing_manager": ["traffic", "conversions", "cost_per_acquisition"],
                "technical": ["site_speed", "crawl_errors", "security_score"]
            }.get(user_role, ["traffic", "conversions"]),
            "default_time_range": "last_30_days",
            "notification_preferences": {
                "email": True,
                "slack": False,
                "dashboard": True
            }
        }

    def _calculate_data_freshness(self, widget_data: Dict) -> str:
        """–†–∞—Å—á–µ—Ç —Å–≤–µ–∂–µ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö"""
        # –°–∏–º—É–ª—è—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–≤–µ–∂–µ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
        freshness_minutes = random.randint(5, 60)
        if freshness_minutes <= 15:
            return "very_fresh"
        elif freshness_minutes <= 30:
            return "fresh"
        elif freshness_minutes <= 60:
            return "moderate"
        else:
            return "stale"

    def _calculate_report_confidence(self, report_data: Dict) -> float:
        """–†–∞—Å—á–µ—Ç –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ –æ—Ç—á–µ—Ç–∞"""
        source_weights = []
        
        for source, data in report_data.items():
            reliability = self.data_source_reliability.get(source, 0.5)
            data_completeness = len([v for v in data.values() if v is not None]) / len(data)
            source_confidence = reliability * data_completeness
            source_weights.append(source_confidence)
        
        return sum(source_weights) / len(source_weights) if source_weights else 0.5

    def _generate_report_recommendations(self, report_content: Dict, report_type: str) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç—á–µ—Ç–∞"""
        recommendations = []
        
        if report_type == "executive_summary":
            recommendations.extend([
                "–£–≤–µ–ª–∏—á–∏—Ç—å –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏ –≤ –≤—ã—Å–æ–∫–æ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –∫–∞–Ω–∞–ª—ã",
                "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω–≤–µ—Ä—Å–∏–æ–Ω–Ω—É—é –≤–æ—Ä–æ–Ω–∫—É",
                "–†–∞—Å—à–∏—Ä–∏—Ç—å —É—Å–ø–µ—à–Ω—ã–µ –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"
            ])
        elif report_type == "technical_audit":
            recommendations.extend([
                "–ò—Å–ø—Ä–∞–≤–∏—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏",
                "–£–ª—É—á—à–∏—Ç—å Core Web Vitals –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏",
                "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–æ–±–∏–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é —Å–∞–π—Ç–∞"
            ])
        else:
            recommendations.extend([
                "–°–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏—Ç—å—Å—è –Ω–∞ –≤—ã—Å–æ–∫–æ–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è—Ö",
                "–£–ª—É—á—à–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–µ–¥–æ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü",
                "–†–∞–∑–≤–∏–≤–∞—Ç—å —É—Å–ø–µ—à–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"
            ])
        
        return recommendations

    def get_agent_metrics(self) -> AgentMetrics:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞"""
        return AgentMetrics(
            agent_name=self.name,
            agent_type="operational",
            version="1.0.0",
            status="active",
            total_tasks_processed=getattr(self, '_tasks_processed', 0),
            success_rate=getattr(self, '_success_rate', 0.0),
            average_response_time=getattr(self, '_avg_response_time', 0.0),
            specialized_metrics={
                "supported_report_types": len(self.supported_report_types),
                "kpi_categories": len(self.kpi_categories),
                "max_data_points": self.max_report_data_points,
                "confidence_threshold": self.confidence_threshold
            }
        )